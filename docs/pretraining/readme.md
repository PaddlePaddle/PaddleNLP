# é¢„è®­ç»ƒ

[LLaMA v1/v2](./llama)ã€[GPT-3](./gpt-3) ç›®å½•ä¸­æä¾›äº†æ¨¡å‹é¢„è®­ç»ƒçš„æ•°æ®å‡†å¤‡å’Œè®­ç»ƒç»†èŠ‚ï¼Œåç»­æˆ‘ä»¬å°†æ”¯æŒæ›´å¤šçš„æ¨¡å‹é¢„è®­ç»ƒã€‚


```
# åƒé—®æ¨¡å‹é¢„è®­ç»ƒ
python -u  -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" run_pretrain.py ./qwen/pretrain_argument_stage2.json
```


## æ¨¡å‹é¢„è®­ç»ƒæ”¯æŒçš„åˆ†å¸ƒå¼èƒ½åŠ›ä¸€è§ˆ

æ¨¡å‹|èƒ½åŠ›|||||||||||||
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
||Data Parallelism|Tensor Parallelism|Pipeline Parallelism|sequence parallelism|Flash Attention|Sharding Stage1 ||Stage2||Stage3||Selective Recompute|
|||||||recompute|DP|recompute|DP|recompute|DP||
LLaMA-65B   |âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
LLaMA2-70B  |âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
BaiChuan-13B|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
GPT3        |âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
Qwen-7B     |âœ…|âœ…|âœ…|ó € ó € ó € â¬œ|âœ…|â¬œ|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
Qwen-14B    |âœ…|âœ…|âœ…|â¬œ|âœ…|â¬œ|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
OPT 66B     |âœ…|â¬œ|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|
Bloom-176B  |âœ…|âœ…|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|
ChatGLM-6B  |âœ…|âœ…|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|
GLM 130B    |âœ…|âœ…|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|

* âœ…: å·²æ”¯æŒï¼ŒSupported
* ğŸš§: éƒ¨åˆ†æ”¯æŒï¼ŒIn Progress
* âŒ: æš‚ä¸æ”¯æŒï¼ŒNot Supported


## æ¨¡å‹æƒé‡æ”¯æŒåˆ—è¡¨
ä¸Šè¡¨ä¸­å±•ç¤ºçš„æ˜¯éƒ¨åˆ†æ¨¡å‹æƒé‡ï¼Œæ”¯æŒçš„æ‰€æœ‰æ¨¡å‹å¦‚ä¸‹ï¼š

```
* LLaMAç³»åˆ—
  - facebook/llama-7b [è‹±æ–‡]
  - facebook/llama-13b [è‹±æ–‡]
  - facebook/llama-65b [è‹±æ–‡]
  - meta-llama/Llama-2-7b [è‹±æ–‡]
  - meta-llama/Llama-2-7b-chat [è‹±æ–‡]
  - meta-llama/Llama-2-13b [è‹±æ–‡]
  - meta-llama/Llama-2-13b-chat [è‹±æ–‡]
  - meta-llama/Llama-2-70b [è‹±æ–‡]
  - baichuan-inc/Baichuan-7B [ä¸­æ–‡]
  - baichuan-inc/Baichuan-13B-Base [ä¸­æ–‡]
  - baichuan-inc/Baichuan-13B-Chat [ä¸­æ–‡]
  - baichuan-inc/Baichuan2-7B-Base [ä¸­æ–‡]
  - baichuan-inc/Baichuan2-7B-Chat [ä¸­æ–‡]
  - baichuan-inc/Baichuan2-13B-Base [ä¸­æ–‡]
  - baichuan-inc/Baichuan2-13B-Chat [ä¸­æ–‡]
  - FlagAlpha/Llama2-Chinese-7b-Chat [ä¸­æ–‡]
  - FlagAlpha/Llama2-Chinese-13b-Chat [ä¸­æ–‡]
  - idea-ccnl/ziya-llama-13b-v1 [ä¸­æ–‡]
  - linly-ai/chinese-llama-2-7b [ä¸­æ–‡]
  - linly-ai/chinese-llama-2-13b [ä¸­æ–‡]
* ChatGLMç³»åˆ—
  - THUDM/chatglm-6b-v1.1 [ä¸­æ–‡]
  - THUDM/chatglm2-6b [ä¸­æ–‡]
* BLOOMç³»åˆ—
  - bigscience/bloom-7b1 [è‹±æ–‡]
  - bigscience/bloomz-7b1 [å¤šè¯­è¨€]
  - bigscience/bloomz-7b1-mt [å¤šè¯­è¨€]
* Qwenç³»åˆ—
  - qwen/qwen-7b [ä¸­æ–‡]
  - qwen/qwen-7b-chat [ä¸­æ–‡]
  - qwen/qwen-14b [ä¸­æ–‡]
  - qwen/qwen-14b-chat [ä¸­æ–‡]
```


## é¢„è®­ç»ƒæ€§èƒ½
ä»¥ä¸‹æµ‹è¯•ç»“æœåŸºäº

æœºå™¨ç¯å¢ƒï¼š A100 80G * 8, CUDA 11.8, NCCL 2.15

```
paddle commit id              : 9b36e53f24ac5f471b20de99e0cc3980f38b44ab
paddlenlp commit id           : 0b246a609a3062e3c3256d87193b70277b5b07e0
```

|æ¨¡å‹        |åºåˆ—é•¿åº¦      |åˆ†å¸ƒå¼ç­–ç•¥     |é€Ÿåº¦(`tokens/card/sec`)|æ˜¾å­˜å ç”¨(`MB^1`)|é…ç½®æ–‡ä»¶      |æµ‹è¯•æ—¶é—´      |
| :-:      | :-:      | :-:      | :-:      | :-:      | :-:      | :-:      |
|`FlagAlpha/Llama2-Chinese-13b-Chat`|      4096|`tp2sd4_stage2`|   1980.22|64323MB   |`./llama/pretrain-flagalpha_llama2_13b-tp2sd4_stage2.json`|2023-11-27 21:42:38|
|`FlagAlpha/Llama2-Chinese-7b-Chat`|      4096|`tp2sd4_stage2`|   3744.62|52092MB   |`./llama/pretrain-flagalpha_llama2_7b-tp2sd4_stage2.json`|2023-11-27 21:44:57|
|`baichuan-inc/Baichuan2-13B-Base`|      4096|`sd8_stage2`|   1354.99|74767MB   |`./llama/pretrain-baichuan2_13b-sd8_stage2.json`|2023-11-27 21:51:26|
|`baichuan-inc/Baichuan2-7B-Base`|      4096|`tp2sd4_stage2`|   3542.45|58363MB   |`./llama/pretrain-baichuan2_7b-tp2sd4_stage2.json`|2023-11-27 21:53:58|
|`facebook/llama-13b`|      4096|`tp2sd4_stage2`|   1969.64|64278MB   |`./llama/pretrain-llama_13b-tp2sd4_stage2.json`| 2023-11-27 21:58:03|
|`facebook/llama-7b`|      4096|`tp2sd4_stage2`|   3754.73|52092MB   |`./llama/pretrain-llama_7b-tp2sd4_stage2.json`|2023-11-27 22:00:30|
|`idea-ccnl/ziya-llama-13b-v1`|      4096|`tp2sd4_stage2`|   1968.34|63983MB   |`./llama/pretrain-ziya_llama_13b-tp2sd4_stage2.json`|2023-11-27 22:04:35|
|`linly-ai/chinese-llama-2-7b`|      4096|`tp2sd4_stage2`|    3732.9|51751MB   |`./llama/pretrain-linly_llama2_7b-tp2sd4_stage2.json`|2023-11-27 22:06:58|
|`meta-llama/Llama-2-13b`|      4096|`tp2sd4_stage2`|   1975.63|64294MB   |`./llama/pretrain-llama2_13b-tp2sd4_stage2.json`|2023-11-27 22:11:04|
|`meta-llama/Llama-2-7b`|      4096|`tp2sd4_stage2`|   3755.21|52092MB   |`./llama/pretrain-llama2_7b-tp2sd4_stage2.json`|2023-11-27 22:13:34|
|`qwen/qwen-7b`|      4096|`tp2sd4_stage2`|   3607.28|65448MB   |`./qwen/pretrain-qwen_7b-tp2sd4_stage2.json`|2023-11-27 22:16:04|


æ³¨ï¼š
1. æ˜¾å­˜å ç”¨(MB)ä½¿ç”¨çš„æ˜¯ `max_memory_allocated`, å®é™…ç‰©ç†æ˜¾å­˜ä¼šå ç”¨æ›´å¤šï¼Œå¤§çº¦å¤š2-3GB.
2. é€Ÿåº¦ä¼šæœ‰å°å¹…æ³¢åŠ¨ï¼Œä¾‹å¦‚ `facebook/llama-7b` å’Œ `meta-llama/Llama-2-7b` æ˜¯ç›¸åŒè®­ç»ƒé…ç½®ã€‚
