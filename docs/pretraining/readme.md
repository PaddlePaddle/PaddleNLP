# é¢„è®­ç»ƒ

[LLaMA v1/v2](./llama)ã€[GPT-3](./gpt-3) ç›®å½•ä¸­æä¾›äº†æ¨¡å‹é¢„è®­ç»ƒçš„æ•°æ®å‡†å¤‡å’Œè®­ç»ƒç»†èŠ‚ï¼Œåç»­æˆ‘ä»¬å°†æ”¯æŒæ›´å¤šçš„æ¨¡å‹é¢„è®­ç»ƒã€‚


```
# åƒé—®æ¨¡å‹é¢„è®­ç»ƒ
python -u  -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" run_pretrain.py ./qwen/pretrain_argument_stage2.json
```


## æ¨¡å‹é¢„è®­ç»ƒæ”¯æŒçš„åˆ†å¸ƒå¼èƒ½åŠ›ä¸€è§ˆ

æ¨¡å‹|èƒ½åŠ›|||||||||||||
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
||Data Parallelism|Tensor Parallelism|Pipeline Parallelism|sequence parallelism|Flash Attention|Sharding Stage1 ||Stage2||Stage3||Selective Recompute|
|||||||recompute|DP|recompute|DP|recompute|DP||
LLaMA-65B   |âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
LLaMA2-70B  |âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
BaiChuan-13B|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
GPT3        |âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
Qwen-7B     |âœ…|âœ…|âœ…|ó € ó € ó € â¬œ|âœ…|â¬œ|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
Qwen-14B    |âœ…|âœ…|âœ…|â¬œ|âœ…|â¬œ|âœ…|âœ…|âœ…|âœ…|âœ…|âœ…|
OPT 66B     |âœ…|â¬œ|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|
Bloom-176B  |âœ…|âœ…|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|
ChatGLM-6B  |âœ…|âœ…|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|
GLM 130B    |âœ…|âœ…|â¬œ|â¬œ|âŒ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|â¬œ|ğŸš§|

* âœ…: å·²æ”¯æŒï¼ŒSupported
* ğŸš§: éƒ¨åˆ†æ”¯æŒï¼ŒIn Progress
* âŒ: æš‚ä¸æ”¯æŒï¼ŒNot Supported


ä¸Šè¡¨ä¸­å±•ç¤ºçš„æ˜¯éƒ¨åˆ†æ¨¡å‹æƒé‡ï¼Œå®é™…ä¸Šï¼š
