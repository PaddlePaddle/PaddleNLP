# PaddleNLPä¸€é”®é¢„æµ‹åŠŸèƒ½ï¼šTaskflow API



<p align="left">
    <a href="https://pypi.org/project/paddlenlp/"><img src="https://img.shields.io/pypi/v/paddlenlp.svg?label=pip&logo=PyPI&logoColor=white"></a>
    <a href="https://github.com/PaddlePaddle/PaddleNLP/releases"><img src="https://img.shields.io/github/v/release/PaddlePaddle/PaddleNLP?color=ffa"></a>
    <a href="https://pypi.org/project/paddlenlp/"><img src="https://img.shields.io/pypi/pyversions/paddlenlp"></a>
    <a href=""><img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-yellow.svg"></a>
    <a href="../../LICENSE"><img src="https://img.shields.io/github/license/paddlepaddle/paddlenlp"></a>
</p>


<h4 align="left">
  <a href=#QuickStart> QuickStart </a> |
  <a href=#ç¤¾åŒºäº¤æµ> ç¤¾åŒºäº¤æµ </a> |
  <a href=#è¯¦ç»†ä½¿ç”¨> ä¸€é”®é¢„æµ‹&å®šåˆ¶è®­ç»ƒ </a> |
  <a href=#FAQ> FAQ </a>
</h4>


------------------------------------------------------------------------------------------

## ç‰¹æ€§
PaddleNLPæä¾›**å¼€ç®±å³ç”¨**çš„äº§ä¸šçº§NLPé¢„ç½®ä»»åŠ¡èƒ½åŠ›ï¼Œæ— éœ€è®­ç»ƒï¼Œä¸€é”®é¢„æµ‹ã€‚
- æœ€å…¨çš„ä¸­æ–‡ä»»åŠ¡ï¼šè¦†ç›–è‡ªç„¶è¯­è¨€ç†è§£ä¸è‡ªç„¶è¯­è¨€ç”Ÿæˆä¸¤å¤§æ ¸å¿ƒåº”ç”¨ï¼›
- æè‡´çš„äº§ä¸šçº§æ•ˆæœï¼šåœ¨å¤šä¸ªä¸­æ–‡åœºæ™¯ä¸Šæä¾›äº§ä¸šçº§çš„ç²¾åº¦ä¸é¢„æµ‹æ€§èƒ½ï¼›
- ç»Ÿä¸€çš„åº”ç”¨èŒƒå¼ï¼šé€šè¿‡`paddlenlp.Taskflow`è°ƒç”¨ï¼Œç®€æ·æ˜“ç”¨ã€‚

| ä»»åŠ¡åç§°                           | è°ƒç”¨æ–¹å¼                         | ä¸€é”®é¢„æµ‹ | å•æ¡è¾“å…¥ | å¤šæ¡è¾“å…¥ | æ–‡æ¡£çº§è¾“å…¥ | å®šåˆ¶åŒ–è®­ç»ƒ | å…¶å®ƒç‰¹æ€§                                               |
| :--------------------------------- | -------------------------------- | -------- | -------- | -------- | ---------- | ---------- | ------------------------------------------------------ |
| [ä¸­æ–‡åˆ†è¯](#ä¸­æ–‡åˆ†è¯)              | `Taskflow("word_segmentation")`  | âœ…        | âœ…        | âœ…        | âœ…          | âœ…          | å¤šç§åˆ†è¯æ¨¡å¼ï¼Œæ»¡è¶³å¿«é€Ÿåˆ‡åˆ†å’Œå®ä½“ç²’åº¦ç²¾å‡†åˆ‡åˆ†           |
| [ä¿¡æ¯æŠ½å–](#ä¿¡æ¯æŠ½å–)           | `Taskflow("information_extraction")`| âœ…        | âœ…        | âœ…        | âœ…         | âœ…          | é€‚é…å¤šåœºæ™¯çš„å¼€æ”¾åŸŸé€šç”¨ä¿¡æ¯æŠ½å–å·¥å…·                     |
| [æ–‡æœ¬çº é”™](#æ–‡æœ¬çº é”™)              | `Taskflow("text_correction")`    | âœ…        | âœ…        | âœ…        | âœ…          | âœ…          | èåˆæ‹¼éŸ³ç‰¹å¾çš„ç«¯åˆ°ç«¯æ–‡æœ¬çº é”™æ¨¡å‹ERNIE-CSC              |
| [æ–‡æœ¬ç›¸ä¼¼åº¦](#æ–‡æœ¬ç›¸ä¼¼åº¦)          | `Taskflow("text_similarity")`    | âœ…        | âœ…        | âœ…        |            |            | åŸºäºç™¾ä¸‡é‡çº§Dureader Retrievalæ•°æ®é›†è®­ç»ƒRocketQAå¹¶è¾¾åˆ°å‰æ²¿æ–‡æœ¬ç›¸ä¼¼æ•ˆæœ|
| [æƒ…æ„Ÿåˆ†æ](#æƒ…æ„Ÿåˆ†æ)      | `Taskflow("sentiment_analysis")`  | âœ…        | âœ…        | âœ…        |            | âœ…          | é›†æˆBiLSTMã€SKEPã€UIEç­‰æ¨¡å‹ï¼Œæ”¯æŒè¯„è®ºç»´åº¦ã€è§‚ç‚¹æŠ½å–ã€æƒ…æ„Ÿææ€§åˆ†ç±»ç­‰æƒ…æ„Ÿåˆ†æä»»åŠ¡             |
| [æ¨¡å‹ç‰¹å¾æå–](#æ¨¡å‹ç‰¹å¾æå–)      | `Taskflow("feature_extraction")`  | âœ…        | âœ…        | âœ…        |     âœ…       |          | é›†æˆæ–‡æœ¬ï¼Œå›¾ç‰‡çš„ç‰¹å¾æŠ½å–å·¥å…·       |

## QuickStart

**ç¯å¢ƒä¾èµ–**
  - python >= 3.6
  - paddlepaddle >= 2.3.0
  - paddlenlp >= 2.3.4

![taskflow1](https://user-images.githubusercontent.com/11793384/159693816-fda35221-9751-43bb-b05c-7fc77571dd76.gif)

å¯è¿›å…¥ Jupyter Notebook ç¯å¢ƒï¼Œåœ¨çº¿ä½“éªŒ ğŸ‘‰ğŸ»  [è¿›å…¥åœ¨çº¿è¿è¡Œç¯å¢ƒ](https://aistudio.baidu.com/aistudio/projectdetail/3696243)

PaddleNLP Taskflow API æ”¯æŒä»»åŠ¡æŒç»­ä¸°å¯Œä¸­ï¼Œæˆ‘ä»¬å°†æ ¹æ®å¼€å‘è€…åé¦ˆï¼Œçµæ´»è°ƒæ•´åŠŸèƒ½å»ºè®¾ä¼˜å…ˆçº§ï¼Œå¯é€šè¿‡Issueæˆ–[é—®å·](https://iwenjuan.baidu.com/?code=44amg8)åé¦ˆç»™æˆ‘ä»¬ã€‚

## ç¤¾åŒºäº¤æµğŸ‘¬

- å¾®ä¿¡æ‰«æäºŒç»´ç å¹¶å¡«å†™é—®å·ä¹‹åï¼ŒåŠ å…¥äº¤æµç¾¤é¢†å–ç¦åˆ©
  - è·å–5æœˆ18-19æ—¥æ¯æ™š20:30ã€Šäº§ä¸šçº§é€šç”¨ä¿¡æ¯æŠ½å–æŠ€æœ¯UIE+ERNIEè½»é‡çº§æ¨¡å‹ã€‹ç›´æ’­è¯¾é“¾æ¥
  - 10Gé‡ç£…NLPå­¦ä¹ å¤§ç¤¼åŒ…ï¼š

  <div align="center">
  <img src="https://user-images.githubusercontent.com/11793384/168411900-d9f3d777-99ab-4b5c-8cdc-ef747a48b864.jpg" width="188" height="188" />
  </div>

## è¯¦ç»†ä½¿ç”¨

## PART â…  &emsp; ä¸€é”®é¢„æµ‹

### ä¸­æ–‡åˆ†è¯

<details><summary>&emsp;ï¼ˆå¯å±•å¼€è¯¦æƒ…ï¼‰å¤šç§åˆ†è¯æ¨¡å¼ï¼Œæ»¡è¶³å¿«é€Ÿåˆ‡åˆ†å’Œå®ä½“ç²’åº¦ç²¾å‡†åˆ‡åˆ† </summary><div>

#### ä¸‰ç§åˆ†è¯æ¨¡å¼ï¼Œæ»¡è¶³å„ç±»åˆ†è¯éœ€æ±‚

```python
from paddlenlp import Taskflow

# é»˜è®¤æ¨¡å¼â€”â€”â€”â€”å®ä½“ç²’åº¦åˆ†è¯ï¼Œåœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¸Šçš„æƒè¡¡ï¼ŒåŸºäºç™¾åº¦LAC
>>> seg = Taskflow("word_segmentation")
>>> seg("è¿‘æ—¥å›½å®¶å«å¥å§”å‘å¸ƒç¬¬ä¹ç‰ˆæ–°å‹å† çŠ¶ç—…æ¯’è‚ºç‚è¯Šç–—æ–¹æ¡ˆ")
['è¿‘æ—¥', 'å›½å®¶å«å¥å§”', 'å‘å¸ƒ', 'ç¬¬ä¹ç‰ˆ', 'æ–°å‹', 'å† çŠ¶ç—…æ¯’è‚ºç‚', 'è¯Šç–—', 'æ–¹æ¡ˆ']

# å¿«é€Ÿæ¨¡å¼â€”â€”â€”â€”æœ€å¿«ï¼šå®ç°æ–‡æœ¬å¿«é€Ÿåˆ‡åˆ†ï¼ŒåŸºäºjiebaä¸­æ–‡åˆ†è¯å·¥å…·
>>> seg_fast = Taskflow("word_segmentation", mode="fast")
>>> seg_fast("è¿‘æ—¥å›½å®¶å«å¥å§”å‘å¸ƒç¬¬ä¹ç‰ˆæ–°å‹å† çŠ¶ç—…æ¯’è‚ºç‚è¯Šç–—æ–¹æ¡ˆ")
['è¿‘æ—¥', 'å›½å®¶', 'å«å¥å§”', 'å‘å¸ƒ', 'ç¬¬ä¹ç‰ˆ', 'æ–°å‹', 'å† çŠ¶ç—…æ¯’', 'è‚ºç‚', 'è¯Šç–—', 'æ–¹æ¡ˆ']

# ç²¾ç¡®æ¨¡å¼â€”â€”â€”â€”æœ€å‡†ï¼šå®ä½“ç²’åº¦åˆ‡åˆ†å‡†ç¡®åº¦æœ€é«˜ï¼ŒåŸºäºç™¾åº¦è§£è¯­
# ç²¾ç¡®æ¨¡å¼åŸºäºé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ›´é€‚åˆå®ä½“ç²’åº¦åˆ†è¯éœ€æ±‚ï¼Œé€‚ç”¨äºçŸ¥è¯†å›¾è°±æ„å»ºã€ä¼ä¸šæœç´¢Queryåˆ†æç­‰åœºæ™¯ä¸­
>>> seg_accurate = Taskflow("word_segmentation", mode="accurate")
>>> seg_accurate("è¿‘æ—¥å›½å®¶å«å¥å§”å‘å¸ƒç¬¬ä¹ç‰ˆæ–°å‹å† çŠ¶ç—…æ¯’è‚ºç‚è¯Šç–—æ–¹æ¡ˆ")
['è¿‘æ—¥', 'å›½å®¶å«å¥å§”', 'å‘å¸ƒ', 'ç¬¬ä¹ç‰ˆ', 'æ–°å‹å† çŠ¶ç—…æ¯’è‚ºç‚', 'è¯Šç–—', 'æ–¹æ¡ˆ']
```

#### æ‰¹é‡æ ·æœ¬è¾“å…¥ï¼Œå¹³å‡é€Ÿåº¦æ›´å¿«

è¾“å…¥ä¸ºå¤šä¸ªå¥å­ç»„æˆçš„listï¼Œå¹³å‡é€Ÿåº¦ä¼šæ›´å¿«ã€‚

```python
>>> from paddlenlp import Taskflow
>>> seg = Taskflow("word_segmentation")
>>> seg(["ç¬¬åå››å±Šå…¨è¿ä¼šåœ¨è¥¿å®‰ä¸¾åŠ", "ä¸‰äºšæ˜¯ä¸€ä¸ªç¾ä¸½çš„åŸå¸‚"])
[['ç¬¬åå››å±Š', 'å…¨è¿ä¼š', 'åœ¨', 'è¥¿å®‰', 'ä¸¾åŠ'], ['ä¸‰äºš', 'æ˜¯', 'ä¸€ä¸ª', 'ç¾ä¸½', 'çš„', 'åŸå¸‚']]
```

#### è‡ªå®šä¹‰è¯å…¸

ä½ å¯ä»¥é€šè¿‡ä¼ å…¥`user_dict`å‚æ•°ï¼Œè£…è½½è‡ªå®šä¹‰è¯å…¸æ¥å®šåˆ¶åˆ†è¯ç»“æœã€‚
åœ¨é»˜è®¤æ¨¡å¼å’Œç²¾ç¡®æ¨¡å¼ä¸‹ï¼Œè¯å…¸æ–‡ä»¶æ¯ä¸€è¡Œç”±ä¸€ä¸ªæˆ–å¤šä¸ªè‡ªå®šä¹‰itemç»„æˆã€‚è¯å…¸æ–‡ä»¶`user_dict.txt`ç¤ºä¾‹ï¼š
```text
å¹³åŸä¸Šçš„ç«ç„°
ä¸Š æ˜ 
```

åœ¨å¿«é€Ÿæ¨¡å¼ä¸‹ï¼Œè¯å…¸æ–‡ä»¶æ¯ä¸€è¡Œä¸ºä¸€ä¸ªè‡ªå®šä¹‰item+"\t"+è¯é¢‘ï¼ˆè¯é¢‘å¯çœç•¥ï¼Œè¯é¢‘çœç•¥åˆ™è‡ªåŠ¨è®¡ç®—èƒ½ä¿è¯åˆ†å‡ºè¯¥è¯çš„è¯é¢‘ï¼‰ï¼Œæš‚æ—¶ä¸æ”¯æŒé»‘åå•è¯å…¸ï¼ˆå³é€šè¿‡è®¾ç½®â€å¹´â€œã€â€æœ«â€œï¼Œä»¥è¾¾åˆ°åˆ‡åˆ†â€å¹´æœ«â€œçš„ç›®çš„ï¼‰ã€‚è¯å…¸æ–‡ä»¶`user_dict.txt`ç¤ºä¾‹ï¼š

```text
å¹³åŸä¸Šçš„ç«ç„°  10
```

åŠ è½½è‡ªå®šä¹‰è¯å…¸åŠè¾“å‡ºç»“æœç¤ºä¾‹ï¼š
```python
>>> from paddlenlp import Taskflow
>>> seg = Taskflow("word_segmentation")
>>> seg("å¹³åŸä¸Šçš„ç«ç„°å®£å¸ƒå»¶æœŸä¸Šæ˜ ")
['å¹³åŸ', 'ä¸Š', 'çš„', 'ç«ç„°', 'å®£å¸ƒ', 'å»¶æœŸ', 'ä¸Šæ˜ ']
>>> seg = Taskflow("word_segmentation", user_dict="user_dict.txt")
>>> seg("å¹³åŸä¸Šçš„ç«ç„°å®£å¸ƒå»¶æœŸä¸Šæ˜ ")
['å¹³åŸä¸Šçš„ç«ç„°', 'å®£å¸ƒ', 'å»¶æœŸ', 'ä¸Š', 'æ˜ ']
```
#### å‚æ•°è¯´æ˜
* `mode`ï¼šæŒ‡å®šåˆ†è¯æ¨¡å¼ï¼Œé»˜è®¤ä¸ºNoneã€‚
* `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼Œè¯·ç»“åˆæœºå™¨æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé»˜è®¤ä¸º1ã€‚
* `user_dict`ï¼šè‡ªå®šä¹‰è¯å…¸æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneã€‚
* `task_path`ï¼šè‡ªå®šä¹‰ä»»åŠ¡è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneã€‚
</div></details>


### ä¿¡æ¯æŠ½å–
<details><summary>&emsp; é€‚é…å¤šåœºæ™¯çš„å¼€æ”¾åŸŸé€šç”¨ä¿¡æ¯æŠ½å–å·¥å…· </summary><div>

å¼€æ”¾åŸŸä¿¡æ¯æŠ½å–æ˜¯ä¿¡æ¯æŠ½å–çš„ä¸€ç§å…¨æ–°èŒƒå¼ï¼Œä¸»è¦æ€æƒ³æ˜¯å‡å°‘äººå·¥å‚ä¸ï¼Œåˆ©ç”¨å•ä¸€æ¨¡å‹æ”¯æŒå¤šç§ç±»å‹çš„å¼€æ”¾æŠ½å–ä»»åŠ¡ï¼Œç”¨æˆ·å¯ä»¥ä½¿ç”¨è‡ªç„¶è¯­è¨€è‡ªå®šä¹‰æŠ½å–ç›®æ ‡ï¼Œåœ¨å®ä½“ã€å…³ç³»ç±»åˆ«ç­‰æœªå®šä¹‰çš„æƒ…å†µä¸‹æŠ½å–è¾“å…¥æ–‡æœ¬ä¸­çš„ä¿¡æ¯ç‰‡æ®µã€‚

#### å®ä½“æŠ½å–

  å‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognitionï¼Œç®€ç§°NERï¼‰ï¼Œæ˜¯æŒ‡è¯†åˆ«æ–‡æœ¬ä¸­å…·æœ‰ç‰¹å®šæ„ä¹‰çš„å®ä½“ã€‚åœ¨å¼€æ”¾åŸŸä¿¡æ¯æŠ½å–ä¸­ï¼ŒæŠ½å–çš„ç±»åˆ«æ²¡æœ‰é™åˆ¶ï¼Œç”¨æˆ·å¯ä»¥è‡ªå·±å®šä¹‰ã€‚

  - ä¾‹å¦‚æŠ½å–çš„ç›®æ ‡å®ä½“ç±»å‹æ˜¯"æ—¶é—´"ã€"é€‰æ‰‹"å’Œ"èµ›äº‹åç§°", schemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    ['æ—¶é—´', 'é€‰æ‰‹', 'èµ›äº‹åç§°']
    ```

    è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> from pprint import pprint
    >>> from paddlenlp import Taskflow

    >>> schema = ['æ—¶é—´', 'é€‰æ‰‹', 'èµ›äº‹åç§°'] # Define the schema for entity extraction
    >>> ie = Taskflow('information_extraction', schema=schema)
    >>> pprint(ie("2æœˆ8æ—¥ä¸ŠåˆåŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›ä¸­ä¸­å›½é€‰æ‰‹è°·çˆ±å‡Œä»¥188.25åˆ†è·å¾—é‡‘ç‰Œï¼")) # Better print results using pprint
    [{'æ—¶é—´': [{'end': 6,
              'probability': 0.9857378532924486,
              'start': 0,
              'text': '2æœˆ8æ—¥ä¸Šåˆ'}],
      'èµ›äº‹åç§°': [{'end': 23,
                'probability': 0.8503089953268272,
                'start': 6,
                'text': 'åŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›'}],
      'é€‰æ‰‹': [{'end': 31,
              'probability': 0.8981548639781138,
              'start': 28,
              'text': 'è°·çˆ±å‡Œ'}]}]
    ```

  - ä¾‹å¦‚æŠ½å–çš„ç›®æ ‡å®ä½“ç±»å‹æ˜¯"è‚¿ç˜¤çš„å¤§å°"ã€"è‚¿ç˜¤çš„ä¸ªæ•°"ã€"è‚ç™Œçº§åˆ«"å’Œ"è„‰ç®¡å†…ç™Œæ “åˆ†çº§", schemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    ['è‚¿ç˜¤çš„å¤§å°', 'è‚¿ç˜¤çš„ä¸ªæ•°', 'è‚ç™Œçº§åˆ«', 'è„‰ç®¡å†…ç™Œæ “åˆ†çº§']
    ```

    åœ¨ä¸Šä¾‹ä¸­æˆ‘ä»¬å·²ç»å®ä¾‹åŒ–äº†ä¸€ä¸ª`Taskflow`å¯¹è±¡ï¼Œè¿™é‡Œå¯ä»¥é€šè¿‡`set_schema`æ–¹æ³•é‡ç½®æŠ½å–ç›®æ ‡ã€‚

    è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = ['è‚¿ç˜¤çš„å¤§å°', 'è‚¿ç˜¤çš„ä¸ªæ•°', 'è‚ç™Œçº§åˆ«', 'è„‰ç®¡å†…ç™Œæ “åˆ†çº§']
    >>> ie.set_schema(schema)
    >>> pprint(ie("ï¼ˆå³è‚è‚¿ç˜¤ï¼‰è‚ç»†èƒæ€§è‚ç™Œï¼ˆII-IIIçº§ï¼Œæ¢ç´¢å‹å’Œå‡è…ºç®¡å‹ï¼‰ï¼Œè‚¿ç˜¤åŒ…è†œä¸å®Œæ•´ï¼Œç´§é‚»è‚è¢«è†œï¼Œä¾µåŠå‘¨å›´è‚ç»„ç»‡ï¼Œæœªè§è„‰ç®¡å†…ç™Œæ “ï¼ˆMVIåˆ†çº§ï¼šM0çº§ï¼‰åŠå«æ˜Ÿå­ç¶å½¢æˆã€‚ï¼ˆè‚¿ç‰©1ä¸ªï¼Œå¤§å°4.2Ã—4.0Ã—2.8cmï¼‰ã€‚"))
    [{'è‚ç™Œçº§åˆ«': [{'end': 20,
                'probability': 0.9243267447402701,
                'start': 13,
                'text': 'II-IIIçº§'}],
      'è‚¿ç˜¤çš„ä¸ªæ•°': [{'end': 84,
                'probability': 0.7538413804059623,
                'start': 82,
                'text': '1ä¸ª'}],
      'è‚¿ç˜¤çš„å¤§å°': [{'end': 100,
                'probability': 0.8341128043459491,
                'start': 87,
                'text': '4.2Ã—4.0Ã—2.8cm'}],
      'è„‰ç®¡å†…ç™Œæ “åˆ†çº§': [{'end': 70,
                  'probability': 0.9083292325934664,
                  'start': 67,
                  'text': 'M0çº§'}]}]
    ```

  - ä¾‹å¦‚æŠ½å–çš„ç›®æ ‡å®ä½“ç±»å‹æ˜¯"person"å’Œ"organization"ï¼Œschemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    ['person', 'organization']
    ```

    è‹±æ–‡æ¨¡å‹è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> from pprint import pprint
    >>> from paddlenlp import Taskflow
    >>> schema = ['Person', 'Organization']
    >>> ie_en = Taskflow('information_extraction', schema=schema, model='uie-base-en')
    >>> pprint(ie_en('In 1997, Steve was excited to become the CEO of Apple.'))
    [{'Organization': [{'end': 53,
                        'probability': 0.9985840259877357,
                        'start': 48,
                        'text': 'Apple'}],
      'Person': [{'end': 14,
                  'probability': 0.999631971804547,
                  'start': 9,
                  'text': 'Steve'}]}]
    ```

#### å…³ç³»æŠ½å–

  å…³ç³»æŠ½å–ï¼ˆRelation Extractionï¼Œç®€ç§°REï¼‰ï¼Œæ˜¯æŒ‡ä»æ–‡æœ¬ä¸­è¯†åˆ«å®ä½“å¹¶æŠ½å–å®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œè¿›è€Œè·å–ä¸‰å…ƒç»„ä¿¡æ¯ï¼Œå³<ä¸»ä½“ï¼Œè°“è¯­ï¼Œå®¢ä½“>ã€‚

  - ä¾‹å¦‚ä»¥"ç«èµ›åç§°"ä½œä¸ºæŠ½å–ä¸»ä½“ï¼ŒæŠ½å–å…³ç³»ç±»å‹ä¸º"ä¸»åŠæ–¹"ã€"æ‰¿åŠæ–¹"å’Œ"å·²ä¸¾åŠæ¬¡æ•°", schemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    {
      'ç«èµ›åç§°': [
        'ä¸»åŠæ–¹',
        'æ‰¿åŠæ–¹',
        'å·²ä¸¾åŠæ¬¡æ•°'
      ]
    }
    ```

    è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = {'ç«èµ›åç§°': ['ä¸»åŠæ–¹', 'æ‰¿åŠæ–¹', 'å·²ä¸¾åŠæ¬¡æ•°']} # Define the schema for relation extraction
    >>> ie.set_schema(schema) # Reset schema
    >>> pprint(ie('2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›ç”±ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè”åˆä¸»åŠï¼Œç™¾åº¦å…¬å¸ã€ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼šå’Œä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼šæ‰¿åŠï¼Œå·²è¿ç»­ä¸¾åŠ4å±Šï¼Œæˆä¸ºå…¨çƒæœ€çƒ­é—¨çš„ä¸­æ–‡NLPèµ›äº‹ä¹‹ä¸€ã€‚'))
    [{'ç«èµ›åç§°': [{'end': 13,
                'probability': 0.7825402622754041,
                'relations': {'ä¸»åŠæ–¹': [{'end': 22,
                                      'probability': 0.8421710521379353,
                                      'start': 14,
                                      'text': 'ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼š'},
                                      {'end': 30,
                                      'probability': 0.7580801847701935,
                                      'start': 23,
                                      'text': 'ä¸­å›½è®¡ç®—æœºå­¦ä¼š'}],
                              'å·²ä¸¾åŠæ¬¡æ•°': [{'end': 82,
                                        'probability': 0.4671295049136148,
                                        'start': 80,
                                        'text': '4å±Š'}],
                              'æ‰¿åŠæ–¹': [{'end': 39,
                                      'probability': 0.8292706618236352,
                                      'start': 35,
                                      'text': 'ç™¾åº¦å…¬å¸'},
                                      {'end': 72,
                                      'probability': 0.6193477885474685,
                                      'start': 56,
                                      'text': 'ä¸­å›½è®¡ç®—æœºå­¦ä¼šè‡ªç„¶è¯­è¨€å¤„ç†ä¸“å§”ä¼š'},
                                      {'end': 55,
                                      'probability': 0.7000497331473241,
                                      'start': 40,
                                      'text': 'ä¸­å›½ä¸­æ–‡ä¿¡æ¯å­¦ä¼šè¯„æµ‹å·¥ä½œå§”å‘˜ä¼š'}]},
                'start': 0,
                'text': '2022è¯­è¨€ä¸æ™ºèƒ½æŠ€æœ¯ç«èµ›'}]}]
    ```

  - ä¾‹å¦‚ä»¥"person"ä½œä¸ºæŠ½å–ä¸»ä½“ï¼ŒæŠ½å–å…³ç³»ç±»å‹ä¸º"Company"å’Œ"Position", schemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    {
      'Person': [
        'Company',
        'Position'
      ]
    }
    ```

    è‹±æ–‡æ¨¡å‹è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = [{'Person': ['Company', 'Position']}]
    >>> ie_en.set_schema(schema)
    >>> pprint(ie_en('In 1997, Steve was excited to become the CEO of Apple.'))
    [{'Person': [{'end': 14,
                  'probability': 0.999631971804547,
                  'relations': {'Company': [{'end': 53,
                                            'probability': 0.9960158209451642,
                                            'start': 48,
                                            'text': 'Apple'}],
                                'Position': [{'end': 44,
                                              'probability': 0.8871063806420736,
                                              'start': 41,
                                              'text': 'CEO'}]},
                  'start': 9,
                  'text': 'Steve'}]}]
    ```

#### äº‹ä»¶æŠ½å–

  äº‹ä»¶æŠ½å– (Event Extraction, ç®€ç§°EE)ï¼Œæ˜¯æŒ‡ä»è‡ªç„¶è¯­è¨€æ–‡æœ¬ä¸­æŠ½å–é¢„å®šä¹‰çš„äº‹ä»¶è§¦å‘è¯(Trigger)å’Œäº‹ä»¶è®ºå…ƒ(Argument)ï¼Œç»„åˆä¸ºç›¸åº”çš„äº‹ä»¶ç»“æ„åŒ–ä¿¡æ¯ã€‚

  - ä¾‹å¦‚æŠ½å–çš„ç›®æ ‡æ˜¯"åœ°éœ‡"äº‹ä»¶çš„"åœ°éœ‡å¼ºåº¦"ã€"æ—¶é—´"ã€"éœ‡ä¸­ä½ç½®"å’Œ"éœ‡æºæ·±åº¦"è¿™äº›ä¿¡æ¯ï¼Œschemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    {
      'åœ°éœ‡è§¦å‘è¯': [
        'åœ°éœ‡å¼ºåº¦',
        'æ—¶é—´',
        'éœ‡ä¸­ä½ç½®',
        'éœ‡æºæ·±åº¦'
      ]
    }
    ```

    è§¦å‘è¯çš„æ ¼å¼ç»Ÿä¸€ä¸º`è§¦å‘è¯`æˆ–``XXè§¦å‘è¯`ï¼Œ`XX`è¡¨ç¤ºå…·ä½“äº‹ä»¶ç±»å‹ï¼Œä¸Šä¾‹ä¸­çš„äº‹ä»¶ç±»å‹æ˜¯`åœ°éœ‡`ï¼Œåˆ™å¯¹åº”è§¦å‘è¯ä¸º`åœ°éœ‡è§¦å‘è¯`ã€‚

    è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = {'åœ°éœ‡è§¦å‘è¯': ['åœ°éœ‡å¼ºåº¦', 'æ—¶é—´', 'éœ‡ä¸­ä½ç½®', 'éœ‡æºæ·±åº¦']} # Define the schema for event extraction
    >>> ie.set_schema(schema) # Reset schema
    >>> ie('ä¸­å›½åœ°éœ‡å°ç½‘æ­£å¼æµ‹å®šï¼š5æœˆ16æ—¥06æ—¶08åˆ†åœ¨äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)å‘ç”Ÿ3.5çº§åœ°éœ‡ï¼Œéœ‡æºæ·±åº¦10åƒç±³ã€‚')
    [{'åœ°éœ‡è§¦å‘è¯': [{'text': 'åœ°éœ‡', 'start': 56, 'end': 58, 'probability': 0.9987181623528585, 'relations': {'åœ°éœ‡å¼ºåº¦': [{'text': '3.5çº§', 'start': 52, 'end': 56, 'probability': 0.9962985320905915}], 'æ—¶é—´': [{'text': '5æœˆ16æ—¥06æ—¶08åˆ†', 'start': 11, 'end': 22, 'probability': 0.9882578028575182}], 'éœ‡ä¸­ä½ç½®': [{'text': 'äº‘å—ä¸´æ²§å¸‚å‡¤åº†å¿(åŒ—çº¬24.34åº¦ï¼Œä¸œç»99.98åº¦)', 'start': 23, 'end': 50, 'probability': 0.8551415716584501}], 'éœ‡æºæ·±åº¦': [{'text': '10åƒç±³', 'start': 63, 'end': 67, 'probability': 0.999158304648045}]}}]}]
    ```

  - è‹±æ–‡æ¨¡å‹zero-shotæ–¹å¼**æš‚ä¸æ”¯æŒäº‹ä»¶æŠ½å–**ï¼Œå¦‚æœ‰è‹±æ–‡äº‹ä»¶æŠ½å–ç›¸å…³è¯­æ–™è¯·è¿›è¡Œè®­ç»ƒå®šåˆ¶ã€‚

#### è¯„è®ºè§‚ç‚¹æŠ½å–

  è¯„è®ºè§‚ç‚¹æŠ½å–ï¼Œæ˜¯æŒ‡æŠ½å–æ–‡æœ¬ä¸­åŒ…å«çš„è¯„ä»·ç»´åº¦ã€è§‚ç‚¹è¯ã€‚

  - ä¾‹å¦‚æŠ½å–çš„ç›®æ ‡æ˜¯æ–‡æœ¬ä¸­åŒ…å«çš„è¯„ä»·ç»´åº¦åŠå…¶å¯¹åº”çš„è§‚ç‚¹è¯å’Œæƒ…æ„Ÿå€¾å‘ï¼Œschemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    {
      'è¯„ä»·ç»´åº¦': [
        'è§‚ç‚¹è¯',
        'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]'
      ]
    }
    ```

    è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = {'è¯„ä»·ç»´åº¦': ['è§‚ç‚¹è¯', 'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]']} # Define the schema for opinion extraction
    >>> ie.set_schema(schema) # Reset schema
    >>> pprint(ie("åº—é¢å¹²å‡€ï¼Œå¾ˆæ¸…é™ï¼ŒæœåŠ¡å‘˜æœåŠ¡çƒ­æƒ…ï¼Œæ€§ä»·æ¯”å¾ˆé«˜ï¼Œå‘ç°æ”¶é“¶å°æœ‰æ’é˜Ÿ")) # Better print results using pprint
    [{'è¯„ä»·ç»´åº¦': [{'end': 20,
                'probability': 0.9817040258681473,
                'relations': {'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]': [{'probability': 0.9966142505350533,
                                              'text': 'æ­£å‘'}],
                              'è§‚ç‚¹è¯': [{'end': 22,
                                      'probability': 0.957396472711558,
                                      'start': 21,
                                      'text': 'é«˜'}]},
                'start': 17,
                'text': 'æ€§ä»·æ¯”'},
              {'end': 2,
                'probability': 0.9696849569741168,
                'relations': {'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]': [{'probability': 0.9982153274927796,
                                              'text': 'æ­£å‘'}],
                              'è§‚ç‚¹è¯': [{'end': 4,
                                      'probability': 0.9945318044652538,
                                      'start': 2,
                                      'text': 'å¹²å‡€'}]},
                'start': 0,
                'text': 'åº—é¢'}]}]
    ```

  - è‹±æ–‡æ¨¡å‹schemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    {
      'Aspect': [
        'Opinion',
        'Sentiment classification [negative, positive]'
      ]
    }
    ```

    è‹±æ–‡æ¨¡å‹è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = [{'Aspect': ['Opinion', 'Sentiment classification [negative, positive]']}]
    >>> ie_en.set_schema(schema)
    >>> pprint(ie_en("The teacher is very nice."))
    [{'Aspect': [{'end': 11,
                  'probability': 0.4301476415932193,
                  'relations': {'Opinion': [{'end': 24,
                                            'probability': 0.9072940447883724,
                                            'start': 15,
                                            'text': 'very nice'}],
                                'Sentiment classification [negative, positive]': [{'probability': 0.9998571920670685,
                                                                                  'text': 'positive'}]},
                  'start': 4,
                  'text': 'teacher'}]}]
    ```

#### æƒ…æ„Ÿåˆ†ç±»

  - å¥å­çº§æƒ…æ„Ÿå€¾å‘åˆ†ç±»ï¼Œå³åˆ¤æ–­å¥å­çš„æƒ…æ„Ÿå€¾å‘æ˜¯â€œæ­£å‘â€è¿˜æ˜¯â€œè´Ÿå‘â€ï¼Œschemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]'
    ```

    è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = 'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]' # Define the schema for sentence-level sentiment classification
    >>> ie.set_schema(schema) # Reset schema
    >>> ie('è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢')
    [{'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]': [{'text': 'æ­£å‘', 'probability': 0.9988661643929895}]}]
    ```

    è‹±æ–‡æ¨¡å‹schemaæ„é€ å¦‚ä¸‹ï¼š

    ```text
    'æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]'
    ```

    è‹±æ–‡æ¨¡å‹è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = 'Sentiment classification [negative, positive]'
    >>> ie_en.set_schema(schema)
    >>> ie_en('I am sorry but this is the worst film I have ever seen in my life.')
    [{'Sentiment classification [negative, positive]': [{'text': 'negative', 'probability': 0.9998415771287057}]}]
    ```

#### è·¨ä»»åŠ¡æŠ½å–

  - ä¾‹å¦‚åœ¨æ³•å¾‹åœºæ™¯åŒæ—¶å¯¹æ–‡æœ¬è¿›è¡Œå®ä½“æŠ½å–å’Œå…³ç³»æŠ½å–ï¼Œschemaå¯æŒ‰ç…§å¦‚ä¸‹æ–¹å¼è¿›è¡Œæ„é€ ï¼š

    ```text
    [
      "æ³•é™¢",
      {
          "åŸå‘Š": "å§”æ‰˜ä»£ç†äºº"
      },
      {
          "è¢«å‘Š": "å§”æ‰˜ä»£ç†äºº"
      }
    ]
    ```

    è°ƒç”¨ç¤ºä¾‹ï¼š

    ```python
    >>> schema = ['æ³•é™¢', {'åŸå‘Š': 'å§”æ‰˜ä»£ç†äºº'}, {'è¢«å‘Š': 'å§”æ‰˜ä»£ç†äºº'}]
    >>> ie.set_schema(schema)
    >>> pprint(ie("åŒ—äº¬å¸‚æµ·æ·€åŒºäººæ°‘æ³•é™¢\næ°‘äº‹åˆ¤å†³ä¹¦\n(199x)å»ºåˆå­—ç¬¬xxxå·\nåŸå‘Šï¼šå¼ ä¸‰ã€‚\nå§”æ‰˜ä»£ç†äººæå››ï¼ŒåŒ—äº¬å¸‚ Aå¾‹å¸ˆäº‹åŠ¡æ‰€å¾‹å¸ˆã€‚\nè¢«å‘Šï¼šBå…¬å¸ï¼Œæ³•å®šä»£è¡¨äººç‹äº”ï¼Œå¼€å‘å…¬å¸æ€»ç»ç†ã€‚\nå§”æ‰˜ä»£ç†äººèµµå…­ï¼ŒåŒ—äº¬å¸‚ Cå¾‹å¸ˆäº‹åŠ¡æ‰€å¾‹å¸ˆã€‚")) # Better print results using pprint
    [{'åŸå‘Š': [{'end': 37,
              'probability': 0.9949814024296764,
              'relations': {'å§”æ‰˜ä»£ç†äºº': [{'end': 46,
                                      'probability': 0.7956844697990384,
                                      'start': 44,
                                      'text': 'æå››'}]},
              'start': 35,
              'text': 'å¼ ä¸‰'}],
      'æ³•é™¢': [{'end': 10,
              'probability': 0.9221074192336651,
              'start': 0,
              'text': 'åŒ—äº¬å¸‚æµ·æ·€åŒºäººæ°‘æ³•é™¢'}],
      'è¢«å‘Š': [{'end': 67,
              'probability': 0.8437349536631089,
              'relations': {'å§”æ‰˜ä»£ç†äºº': [{'end': 92,
                                      'probability': 0.7267121388225029,
                                      'start': 90,
                                      'text': 'èµµå…­'}]},
              'start': 64,
              'text': 'Bå…¬å¸'}]}]
    ```

#### æ¨¡å‹é€‰æ‹©

- å¤šæ¨¡å‹é€‰æ‹©ï¼Œæ»¡è¶³ç²¾åº¦ã€é€Ÿåº¦è¦æ±‚

  | æ¨¡å‹ |  ç»“æ„  | è¯­è¨€ |
  | :---: | :--------: | :--------: |
  | `uie-base` (é»˜è®¤)| 12-layers, 768-hidden, 12-heads | ä¸­æ–‡ |
  | `uie-base-en` | 12-layers, 768-hidden, 12-heads | è‹±æ–‡ |
  | `uie-medical-base` | 12-layers, 768-hidden, 12-heads | ä¸­æ–‡ |
  | `uie-medium`| 6-layers, 768-hidden, 12-heads | ä¸­æ–‡ |
  | `uie-mini`| 6-layers, 384-hidden, 12-heads | ä¸­æ–‡ |
  | `uie-micro`| 4-layers, 384-hidden, 12-heads | ä¸­æ–‡ |
  | `uie-nano`| 4-layers, 312-hidden, 12-heads | ä¸­æ–‡ |
  | `uie-m-large`| 24-layers, 1024-hidden, 16-heads | ä¸­ã€è‹±æ–‡ |
  | `uie-m-base`| 12-layers, 768-hidden, 12-heads | ä¸­ã€è‹±æ–‡ |

- `uie-nano`è°ƒç”¨ç¤ºä¾‹ï¼š

  ```python
  >>> from paddlenlp import Taskflow

  >>> schema = ['æ—¶é—´', 'é€‰æ‰‹', 'èµ›äº‹åç§°']
  >>> ie = Taskflow('information_extraction', schema=schema, model="uie-nano")
  >>> ie("2æœˆ8æ—¥ä¸ŠåˆåŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›ä¸­ä¸­å›½é€‰æ‰‹è°·çˆ±å‡Œä»¥188.25åˆ†è·å¾—é‡‘ç‰Œï¼")
  [{'æ—¶é—´': [{'text': '2æœˆ8æ—¥ä¸Šåˆ', 'start': 0, 'end': 6, 'probability': 0.6513581678349247}], 'é€‰æ‰‹': [{'text': 'è°·çˆ±å‡Œ', 'start': 28, 'end': 31, 'probability': 0.9819330659468051}], 'èµ›äº‹åç§°': [{'text': 'åŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›', 'start': 6, 'end': 23, 'probability': 0.4908131110420939}]}]
  ```

- `uie-m-base`å’Œ`uie-m-large`æ”¯æŒä¸­è‹±æ–‡æ··åˆæŠ½å–ï¼Œè°ƒç”¨ç¤ºä¾‹ï¼š

  ```python
  >>> from pprint import pprint
  >>> from paddlenlp import Taskflow

  >>> schema = ['Time', 'Player', 'Competition', 'Score']
  >>> ie = Taskflow('information_extraction', schema=schema, model="uie-m-base", schema_lang="en")
  >>> pprint(ie(["2æœˆ8æ—¥ä¸ŠåˆåŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›ä¸­ä¸­å›½é€‰æ‰‹è°·çˆ±å‡Œä»¥188.25åˆ†è·å¾—é‡‘ç‰Œï¼", "Rafael Nadal wins French Open Final!"]))
  [{'Competition': [{'end': 23,
                    'probability': 0.9373889907291257,
                    'start': 6,
                    'text': 'åŒ—äº¬å†¬å¥¥ä¼šè‡ªç”±å¼æ»‘é›ªå¥³å­å¤§è·³å°å†³èµ›'}],
    'Player': [{'end': 31,
                'probability': 0.6981119555336441,
                'start': 28,
                'text': 'è°·çˆ±å‡Œ'}],
    'Score': [{'end': 39,
              'probability': 0.9888507878270296,
              'start': 32,
              'text': '188.25åˆ†'}],
    'Time': [{'end': 6,
              'probability': 0.9784080036931151,
              'start': 0,
              'text': '2æœˆ8æ—¥ä¸Šåˆ'}]},
  {'Competition': [{'end': 35,
                    'probability': 0.9851549932171295,
                    'start': 18,
                    'text': 'French Open Final'}],
    'Player': [{'end': 12,
                'probability': 0.9379371275888104,
                'start': 0,
                'text': 'Rafael Nadal'}]}]
  ```

#### å®šåˆ¶è®­ç»ƒ

å¯¹äºç®€å•çš„æŠ½å–ç›®æ ‡å¯ä»¥ç›´æ¥ä½¿ç”¨```paddlenlp.Taskflow```å®ç°é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æŠ½å–ï¼Œå¯¹äºç»†åˆ†åœºæ™¯æˆ‘ä»¬æ¨èä½¿ç”¨[å®šåˆ¶è®­ç»ƒ](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/uie)ï¼ˆæ ‡æ³¨å°‘é‡æ•°æ®è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼‰ä»¥è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚

æˆ‘ä»¬åœ¨äº’è”ç½‘ã€åŒ»ç–—ã€é‡‘èä¸‰å¤§å‚ç±»è‡ªå»ºæµ‹è¯•é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼š

<table>
<tr><th row_span='2'><th colspan='2'>é‡‘è<th colspan='2'>åŒ»ç–—<th colspan='2'>äº’è”ç½‘
<tr><td><th>0-shot<th>5-shot<th>0-shot<th>5-shot<th>0-shot<th>5-shot
<tr><td>uie-base (12L768H)<td>46.43<td>70.92<td><b>71.83</b><td>85.72<td>78.33<td>81.86
<tr><td>uie-medium (6L768H)<td>41.11<td>64.53<td>65.40<td>75.72<td>78.32<td>79.68
<tr><td>uie-mini (6L384H)<td>37.04<td>64.65<td>60.50<td>78.36<td>72.09<td>76.38
<tr><td>uie-micro (4L384H)<td>37.53<td>62.11<td>57.04<td>75.92<td>66.00<td>70.22
<tr><td>uie-nano (4L312H)<td>38.94<td>66.83<td>48.29<td>76.74<td>62.86<td>72.35
<tr><td>uie-m-large (24L1024H)<td><b>49.35</b><td><b>74.55</b><td>70.50<td><b>92.66</b><td><b>78.49</b><td><b>83.02</b>
<tr><td>uie-m-base (12L768H)<td>38.46<td>74.31<td>63.37<td>87.32<td>76.27<td>80.13
</table>

0-shotè¡¨ç¤ºæ— è®­ç»ƒæ•°æ®ç›´æ¥é€šè¿‡```paddlenlp.Taskflow```è¿›è¡Œé¢„æµ‹ï¼Œ5-shotè¡¨ç¤ºæ¯ä¸ªç±»åˆ«åŒ…å«5æ¡æ ‡æ³¨æ•°æ®è¿›è¡Œæ¨¡å‹å¾®è°ƒã€‚**å®éªŒè¡¨æ˜UIEåœ¨å‚ç±»åœºæ™¯å¯ä»¥é€šè¿‡å°‘é‡æ•°æ®ï¼ˆfew-shotï¼‰è¿›ä¸€æ­¥æå‡æ•ˆæœ**ã€‚

#### å¯é…ç½®å‚æ•°è¯´æ˜

* `schema`ï¼šå®šä¹‰ä»»åŠ¡æŠ½å–ç›®æ ‡ï¼Œå¯å‚è€ƒå¼€ç®±å³ç”¨ä¸­ä¸åŒä»»åŠ¡çš„è°ƒç”¨ç¤ºä¾‹è¿›è¡Œé…ç½®ã€‚
* `schema_lang`ï¼šè®¾ç½®schemaçš„è¯­è¨€ï¼Œé»˜è®¤ä¸º`zh`, å¯é€‰æœ‰`zh`å’Œ`en`ã€‚å› ä¸ºä¸­è‹±schemaçš„æ„é€ æœ‰æ‰€ä¸åŒï¼Œå› æ­¤éœ€è¦æŒ‡å®šschemaçš„è¯­è¨€ã€‚è¯¥å‚æ•°åªå¯¹`uie-m-base`å’Œ`uie-m-large`æ¨¡å‹æœ‰æ•ˆã€‚
* `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼Œè¯·ç»“åˆæœºå™¨æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé»˜è®¤ä¸º1ã€‚
* `model`ï¼šé€‰æ‹©ä»»åŠ¡ä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º`uie-base`ï¼Œå¯é€‰æœ‰`uie-base`, `uie-medium`, `uie-mini`, `uie-micro`, `uie-nano`, `uie-medical-base`, `uie-base-en`ã€‚
* `position_prob`ï¼šæ¨¡å‹å¯¹äºspançš„èµ·å§‹ä½ç½®/ç»ˆæ­¢ä½ç½®çš„ç»“æœæ¦‚ç‡0~1ä¹‹é—´ï¼Œè¿”å›ç»“æœå»æ‰å°äºè¿™ä¸ªé˜ˆå€¼çš„ç»“æœï¼Œé»˜è®¤ä¸º0.5ï¼Œspançš„æœ€ç»ˆæ¦‚ç‡è¾“å‡ºä¸ºèµ·å§‹ä½ç½®æ¦‚ç‡å’Œç»ˆæ­¢ä½ç½®æ¦‚ç‡çš„ä¹˜ç§¯ã€‚
* `precision`ï¼šé€‰æ‹©æ¨¡å‹ç²¾åº¦ï¼Œé»˜è®¤ä¸º`fp32`ï¼Œå¯é€‰æœ‰`fp16`å’Œ`fp32`ã€‚`fp16`æ¨ç†é€Ÿåº¦æ›´å¿«ã€‚å¦‚æœé€‰æ‹©`fp16`ï¼Œè¯·å…ˆç¡®ä¿æœºå™¨æ­£ç¡®å®‰è£…NVIDIAç›¸å…³é©±åŠ¨å’ŒåŸºç¡€è½¯ä»¶ï¼Œ**ç¡®ä¿CUDA>=11.2ï¼ŒcuDNN>=8.1.1**ï¼Œåˆæ¬¡ä½¿ç”¨éœ€æŒ‰ç…§æç¤ºå®‰è£…ç›¸å…³ä¾èµ–(ä¸»è¦æ˜¯**ç¡®ä¿å®‰è£…onnxruntime-gpu**)ã€‚å…¶æ¬¡ï¼Œéœ€è¦ç¡®ä¿GPUè®¾å¤‡çš„CUDAè®¡ç®—èƒ½åŠ›ï¼ˆCUDA Compute Capabilityï¼‰å¤§äº7.0ï¼Œå…¸å‹çš„è®¾å¤‡åŒ…æ‹¬V100ã€T4ã€A10ã€A100ã€GTX 20ç³»åˆ—å’Œ30ç³»åˆ—æ˜¾å¡ç­‰ã€‚æ›´å¤šå…³äºCUDA Compute Capabilityå’Œç²¾åº¦æ”¯æŒæƒ…å†µè¯·å‚è€ƒNVIDIAæ–‡æ¡£ï¼š[GPUç¡¬ä»¶ä¸æ”¯æŒç²¾åº¦å¯¹ç…§è¡¨](https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-840-ea/support-matrix/index.html#hardware-precision-matrix)ã€‚
</div></details>


### æ–‡æœ¬çº é”™
<details><summary>&emsp;èåˆæ‹¼éŸ³ç‰¹å¾çš„ç«¯åˆ°ç«¯æ–‡æœ¬çº é”™æ¨¡å‹ERNIE-CSC</summary><div>


#### æ”¯æŒå•æ¡ã€æ‰¹é‡é¢„æµ‹

```python
>>> from paddlenlp import Taskflow
>>> corrector = Taskflow("text_correction")
# å•æ¡è¾“å…¥
>>> corrector('é‡åˆ°é€†ç«Ÿæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ã€‚')
[{'source': 'é‡åˆ°é€†ç«Ÿæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ã€‚', 'target': 'é‡åˆ°é€†å¢ƒæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ã€‚', 'errors': [{'position': 3, 'correction': {'ç«Ÿ': 'å¢ƒ'}}]}]

# æ‰¹é‡é¢„æµ‹
>>> corrector(['é‡åˆ°é€†ç«Ÿæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ã€‚', 'äººç”Ÿå°±æ˜¯å¦‚æ­¤ï¼Œç»è¿‡ç£¨ç»ƒæ‰èƒ½è®©è‡ªå·±æ›´åŠ æ‹™å£®ï¼Œæ‰èƒ½ä½¿è‡ªå·±æ›´åŠ ä¹è§‚ã€‚'])
[{'source': 'é‡åˆ°é€†ç«Ÿæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ã€‚', 'target': 'é‡åˆ°é€†å¢ƒæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å‹‡äºé¢å¯¹ï¼Œè€Œä¸”è¦æ„ˆæŒ«æ„ˆå‹‡ã€‚', 'errors': [{'position': 3, 'correction': {'ç«Ÿ': 'å¢ƒ'}}]}, {'source': 'äººç”Ÿå°±æ˜¯å¦‚æ­¤ï¼Œç»è¿‡ç£¨ç»ƒæ‰èƒ½è®©è‡ªå·±æ›´åŠ æ‹™å£®ï¼Œæ‰èƒ½ä½¿è‡ªå·±æ›´åŠ ä¹è§‚ã€‚', 'target': 'äººç”Ÿå°±æ˜¯å¦‚æ­¤ï¼Œç»è¿‡ç£¨ç»ƒæ‰èƒ½è®©è‡ªå·±æ›´åŠ èŒå£®ï¼Œæ‰èƒ½ä½¿è‡ªå·±æ›´åŠ ä¹è§‚ã€‚', 'errors': [{'position': 18, 'correction': {'æ‹™': 'èŒ'}}]}]
```

#### å¯é…ç½®å‚æ•°è¯´æ˜
* `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼Œè¯·ç»“åˆæœºå™¨æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé»˜è®¤ä¸º1ã€‚
* `task_path`ï¼šè‡ªå®šä¹‰ä»»åŠ¡è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneã€‚
</div></details>

### æ–‡æœ¬ç›¸ä¼¼åº¦
<details><summary>&emsp;åŸºäºç™¾ä¸‡é‡çº§Dureader Retrievalæ•°æ®é›†è®­ç»ƒRocketQAå¹¶è¾¾åˆ°å‰æ²¿æ–‡æœ¬ç›¸ä¼¼æ•ˆæœ</summary><div>

#### å•æ¡è¾“å…¥

+ Query-Queryçš„ç›¸ä¼¼åº¦åŒ¹é…

```python
>>> from paddlenlp import Taskflow
>>> similarity = Taskflow("text_similarity")
>>> similarity([["æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèŠ±ï¼Ÿ", "æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèœï¼Ÿ"]])
[{'text1': 'æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèŠ±ï¼Ÿ', 'text2': 'æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèœï¼Ÿ', 'similarity': 0.83402544}]
```

+ Query-Passageçš„ç›¸ä¼¼åº¦åŒ¹é…

```python
>>> similarity = Taskflow("text_similarity", model='rocketqa-base-cross-encoder')
>>> similarity([["å›½å®¶æ³•å®šèŠ‚å‡æ—¥å…±å¤šå°‘å¤©?", "ç°åœ¨æ³•å®šå‡æ—¥æ˜¯å…ƒæ—¦1å¤©ï¼Œæ˜¥èŠ‚3å¤©ï¼Œæ¸…æ˜èŠ‚1å¤©ï¼Œäº”ä¸€åŠ³åŠ¨èŠ‚1å¤©ï¼Œç«¯åˆèŠ‚1å¤©ï¼Œå›½åº†èŠ‚3å¤©ï¼Œä¸­ç§‹èŠ‚1å¤©ï¼Œå…±è®¡11å¤©ã€‚æ³•å®šä¼‘æ¯æ—¥æ¯å¹´52ä¸ªå‘¨æœ«æ€»å…±104å¤©ã€‚åˆåˆ°ä¸€èµ·æ€»è®¡115å¤©ã€‚"]])
[{'text1': 'å›½å®¶æ³•å®šèŠ‚å‡æ—¥å…±å¤šå°‘å¤©?', 'text2': 'ç°åœ¨æ³•å®šå‡æ—¥æ˜¯å…ƒæ—¦1å¤©ï¼Œæ˜¥èŠ‚3å¤©ï¼Œæ¸…æ˜èŠ‚1å¤©ï¼Œäº”ä¸€åŠ³åŠ¨èŠ‚1å¤©ï¼Œç«¯åˆèŠ‚1å¤©ï¼Œå›½åº†èŠ‚3å¤©ï¼Œä¸­ç§‹èŠ‚1å¤©ï¼Œå…±è®¡11å¤©ã€‚æ³•å®šä¼‘æ¯æ—¥æ¯å¹´52ä¸ªå‘¨æœ«æ€»å…±104å¤©ã€‚åˆåˆ°ä¸€èµ·æ€»è®¡115å¤©ã€‚', 'similarity': 0.7174624800682068}]
```

#### æ‰¹é‡æ ·æœ¬è¾“å…¥ï¼Œå¹³å‡é€Ÿåº¦æ›´å¿«

+ Query-Queryçš„ç›¸ä¼¼åº¦åŒ¹é…

```python
>>> from paddlenlp import Taskflow
>>> similarity = Taskflow("text_similarity")
>>> similarity([['æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèŠ±ï¼Ÿ','æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèœï¼Ÿ'],['è°æœ‰ç‹‚ä¸‰è¿™å¼ é«˜æ¸…çš„','è¿™å¼ é«˜æ¸…å›¾ï¼Œè°æœ‰']])
[{'text1': 'æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèŠ±ï¼Ÿ', 'text2': 'æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèœï¼Ÿ', 'similarity': 0.83402544}, {'text1': 'è°æœ‰ç‹‚ä¸‰è¿™å¼ é«˜æ¸…çš„', 'text2': 'è¿™å¼ é«˜æ¸…å›¾ï¼Œè°æœ‰', 'similarity': 0.6540646}]
```

+ Query-Passageçš„ç›¸ä¼¼åº¦åŒ¹é…

```python
>>> similarity = Taskflow("text_similarity", model='rocketqa-base-cross-encoder')
>>> similarity([["å›½å®¶æ³•å®šèŠ‚å‡æ—¥å…±å¤šå°‘å¤©?", "ç°åœ¨æ³•å®šå‡æ—¥æ˜¯å…ƒæ—¦1å¤©ï¼Œæ˜¥èŠ‚3å¤©ï¼Œæ¸…æ˜èŠ‚1å¤©ï¼Œäº”ä¸€åŠ³åŠ¨èŠ‚1å¤©ï¼Œç«¯åˆèŠ‚1å¤©ï¼Œå›½åº†èŠ‚3å¤©ï¼Œä¸­ç§‹èŠ‚1å¤©ï¼Œå…±è®¡11å¤©ã€‚æ³•å®šä¼‘æ¯æ—¥æ¯å¹´52ä¸ªå‘¨æœ«æ€»å…±104å¤©ã€‚åˆåˆ°ä¸€èµ·æ€»è®¡115å¤©ã€‚"],["è¡¡é‡é…’æ°´çš„ä»·æ ¼çš„å› ç´ æœ‰å“ªäº›?", "è¡¡é‡é…’æ°´çš„ä»·æ ¼çš„å› ç´ å¾ˆå¤šçš„ï¼Œé…’æ°´çš„è¡€ç»Ÿ(ä¹Ÿå°±æ˜¯é‚£é‡Œäº§çš„ï¼Œé‡‡ç”¨ä»€ä¹ˆå·¥è‰ºç­‰ï¼‰ï¼›å­˜å‚¨çš„æ—¶é—´ç­‰ç­‰ï¼Œé…’æ°´æ˜¯ä¸€ä»¶å¾ˆéš¾æ ‡å‡†åŒ–å¾—å•†å“ï¼Œåªè¦ä½ æ•¢è¦ä»·ï¼Œæœ‰ä¹°çš„é‚£å°±å€¼é‚£ä¸ªé’±ã€‚"]])
[{'text1': 'å›½å®¶æ³•å®šèŠ‚å‡æ—¥å…±å¤šå°‘å¤©?', 'text2': 'ç°åœ¨æ³•å®šå‡æ—¥æ˜¯å…ƒæ—¦1å¤©ï¼Œæ˜¥èŠ‚3å¤©ï¼Œæ¸…æ˜èŠ‚1å¤©ï¼Œäº”ä¸€åŠ³åŠ¨èŠ‚1å¤©ï¼Œç«¯åˆèŠ‚1å¤©ï¼Œå›½åº†èŠ‚3å¤©ï¼Œä¸­ç§‹èŠ‚1å¤©ï¼Œå…±è®¡11å¤©ã€‚æ³•å®šä¼‘æ¯æ—¥æ¯å¹´52ä¸ªå‘¨æœ«æ€»å…±104å¤©ã€‚åˆåˆ°ä¸€èµ·æ€»è®¡115å¤©ã€‚', 'similarity': 0.7174624800682068}, {'text1': 'è¡¡é‡é…’æ°´çš„ä»·æ ¼çš„å› ç´ æœ‰å“ªäº›?', 'text2': 'è¡¡é‡é…’æ°´çš„ä»·æ ¼çš„å› ç´ å¾ˆå¤šçš„ï¼Œé…’æ°´çš„è¡€ç»Ÿ(ä¹Ÿå°±æ˜¯é‚£é‡Œäº§çš„ï¼Œé‡‡ç”¨ä»€ä¹ˆå·¥è‰ºç­‰ï¼‰ï¼›å­˜å‚¨çš„æ—¶é—´ç­‰ç­‰ï¼Œé…’æ°´æ˜¯ä¸€ä»¶å¾ˆéš¾æ ‡å‡†åŒ–å¾—å•†å“ï¼Œåªè¦ä½ æ•¢è¦ä»·ï¼Œæœ‰ä¹°çš„é‚£å°±å€¼é‚£ä¸ªé’±ã€‚', 'similarity': 0.9069755673408508}]

```

#### æ¨¡å‹é€‰æ‹©

- å¤šæ¨¡å‹é€‰æ‹©ï¼Œæ»¡è¶³ç²¾åº¦ã€é€Ÿåº¦è¦æ±‚

  | æ¨¡å‹ |  ç»“æ„  | è¯­è¨€ |
  | :---: | :--------: | :--------: |
  | `rocketqa-zh-dureader-cross-encoder`       | 12-layers, 768-hidden, 12-heads | ä¸­æ–‡ |
  | `simbert-base-chinese` (é»˜è®¤)               | 12-layers, 768-hidden, 12-heads | ä¸­æ–‡ |
  | `rocketqa-base-cross-encoder`              | 12-layers, 768-hidden, 12-heads | ä¸­æ–‡ |
  | `rocketqa-medium-cross-encoder`            | 6-layers, 768-hidden, 12-heads | ä¸­æ–‡ |
  | `rocketqa-mini-cross-encoder`              | 6-layers, 384-hidden, 12-heads | ä¸­æ–‡ |
  | `rocketqa-micro-cross-encoder`             | 4-layers, 384-hidden, 12-heads | ä¸­æ–‡ |
  | `rocketqa-nano-cross-encoder`              | 4-layers, 312-hidden, 12-heads | ä¸­æ–‡ |
  | `rocketqav2-en-marco-cross-encoder`        | 12-layers, 768-hidden, 12-heads | è‹±æ–‡ |


#### å¯é…ç½®å‚æ•°è¯´æ˜
* `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼Œè¯·ç»“åˆæœºå™¨æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé»˜è®¤ä¸º1ã€‚
* `max_seq_len`ï¼šæœ€å¤§åºåˆ—é•¿åº¦ï¼Œé»˜è®¤ä¸º384ã€‚
* `task_path`ï¼šè‡ªå®šä¹‰ä»»åŠ¡è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneã€‚
</div></details>

### æƒ…æ„Ÿåˆ†æ
<details><summary>&emsp;é›†æˆBiLSTMã€SKEPã€UIEç­‰æ¨¡å‹ï¼Œæ”¯æŒè¯„è®ºç»´åº¦ã€è§‚ç‚¹æŠ½å–ã€æƒ…æ„Ÿææ€§åˆ†ç±»ç­‰æƒ…æ„Ÿåˆ†æä»»åŠ¡ </summary><div>

#### æ”¯æŒä¸åŒæ¨¡å‹ï¼Œé€Ÿåº¦å¿«å’Œç²¾åº¦é«˜ä¸¤ç§æ¨¡å¼

```python
>>> from paddlenlp import Taskflow
# é»˜è®¤ä½¿ç”¨bilstmæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œé€Ÿåº¦å¿«
>>> senta = Taskflow("sentiment_analysis")
>>> senta("è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢")
[{'text': 'è¿™ä¸ªäº§å“ç”¨èµ·æ¥çœŸçš„å¾ˆæµç•…ï¼Œæˆ‘éå¸¸å–œæ¬¢', 'label': 'positive', 'score': 0.9938690066337585}]

# ä½¿ç”¨SKEPæƒ…æ„Ÿåˆ†æé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œç²¾åº¦é«˜
>>> senta = Taskflow("sentiment_analysis", model="skep_ernie_1.0_large_ch")
>>> senta("ä½œä¸ºè€çš„å››æ˜Ÿé…’åº—ï¼Œæˆ¿é—´ä¾ç„¶å¾ˆæ•´æ´ï¼Œç›¸å½“ä¸é”™ã€‚æœºåœºæ¥æœºæœåŠ¡å¾ˆå¥½ï¼Œå¯ä»¥åœ¨è½¦ä¸ŠåŠç†å…¥ä½æ‰‹ç»­ï¼ŒèŠ‚çœæ—¶é—´ã€‚")
[{'text': 'ä½œä¸ºè€çš„å››æ˜Ÿé…’åº—ï¼Œæˆ¿é—´ä¾ç„¶å¾ˆæ•´æ´ï¼Œç›¸å½“ä¸é”™ã€‚æœºåœºæ¥æœºæœåŠ¡å¾ˆå¥½ï¼Œå¯ä»¥åœ¨è½¦ä¸ŠåŠç†å…¥ä½æ‰‹ç»­ï¼ŒèŠ‚çœæ—¶é—´ã€‚', 'label': 'positive', 'score': 0.984320878982544}]

# ä½¿ç”¨UIEæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œå…·æœ‰è¾ƒå¼ºçš„æ ·æœ¬è¿ç§»èƒ½åŠ›
# 1. è¯­å¥çº§æƒ…æ„Ÿåˆ†æ
>>> schema = ['æƒ…æ„Ÿå€¾å‘[æ­£å‘ï¼Œè´Ÿå‘]']
>>> senta = Taskflow("sentiment_analysis", model="uie-senta-base", schema=schema)
>>> senta('è›‹ç³•å‘³é“ä¸é”™ï¼Œåº—å®¶æœåŠ¡ä¹Ÿå¾ˆå¥½')
[{'æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘]': [{'text': 'æ­£å‘', 'probability': 0.996646058824652}]}]

# 2. è¯„ä»·ç»´åº¦çº§æƒ…æ„Ÿåˆ†æ
>>> # Aspect Term Extraction
>>> # schema =  ["è¯„ä»·ç»´åº¦"]
>>> # Aspect - Opinion Extraction
>>> # schema =  [{"è¯„ä»·ç»´åº¦":["è§‚ç‚¹è¯"]}]
>>> # Aspect - Sentiment Extraction
>>> # schema =  [{"è¯„ä»·ç»´åº¦":["æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]"]}]
>>> # Aspect - Sentiment - Opinion Extraction
>>> schema =  [{"è¯„ä»·ç»´åº¦":["è§‚ç‚¹è¯", "æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]"]}]

>>> senta = Taskflow("sentiment_analysis", model="uie-senta-base", schema=schema)
>>> senta('è›‹ç³•å‘³é“ä¸é”™ï¼Œåº—å®¶æœåŠ¡ä¹Ÿå¾ˆçƒ­æƒ…')
[{'è¯„ä»·ç»´åº¦': [{'text': 'æœåŠ¡', 'start': 9, 'end': 11, 'probability': 0.9709093024793489, 'relations': { 'è§‚ç‚¹è¯': [{'text': 'çƒ­æƒ…', 'start': 13, 'end': 15, 'probability': 0.9897222206316556}], 'æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]': [{'text': 'æ­£å‘', 'probability': 0.9999327669598301}]}}, {'text': 'å‘³é“', 'start': 2, 'end': 4, 'probability': 0.9105472387838915, 'relations': {'è§‚ç‚¹è¯': [{'text': 'ä¸é”™', 'start': 4, 'end': 6, 'probability': 0.9946981266891619}], 'æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]': [{'text': 'æ­£å‘', 'probability': 0.9998829392709467}]}}]}]
```

#### æ‰¹é‡æ ·æœ¬è¾“å…¥ï¼Œå¹³å‡é€Ÿåº¦æ›´å¿«
```python
>>> from paddlenlp import Taskflow
>>> schema =  [{"è¯„ä»·ç»´åº¦":["è§‚ç‚¹è¯", "æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]"]}]
>>> senta = Taskflow("sentiment_analysis", model="uie-senta-base", schema=schema)
>>> senta(["æˆ¿é—´ä¸å¤§ï¼Œå¾ˆå¹²å‡€", "è€æ¿æœåŠ¡çƒ­æƒ…ï¼Œä»·æ ¼ä¹Ÿä¾¿å®œ"])
[{'è¯„ä»·ç»´åº¦': [{'text': 'æˆ¿é—´', 'start': 0, 'end': 2, 'probability': 0.998526653966298, 'relations': {'è§‚ç‚¹è¯': [{'text': 'å¹²å‡€', 'start': 6, 'end': 8, 'probability': 0.9899580841973474}, {'text': 'ä¸å¤§', 'start': 2, 'end': 4, 'probability': 0.9945525066163512}], 'æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]': [{'text': 'æ­£å‘', 'probability': 0.6077412795680956}]}}]}, {'è¯„ä»·ç»´åº¦': [{'text': 'æœåŠ¡', 'start': 2, 'end': 4, 'probability': 0.9913965811617516, 'relations': {'è§‚ç‚¹è¯': [{'text': 'çƒ­æƒ…', 'start': 4, 'end': 6, 'probability': 0.9995530034336753}], 'æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]': [{'text': 'æ­£å‘', 'probability': 0.9956709542206106}]}}, {'text': 'ä»·æ ¼', 'start': 7, 'end': 9, 'probability': 0.9970075537913772, 'relations': {'è§‚ç‚¹è¯': [{'text': 'ä¾¿å®œ', 'start': 10, 'end': 12, 'probability': 0.9991568497876635}], 'æƒ…æ„Ÿå€¾å‘[æ­£å‘,è´Ÿå‘,æœªæåŠ]': [{'text': 'æ­£å‘', 'probability': 0.9943191048602245}]}}]}]
```

#### å¯é…ç½®å‚æ•°è¯´æ˜
* `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼Œè¯·ç»“åˆæœºå™¨æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé»˜è®¤ä¸º1ã€‚
* `model`ï¼šé€‰æ‹©ä»»åŠ¡ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¯é€‰æœ‰`bilstm`,`skep_ernie_1.0_large_ch`,`uie-senta-base`,`uie-senta-medium`,`uie-senta-mini`,`uie-senta-micro`,`uie-senta-nano`ã€‚
* `task_path`ï¼šè‡ªå®šä¹‰ä»»åŠ¡è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneã€‚
</div></details>

### æ¨¡å‹ç‰¹å¾æå–

<details><summary>&emsp; åŸºäºç™¾åº¦è‡ªç ”ä¸­æ–‡å›¾æ–‡è·¨æ¨¡æ€é¢„è®­ç»ƒæ¨¡å‹ERNIE-ViL 2.0</summary><div>

#### å¤šæ¨¡æ€ç‰¹å¾æå–

```python
>>> from paddlenlp import Taskflow
>>> from PIL import Image
>>> import paddle.nn.functional as F
>>> vision_language= Taskflow("feature_extraction")
# å•æ¡è¾“å…¥
>>> image_embeds = vision_language(Image.open("demo/000000039769.jpg"))
>>> image_embeds["features"]
Tensor(shape=[1, 768], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [[-0.59475428, -0.69795364,  0.22144008,  0.88066685, -0.58184201,
# å•æ¡è¾“å…¥
>>> text_embeds = vision_language("çŒ«çš„ç…§ç‰‡")
>>> text_embeds['features']
Tensor(shape=[1, 768], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [[ 0.04250504, -0.41429776,  0.26163983,  0.29910022,  0.39019185,
         -0.41884750, -0.19893740,  0.44328332,  0.08186490,  0.10953025,
         ......

# å¤šæ¡è¾“å…¥
>>> image_embeds = vision_language([Image.open("demo/000000039769.jpg")])
>>> image_embeds["features"]
Tensor(shape=[1, 768], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [[-0.59475428, -0.69795364,  0.22144008,  0.88066685, -0.58184201,
       ......
# å¤šæ¡è¾“å…¥
>>> text_embeds = vision_language(["çŒ«çš„ç…§ç‰‡","ç‹—çš„ç…§ç‰‡"])
>>> text_embeds["features"]
Tensor(shape=[2, 768], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [[ 0.04250504, -0.41429776,  0.26163983, ...,  0.26221892,
          0.34387422,  0.18779707],
        [ 0.06672225, -0.41456309,  0.13787819, ...,  0.21791610,
          0.36693242,  0.34208685]])
>>> image_features = image_embeds["features"]
>>> text_features = text_embeds["features"]
>>> image_features /= image_features.norm(axis=-1, keepdim=True)
>>> text_features /= text_features.norm(axis=-1, keepdim=True)
>>> logits_per_image = 100 * image_features @ text_features.t()
>>> probs = F.softmax(logits_per_image, axis=-1)
>>> probs
Tensor(shape=[1, 2], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [[0.99833173, 0.00166824]])
```
#### æ¨¡å‹é€‰æ‹©

- å¤šæ¨¡å‹é€‰æ‹©ï¼Œæ»¡è¶³ç²¾åº¦ã€é€Ÿåº¦è¦æ±‚

  | æ¨¡å‹ |  è§†è§‰| æ–‡æœ¬  | è¯­è¨€ |
  | :---: | :--------: | :--------: | :--------: |
  | `PaddlePaddle/ernie_vil-2.0-base-zh` (é»˜è®¤) | ViT | ERNIE | ä¸­æ–‡ |
  | `OFA-Sys/chinese-clip-vit-base-patch16`                     | ViT-B/16 |RoBERTa-wwm-Base| ä¸­æ–‡ |
  | `OFA-Sys/chinese-clip-vit-large-patch14`            | ViT-L/14 | RoBERTa-wwm-Base | ä¸­æ–‡ |
  | `OFA-Sys/chinese-clip-vit-large-patch14-336px`              | ViT-L/14 | RoBERTa-wwm-Base | ä¸­æ–‡ |


#### å¯é…ç½®å‚æ•°è¯´æ˜
* `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼Œè¯·ç»“åˆæœºå™¨æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé»˜è®¤ä¸º1ã€‚
* `_static_mode`ï¼šé™æ€å›¾æ¨¡å¼ï¼Œé»˜è®¤å¼€å¯ã€‚
* `model`ï¼šé€‰æ‹©ä»»åŠ¡ä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º`PaddlePaddle/ernie_vil-2.0-base-zh`ã€‚

#### æ–‡æœ¬ç‰¹å¾æå–

```python
>>> from paddlenlp import Taskflow
>>> import paddle.nn.functional as F
>>> text_encoder = Taskflow("feature_extraction", model='rocketqa-zh-base-query-encoder')
>>> text_embeds = text_encoder(['æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèŠ±ï¼Ÿ','è°æœ‰ç‹‚ä¸‰è¿™å¼ é«˜æ¸…çš„?'])
>>> text_features1 = text_embeds["features"]
>>> text_features1
Tensor(shape=[2, 768], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [[ 0.27640465, -0.13405125,  0.00612330, ..., -0.15600294,
         -0.18932408, -0.03029604],
        [-0.12041329, -0.07424965,  0.07895312, ..., -0.17068857,
          0.04485796, -0.18887770]])
>>> text_embeds = text_encoder('æ˜¥å¤©é€‚åˆç§ä»€ä¹ˆèœï¼Ÿ')
>>> text_features2 = text_embeds["features"]
>>> text_features2
Tensor(shape=[1, 768], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [[ 0.32578075, -0.02398480, -0.18929179, -0.18639392, -0.04062131,
       ......
>>> probs = F.cosine_similarity(text_features1, text_features2)
>>> probs
Tensor(shape=[2], dtype=float32, place=Place(gpu:0), stop_gradient=True,
       [0.86455142, 0.41222256])
```

#### æ¨¡å‹é€‰æ‹©

- å¤šæ¨¡å‹é€‰æ‹©ï¼Œæ»¡è¶³ç²¾åº¦ã€é€Ÿåº¦è¦æ±‚

  | æ¨¡å‹ |  å±‚æ•°| ç»´åº¦  | è¯­è¨€|
  | :---: | :--------: | :--------: | :--------: |
  | `rocketqa-zh-dureader-query-encoder`  | 12 | 768 | ä¸­æ–‡|
  | `rocketqa-zh-dureader-para-encoder`  | 12 | 768 | ä¸­æ–‡|
  | `rocketqa-zh-base-query-encoder`  | 12 | 768 | ä¸­æ–‡|
  | `rocketqa-zh-base-para-encoder`  | 12 | 768 | ä¸­æ–‡|
  | `moka-ai/m3e-base`  | 12 | 768 | ä¸­æ–‡|
  | `rocketqa-zh-medium-query-encoder`  | 6 | 768 | ä¸­æ–‡|
  | `rocketqa-zh-medium-para-encoder`  | 6 | 768 | ä¸­æ–‡|
  | `rocketqa-zh-mini-query-encoder`  | 6 | 384 | ä¸­æ–‡|
  | `rocketqa-zh-mini-para-encoder`  | 6 | 384 | ä¸­æ–‡|
  | `rocketqa-zh-micro-query-encoder`  | 4 | 384 | ä¸­æ–‡|
  | `rocketqa-zh-micro-para-encoder`  | 4 | 384 | ä¸­æ–‡|
  | `rocketqa-zh-nano-query-encoder`  | 4 | 312 | ä¸­æ–‡|
  | `rocketqa-zh-nano-para-encoder`  | 4 | 312 | ä¸­æ–‡|
  | `rocketqav2-en-marco-query-encoder`  | 12 | 768 | è‹±æ–‡|
  | `rocketqav2-en-marco-para-encoder`  | 12 | 768 | è‹±æ–‡|
  | `ernie-search-base-dual-encoder-marco-en"`  | 12 | 768 | è‹±æ–‡|

#### å¯é…ç½®å‚æ•°è¯´æ˜
* `batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼Œè¯·ç»“åˆæœºå™¨æƒ…å†µè¿›è¡Œè°ƒæ•´ï¼Œé»˜è®¤ä¸º1ã€‚
* `max_seq_len`ï¼šæ–‡æœ¬åºåˆ—çš„æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ä¸º128ã€‚
* `return_tensors`: è¿”å›çš„ç±»å‹ï¼Œæœ‰pdå’Œnpï¼Œé»˜è®¤ä¸ºpdã€‚
* `model`ï¼šé€‰æ‹©ä»»åŠ¡ä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º`PaddlePaddle/ernie_vil-2.0-base-zh`ã€‚
* `pooling_mode`ï¼šé€‰æ‹©å¥å‘é‡è·å–æ–¹å¼ï¼Œæœ‰'max_tokens','mean_tokens','mean_sqrt_len_tokens','cls_token'ï¼Œé»˜è®¤ä¸º'cls_token'ï¼ˆ`moka-ai/m3e-base`ï¼‰ã€‚

</div></details>

## PART â…¡ &emsp; å®šåˆ¶åŒ–è®­ç»ƒ

<details><summary>é€‚é…ä»»åŠ¡åˆ—è¡¨</summary><div>

å¦‚æœä½ æœ‰è‡ªå·±çš„ä¸šåŠ¡æ•°æ®é›†ï¼Œå¯ä»¥å¯¹æ¨¡å‹æ•ˆæœè¿›ä¸€æ­¥è°ƒä¼˜ï¼Œæ”¯æŒå®šåˆ¶åŒ–è®­ç»ƒçš„ä»»åŠ¡å¦‚ä¸‹ï¼š

|                           ä»»åŠ¡åç§°                           |                           é»˜è®¤è·¯å¾„                           |                                                              |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|         `Taskflow("word_segmentation", mode="base")`         |             `$HOME/.paddlenlp/taskflow/lac`                  | [ç¤ºä¾‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/lexical_analysis) |
|       `Taskflow("word_segmentation", mode="accurate")`       |             `$HOME/.paddlenlp/taskflow/wordtag`              | [ç¤ºä¾‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_to_knowledge/ernie-ctm) |
|              `Taskflow("information_extraction", model="uie-base")`              |             `$HOME/.paddlenlp/taskflow/information_extraction/uie-base`              | [ç¤ºä¾‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/uie) |
|              `Taskflow("information_extraction", model="uie-tiny")`              |             `$HOME/.paddlenlp/taskflow/information_extraction/uie-tiny`              | [ç¤ºä¾‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/uie) |
|     `Taskflow("text_correction", model="ernie-csc")`     |  `$HOME/.paddlenlp/taskflow/text_correction/ernie-csc`   | [ç¤ºä¾‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_correction/ernie-csc) |
| `Taskflow("sentiment_analysis", model="skep_ernie_1.0_large_ch")` | `$HOME/.paddlenlp/taskflow/sentiment_analysis/skep_ernie_1.0_large_ch` | [ç¤ºä¾‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/sentiment_analysis/skep) |

</div></details>


<details><summary>å®šåˆ¶åŒ–è®­ç»ƒç¤ºä¾‹</summary><div>

è¿™é‡Œæˆ‘ä»¬ä»¥å‘½åå®ä½“è¯†åˆ«`Taskflow("ner", mode="accurate")`ä¸ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å®šåˆ¶è‡ªå·±çš„æ¨¡å‹ã€‚

è°ƒç”¨`Taskflow`æ¥å£åï¼Œç¨‹åºè‡ªåŠ¨å°†ç›¸å…³æ–‡ä»¶ä¸‹è½½åˆ°`$HOME/.paddlenlp/taskflow/wordtag/`ï¼Œè¯¥é»˜è®¤è·¯å¾„åŒ…å«ä»¥ä¸‹æ–‡ä»¶:

```text
$HOME/.paddlenlp/taskflow/wordtag/
â”œâ”€â”€ model_state.pdparams # é»˜è®¤æ¨¡å‹å‚æ•°æ–‡ä»¶
â”œâ”€â”€ model_config.json # é»˜è®¤æ¨¡å‹é…ç½®æ–‡ä»¶
â””â”€â”€ tags.txt # é»˜è®¤æ ‡ç­¾æ–‡ä»¶
```

* å‚è€ƒä¸Šè¡¨ä¸­å¯¹åº”[ç¤ºä¾‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_to_knowledge/ernie-ctm)å‡†å¤‡æ•°æ®é›†å’Œæ ‡ç­¾æ–‡ä»¶`tags.txt`ï¼Œæ‰§è¡Œç›¸åº”è®­ç»ƒè„šæœ¬å¾—åˆ°è‡ªå·±çš„`model_state.pdparams`å’Œ`model_config.json`ã€‚

* æ ¹æ®è‡ªå·±æ•°æ®é›†æƒ…å†µï¼Œä¿®æ”¹æ ‡ç­¾æ–‡ä»¶`tags.txt`ã€‚

* å°†ä»¥ä¸Šæ–‡ä»¶ä¿å­˜åˆ°ä»»æ„è·¯å¾„ä¸­ï¼Œè‡ªå®šä¹‰è·¯å¾„ä¸‹çš„æ–‡ä»¶éœ€è¦å’Œé»˜è®¤è·¯å¾„çš„æ–‡ä»¶ä¸€è‡´:

```text
custom_task_path/
â”œâ”€â”€ model_state.pdparams # å®šåˆ¶æ¨¡å‹å‚æ•°æ–‡ä»¶
â”œâ”€â”€ model_config.json # å®šåˆ¶æ¨¡å‹é…ç½®æ–‡ä»¶
â””â”€â”€ tags.txt # å®šåˆ¶æ ‡ç­¾æ–‡ä»¶
```
* é€šè¿‡`task_path`æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„ï¼Œä½¿ç”¨TaskflowåŠ è½½è‡ªå®šä¹‰æ¨¡å‹è¿›è¡Œä¸€é”®é¢„æµ‹ï¼š

```python
from paddlenlp import Taskflow
my_ner = Taskflow("ner", mode="accurate", task_path="./custom_task_path/")
```
</div></details>

## æ¨¡å‹ç®—æ³•

<details><summary>æ¨¡å‹ç®—æ³•è¯´æ˜</summary><div>

<table>
  <tr><td>ä»»åŠ¡åç§°<td>æ¨¡å‹<td>æ¨¡å‹è¯¦æƒ…<td>è®­ç»ƒé›†
  <tr><td rowspan="3">ä¸­æ–‡åˆ†è¯<td>é»˜è®¤æ¨¡å¼: BiGRU+CRF<td>  <a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/lexical_analysis"> è®­ç»ƒè¯¦æƒ… <td> ç™¾åº¦è‡ªå»ºæ•°æ®é›†ï¼ŒåŒ…å«è¿‘2200ä¸‡å¥å­ï¼Œè¦†ç›–å¤šç§åœºæ™¯
  <tr><td>å¿«é€Ÿæ¨¡å¼ï¼šJieba<td> - <td> -
  <tr><td>ç²¾ç¡®æ¨¡å¼ï¼šWordTag<td> <a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_to_knowledge/ernie-ctm"> è®­ç»ƒè¯¦æƒ… <td> ç™¾åº¦è‡ªå»ºæ•°æ®é›†ï¼Œè¯ç±»ä½“ç³»åŸºäºTermTreeæ„å»º
  <tr><td>ä¿¡æ¯æŠ½å–<td> UIE <td> <a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/uie"> è®­ç»ƒè¯¦æƒ… <td> ç™¾åº¦è‡ªå»ºæ•°æ®é›†
  <tr><td>æ–‡æœ¬çº é”™<td>ERNIE-CSC<td> <a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_correction/ernie-csc"> è®­ç»ƒè¯¦æƒ… <td> SIGHANç®€ä½“ç‰ˆæ•°æ®é›†åŠ <a href="https://github.com/wdimmy/Automatic-Corpus-Generation/blob/master/corpus/train.sgml"> Automatic Corpus Generationç”Ÿæˆçš„ä¸­æ–‡çº é”™æ•°æ®é›†
  <tr><td>æ–‡æœ¬ç›¸ä¼¼åº¦<td>SimBERT<td> - <td> æ”¶é›†ç™¾åº¦çŸ¥é“2200ä¸‡å¯¹ç›¸ä¼¼å¥ç»„
  <tr><td rowspan="3">æƒ…æ„Ÿåˆ†æ<td> BiLSTM <td> - <td> ç™¾åº¦è‡ªå»ºæ•°æ®é›†
  <tr><td> SKEP <td> <a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/sentiment_analysis/skep"> è®­ç»ƒè¯¦æƒ… <td> ç™¾åº¦è‡ªå»ºæ•°æ®é›†
  <tr><td> UIE <td> <a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/sentiment_analysis/unified_sentiment_extraction"> è®­ç»ƒè¯¦æƒ… <td> ç™¾åº¦è‡ªå»ºæ•°æ®é›†
</table>

</div></details>

## FAQ

<details><summary><b>Qï¼š</b>Taskflowå¦‚ä½•ä¿®æ”¹ä»»åŠ¡ä¿å­˜è·¯å¾„ï¼Ÿ</summary><div>

**A:** Taskflowé»˜è®¤ä¼šå°†ä»»åŠ¡ç›¸å…³æ¨¡å‹ç­‰æ–‡ä»¶ä¿å­˜åˆ°`$HOME/.paddlenlp`ä¸‹ï¼Œå¯ä»¥åœ¨ä»»åŠ¡åˆå§‹åŒ–çš„æ—¶å€™é€šè¿‡`home_path`è‡ªå®šä¹‰ä¿®æ”¹ä¿å­˜è·¯å¾„ã€‚ç¤ºä¾‹ï¼š
```python
from paddlenlp import Taskflow

ner = Taskflow("ner", home_path="/workspace")
```
é€šè¿‡ä»¥ä¸Šæ–¹å¼å³å¯å°†nerä»»åŠ¡ç›¸å…³æ–‡ä»¶ä¿å­˜è‡³`/workspace`è·¯å¾„ä¸‹ã€‚
</div></details>


<details><summary><b>Qï¼š</b>ä¸‹è½½æˆ–è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼Œå¤šæ¬¡ä¸‹è½½å‡å¤±è´¥æ€ä¹ˆåŠï¼Ÿ</summary><div>

**A:** Taskflowé»˜è®¤ä¼šå°†ä»»åŠ¡ç›¸å…³æ¨¡å‹ç­‰æ–‡ä»¶ä¿å­˜åˆ°`$HOME/.paddlenlp/taskflow`ä¸‹ï¼Œå¦‚æœä¸‹è½½æˆ–è°ƒç”¨å¤±è´¥ï¼Œå¯åˆ é™¤ç›¸åº”è·¯å¾„ä¸‹çš„æ–‡ä»¶ï¼Œé‡æ–°å°è¯•å³å¯

</div></details>

<details><summary><b>Qï¼š</b>Taskflowå¦‚ä½•æå‡é¢„æµ‹é€Ÿåº¦ï¼Ÿ</summary><div>

**A:** å¯ä»¥ç»“åˆè®¾å¤‡æƒ…å†µé€‚å½“è°ƒæ•´batch_sizeï¼Œé‡‡ç”¨æ‰¹é‡è¾“å…¥çš„æ–¹å¼æ¥æå‡å¹³å‡é€Ÿç‡ã€‚ç¤ºä¾‹ï¼š
```python
from paddlenlp import Taskflow

# ç²¾ç¡®æ¨¡å¼æ¨¡å‹ä½“ç§¯è¾ƒå¤§ï¼Œå¯ç»“åˆæœºå™¨æƒ…å†µé€‚å½“è°ƒæ•´batch_sizeï¼Œé‡‡ç”¨æ‰¹é‡æ ·æœ¬è¾“å…¥çš„æ–¹å¼ã€‚
seg_accurate = Taskflow("word_segmentation", mode="accurate", batch_size=32)

# æ‰¹é‡æ ·æœ¬è¾“å…¥ï¼Œè¾“å…¥ä¸ºå¤šä¸ªå¥å­ç»„æˆçš„listï¼Œé¢„æµ‹é€Ÿåº¦æ›´å¿«
texts = ["çƒ­æ¢…èŒ¶æ˜¯ä¸€é“ä»¥æ¢…å­ä¸ºä¸»è¦åŸæ–™åˆ¶ä½œçš„èŒ¶é¥®", "ã€Šå­¤å¥³ã€‹æ˜¯2010å¹´ä¹å·å‡ºç‰ˆç¤¾å‡ºç‰ˆçš„å°è¯´ï¼Œä½œè€…æ˜¯ä½™å…¼ç¾½"]
seg_accurate(texts)
```
é€šè¿‡ä¸Šè¿°æ–¹å¼è¿›è¡Œåˆ†è¯å¯ä»¥å¤§å¹…æå‡é¢„æµ‹é€Ÿåº¦ã€‚

</div></details>

<details><summary><b>Qï¼š</b>åç»­ä¼šå¢åŠ æ›´å¤šä»»åŠ¡æ”¯æŒå—ï¼Ÿ</summary><div>

**A:** Taskflowæ”¯æŒä»»åŠ¡æŒç»­ä¸°å¯Œä¸­ï¼Œæˆ‘ä»¬å°†æ ¹æ®å¼€å‘è€…åé¦ˆï¼Œçµæ´»è°ƒæ•´åŠŸèƒ½å»ºè®¾ä¼˜å…ˆçº§ï¼Œå¯é€šè¿‡Issueæˆ–[é—®å·](https://wenjuan.baidu-int.com/manage/?r=survey/pageEdit&sid=85827)åé¦ˆç»™æˆ‘ä»¬ã€‚

</div></details>


## é™„å½•

<details><summary><b>å‚è€ƒèµ„æ–™</b> </summary><div>

1. [fxsjy/jieba](https://github.com/fxsjy/jieba)
2. [ZhuiyiTechnology/simbert](https://github.com/ZhuiyiTechnology/simbert)
3. [CPM: A Large-scale Generative Chinese Pre-trained Language Model](https://arxiv.org/abs/2012.00413)

</div></details>
