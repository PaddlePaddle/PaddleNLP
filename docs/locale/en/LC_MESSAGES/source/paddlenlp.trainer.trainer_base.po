# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-05-19 14:17+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.10.1\n"

#: ../source/paddlenlp.trainer.trainer_base.rst:2
msgid "trainer\\_base"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:1
msgid "基类：:class:`object`"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:1
msgid ""
"Trainer is a simple but feature-complete training and eval loop for "
"PaddlePaddle, optimized for PaddleNLP."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer
#: paddlenlp.trainer.trainer_base.Trainer.add_callback
#: paddlenlp.trainer.trainer_base.Trainer.create_scheduler
#: paddlenlp.trainer.trainer_base.Trainer.evaluate
#: paddlenlp.trainer.trainer_base.Trainer.export_model
#: paddlenlp.trainer.trainer_base.Trainer.get_eval_dataloader
#: paddlenlp.trainer.trainer_base.Trainer.get_optimizer_cls_and_kwargs
#: paddlenlp.trainer.trainer_base.Trainer.get_test_dataloader
#: paddlenlp.trainer.trainer_base.Trainer.log
#: paddlenlp.trainer.trainer_base.Trainer.predict
#: paddlenlp.trainer.trainer_base.Trainer.prediction_step
#: paddlenlp.trainer.trainer_base.Trainer.training_step
msgid "参数"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:3
msgid ""
"The model to train, evaluate or use for predictions.  <Tip>  [`Trainer`] "
"is optimized to work with the [`PretrainedModel`] provided by the "
"library. You can still use your own models defined as `paddle.nn.Layer` "
"as long as they work the same way as the PaddleNLP models.  </Tip>"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:3
msgid "The model to train, evaluate or use for predictions."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:5
msgid "<Tip>"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:7
msgid ""
"[`Trainer`] is optimized to work with the [`PretrainedModel`] provided by"
" the library. You can still use your own models defined as "
"`paddle.nn.Layer` as long as they work the same way as the PaddleNLP "
"models."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:11
msgid "</Tip>"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:13
msgid ""
"The arguments to tweak for training. Will default to a basic instance of "
"[`TrainingArguments`] with the `output_dir` set to a directory named "
"*tmp_trainer* in the current directory if not provided."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:16
msgid ""
"The function to use to form a batch from a list of elements of "
"`train_dataset` or `eval_dataset`. Will default to "
"[`default_data_collator`] if no `tokenizer` is provided, an instance of "
"[`DataCollatorWithPadding`] otherwise."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:20
msgid ""
"The dataset to use for training. If it is an `datasets.Dataset`, columns "
"not accepted by the `model.forward()` method are automatically removed."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:23
msgid ""
"The dataset to use for evaluation. If it is an `datasets.Dataset`, "
"columns not accepted by the `model.forward()` method are automatically "
"removed."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:26
msgid ""
"The tokenizer used to preprocess the data. If provided, will be used to "
"automatically pad the inputs the maximum length when batching inputs, and"
" it will be saved along the model to make it easier to rerun an "
"interrupted training or reuse the fine-tuned model."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:30
msgid ""
"The function that will be used to compute metrics at evaluation. Must "
"take a [`EvalPrediction`] and return a dictionary string to metric "
"values."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:33
msgid ""
"A tuple containing the optimizer and the scheduler to use. Will default "
"to an instance of [`AdamW`] on your model and a scheduler given by "
"[`get_linear_schedule_with_warmup`] controlled by `args`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:38
msgid "Important attributes:"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:40
msgid ""
"**model** -- Always points to the core model. If using a transformers "
"model, it will be a [`PretrainedModel`] subclass."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:42
msgid ""
"**model_wrapped** -- Always points to the most external model in case one"
" or more other modules wrap the original model. This is the model that "
"should be used for the forward pass. For example, the inner model is "
"wrapped in `paddle.DataParallel`. If model hasn't been wrapped, then "
"`self.model_wrapped` is the same as `self.model`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:46
msgid ""
"**is_model_parallel** -- Whether or not a model has been switched to a "
"model parallel mode (different from data parallelism, this means some of "
"the model layers are split on different GPUs)."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:48
msgid ""
"**place_model_on_device** -- Whether or not to automatically place the "
"model on the device - it will be set to `False` if model parallel or "
"deepspeed is used, or if the default "
"`TrainingArguments.place_model_on_device` is overridden to return `False`"
" ."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer:51
msgid ""
"**is_in_train** -- Whether or not a model is currently running `train` "
"(e.g. when `evaluate` is called while in `train`)"
msgstr ""

#: of paddlenlp.trainer.trainer_utils.log_metrics:1
msgid ""
"Log metrics in a specially formatted way Under distributed environment "
"this is done only for a process with rank 0. :param split: Mode/split "
"name: one of `train`, `eval`, `test` :type split: `str` :param metrics: "
"The metrics returned from train/evaluate/predictmetrics: metrics dict "
":type metrics: `Dict[str, float]`"
msgstr ""

#: of paddlenlp.trainer.trainer_utils.metrics_format:1
msgid ""
"Reformat Trainer metrics values to a human-readable format :param "
"metrics: The metrics returned from train/evaluate/predict :type metrics: "
"`Dict[str, float]`"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate
#: paddlenlp.trainer.trainer_base.Trainer.pop_callback
#: paddlenlp.trainer.trainer_base.Trainer.prediction_step
#: paddlenlp.trainer.trainer_base.Trainer.training_step
#: paddlenlp.trainer.trainer_utils.metrics_format
msgid "返回"
msgstr ""

#: of paddlenlp.trainer.trainer_utils.metrics_format:5
msgid "The reformatted metrics"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.pop_callback
#: paddlenlp.trainer.trainer_base.Trainer.prediction_step
#: paddlenlp.trainer.trainer_base.Trainer.training_step
#: paddlenlp.trainer.trainer_utils.metrics_format
msgid "返回类型"
msgstr ""

#: of paddlenlp.trainer.trainer_utils.metrics_format:6
msgid "metrics (`Dict[str, float]`)"
msgstr ""

#: of paddlenlp.trainer.trainer_utils.save_metrics:1
msgid ""
"Save metrics into a json file for that split, e.g. `train_results.json`. "
"Under distributed environment this is done only for a process with rank "
"0. :param split: Mode/split name: one of `train`, `eval`, `test`, `all` "
":type split: `str` :param metrics: The metrics returned from "
"train/evaluate/predict :type metrics: `Dict[str, float]` :param combined:"
" Creates combined metrics by updating `all_results.json` with metrics of "
"this call :type combined: `bool`, *optional*, defaults to `True`"
msgstr ""

#: of paddlenlp.trainer.trainer_utils.save_metrics:10
msgid ""
"To understand the metrics please read the docstring of "
"[`~Trainer.log_metrics`]. The only difference is that raw unformatted "
"numbers are saved in the current method."
msgstr ""

#: of paddlenlp.trainer.trainer_utils.save_state:1
msgid ""
"Saves the Trainer state, since Trainer.save_model saves only the "
"tokenizer with the model Under distributed environment this is done only "
"for a process with rank 0."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.add_callback:1
msgid "Add a callback to the current list of [`~TrainerCallback`]."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.add_callback:3
msgid ""
"A [`~TrainerCallback`] class or an instance of a [`~TrainerCallback`]. In"
" the first case, will instantiate a member of that class."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.pop_callback:1
msgid ""
"Remove a callback from the current list of [`~TrainerCallback`] and "
"returns it. If the callback is not found, returns `None` (and no error is"
" raised). :param callback: A [`~TrainerCallback`] class or an instance of"
" a [`~TrainerCallback`]. In the"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.pop_callback:4
msgid ""
"first case, will pop the first member of that class found in the list of "
"callbacks."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.pop_callback:7
msgid "The callback removed, if found."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.pop_callback:8
msgid "[`~TrainerCallback`]"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.remove_callback:1
msgid ""
"Remove a callback from the current list of [`~TrainerCallback`]. :param "
"callback: A [`~TrainerCallback`] class or an instance of a "
"[`~TrainerCallback`]. In the"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.remove_callback:3
msgid ""
"first case, will remove the first member of that class found in the list "
"of callbacks."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_train_dataloader:1
msgid "Returns the training [`~paddle.io.DataLoader`]."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_train_dataloader:3
msgid ""
"Will use no sampler if `self.train_dataset` does not implement `__len__`,"
" a random sampler (adapted to distributed training if necessary) "
"otherwise."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_eval_dataloader:3
#: paddlenlp.trainer.trainer_base.Trainer.get_test_dataloader:3
#: paddlenlp.trainer.trainer_base.Trainer.get_train_dataloader:6
msgid ""
"Subclass and override this method if you want to inject some custom "
"behavior."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_eval_dataloader:1
msgid "Returns the evaluation [`~paddle.io.DataLoader`]."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_eval_dataloader:5
msgid ""
"If provided, will override `self.eval_dataset`. If it is an "
"`datasets.Dataset`, columns not accepted by the `model.forward()` method "
"are automatically removed. It must implement `__len__`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_test_dataloader:1
msgid "Returns the test [`~paddle.io.DataLoader`]."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_test_dataloader:5
msgid ""
"The test dataset to use. If it is an `datasets.Dataset`, columns not "
"accepted by the `model.forward()` method are automatically removed. It "
"must implement `__len__`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.create_optimizer_and_scheduler:1
msgid "Setup the optimizer and the learning rate scheduler."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.create_optimizer_and_scheduler:3
msgid ""
"We provide a reasonable default that works well. If you want to use "
"something else, you can pass a tuple in the Trainer's init through "
"`optimizers`, or subclass and override this method (or `create_optimizer`"
" and/or `create_scheduler`) in a subclass."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.create_optimizer:1
msgid "Setup the optimizer."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.create_optimizer:3
msgid ""
"We provide a reasonable default that works well. If you want to use "
"something else, you can pass a tuple in the Trainer's init through "
"`optimizers`, or subclass and override this method in a subclass."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_optimizer_cls_and_kwargs:1
msgid ""
"Returns the optimizer class and optimizer parameters based on the "
"training arguments."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.get_optimizer_cls_and_kwargs:3
msgid "The training arguments for the training session."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.create_scheduler:1
msgid ""
"Setup the scheduler. The optimizer of the trainer must have been set up "
"either before this method is called or passed as an argument."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.create_scheduler:4
msgid "The number of training steps to do."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.autocast_smart_context_manager:1
msgid ""
"A helper wrapper that creates an appropriate context manager for "
"`autocast` while feeding it the desired arguments, depending on the "
"situation."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.compute_loss:1
msgid ""
"How the loss is computed by Trainer. By default, all models return the "
"loss in the first element. Subclass and override for custom behavior."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.training_step:1
msgid "Perform a training step on a batch of inputs."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:3
#: paddlenlp.trainer.trainer_base.Trainer.training_step:3
msgid "Subclass and override to inject custom behavior."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.training_step:5
msgid "The model to train."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:7
#: paddlenlp.trainer.trainer_base.Trainer.training_step:7
msgid ""
"The inputs and targets of the model.  The dictionary will be unpacked "
"before being fed to the model. Most models expect the targets under the "
"argument `labels`. Check your model's documentation for all accepted "
"arguments."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:7
#: paddlenlp.trainer.trainer_base.Trainer.training_step:7
msgid "The inputs and targets of the model."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:9
#: paddlenlp.trainer.trainer_base.Trainer.training_step:9
msgid ""
"The dictionary will be unpacked before being fed to the model. Most "
"models expect the targets under the argument `labels`. Check your model's"
" documentation for all accepted arguments."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.training_step:13
msgid "The tensor with training loss on this batch."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.training_step:14
msgid "`paddle.Tensor`"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.save_model:1
msgid "Will save the model, so you can reload it using `from_pretrained()`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.save_model:3
msgid "Will only save from the main process."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.export_model:1
msgid "Export paddle inference model."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.export_model:3
msgid ""
"InputSpec describes the signature information of the model input, such as"
" shape , dtype , name. Defaults to None."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.export_model:6
msgid "Load best model. Defaults to False."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.export_model:8
msgid "Output dir to save the exported model. Defaults to None."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.log:1
msgid "Log `logs` on the various objects watching training."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.log:3
msgid "Subclass and override this method to inject custom behavior."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.log:5
msgid "The values to log."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate:1
msgid "Run evaluation and returns metrics."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate:3
msgid ""
"The calling script will be responsible for providing a method to compute "
"metrics, as they are task-dependent (pass it to the init "
"`compute_metrics` argument)."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate:6
msgid "You can also subclass and override this method to inject custom behavior."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate:8
msgid ""
"Pass a dataset if you wish to override `self.eval_dataset`. If it is an "
"`datasets.Dataset`, columns not accepted by the `model.forward()` method "
"are automatically removed. It must implement the `__len__` method."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate:12
#: paddlenlp.trainer.trainer_base.Trainer.predict:7
#: paddlenlp.trainer.trainer_base.Trainer.prediction_step:14
msgid ""
"A list of keys in the output of your model (if it is a dictionary) that "
"should be ignored when gathering predictions."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate:15
msgid ""
"An optional prefix to be used as the metrics key prefix. For example the "
"metrics \"bleu\" will be named \"eval_bleu\" if the prefix is \"eval\" "
"(default)"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluate:19
msgid ""
"A dictionary containing the evaluation loss and the potential metrics "
"computed from the predictions. The dictionary also contains the epoch "
"number which comes from the training state."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluation_loop:1
msgid ""
"Prediction/evaluation loop, shared by `Trainer.evaluate()` and "
"`Trainer.predict()`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.evaluation_loop:3
msgid "Works both with or without labels."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.predict:1
msgid ""
"Run prediction and returns predictions and potential metrics. Depending "
"on the dataset and your use case, your test dataset may contain labels. "
"In that case, this method will also return metrics, like in `evaluate()`."
" :param test_dataset: Dataset to run the predictions on. If it is an "
"`datasets.Dataset`, columns not accepted by the"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.predict:5
msgid ""
"`model.forward()` method are automatically removed. Has to implement the "
"method `__len__`"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.predict:10
msgid ""
"An optional prefix to be used as the metrics key prefix. For example the "
"metrics \"bleu\" will be named \"test_bleu\" if the prefix is \"test\" "
"(default)"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.predict:14
msgid ""
"<Tip> If your predictions or labels have different sequence length (for "
"instance because you're doing dynamic padding in a token classification "
"task) the predictions will be padded (on the right) to allow for "
"concatenation into one array. The padding index is -100. </Tip> Returns: "
"*NamedTuple* A namedtuple with the following keys:"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.predict:20
msgid "predictions (`np.ndarray`): The predictions on `test_dataset`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.predict:21
msgid ""
"label_ids (`np.ndarray`, *optional*): The labels (if the dataset "
"contained some)."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.predict:22
msgid ""
"metrics (`Dict[str, float]`, *optional*): The potential dictionary of "
"metrics (if the dataset contained labels)."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:1
msgid "Perform an evaluation step on `model` using `inputs`."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:5
msgid "The model to evaluate."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:12
msgid "Whether or not to return the loss only."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.prediction_step:18
msgid "A tuple with the loss, logits and labels (each being optional)."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.num_examples:1
msgid ""
"Helper to get number of samples in a [`~paddle.io.DataLoader`] by "
"accessing its dataset."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.num_examples:3
msgid ""
"Will raise an exception if the underlying dataset does not implement "
"method `__len__`"
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.is_local_process_zero:1
msgid ""
"Whether or not this process is the local (e.g., on one machine if "
"training in a distributed fashion on several machines) main process."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.is_world_process_zero:1
msgid ""
"Whether or not this process is the global main process (when training in "
"a distributed fashion on several machines, this is only going to be "
"`True` for one process)."
msgstr ""

#: of paddlenlp.trainer.trainer_base.Trainer.print_config:1
msgid "print config values"
msgstr ""

