# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-09-24 16:20+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../source/paddlenlp.transformers.ernie_ctm.tokenizer.rst:2
msgid "tokenizer"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:1
msgid "基类：:class:`paddlenlp.transformers.tokenizer_utils.PretrainedTokenizer`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:1
msgid ""
"Construct a ERNIE-CTM tokenizer. It uses a basic tokenizer to do "
"punctuation splitting, lower casing and so on, and follows a WordPiece "
"tokenizer to tokenize as subwords."
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.tokenize
msgid "参数"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:5
msgid "File containing the vocabulary."
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:7
msgid "Whether or not to lowercase the input when tokenizing. Defaults to `True`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:9
msgid ""
"Whether or not to do basic tokenization before WordPiece. Defaults to "
"`True`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:11
msgid ""
"The unknown token. A token that is not in the vocabulary cannot be "
"converted to an ID and is set to be this token instead. Defaults to "
"`\"[UNK]\"`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:14
msgid ""
"The separator token, which is used when building a sequence from multiple"
" sequences, e.g. two sequences for sequence classification or for a text "
"and a question for question answering. It is also used as the last token "
"of a sequence built with special tokens. Defaults to `\"[SEP]\"`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:18
msgid ""
"The token used for padding, for example when batching sequences of "
"different lengths. Defaults to `\"[PAD]\"`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:20
msgid ""
"The template of summary token for multiple summary placeholders. Defauts "
"to `\"[CLS{}]\"`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:22
msgid ""
"Summary placeholder used in ernie-ctm model. For catching a sentence "
"global feature from multiple aware. Defaults to 1"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:25
msgid ""
"The token used for masking values. This is the token used when training "
"this model with masked language modeling. This is the token which the "
"model will try to predict. Defaults to `\"[MASK]\"`"
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer:28
msgid ""
"(`bool`, optional): Whether or not to strip all accents. If this option "
"is not specified, then it will be determined by the value for `lowercase`"
" (as in the original BERT)."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.convert_tokens_to_string:1
msgid ""
"Converts a sequence of tokens (list of string) to a single string by "
"using ``' '.join(tokens)`` ."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.convert_tokens_to_string:4
msgid "A sequence of tokens."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.tokenize
msgid "返回"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.convert_tokens_to_string:7
msgid "Converted string."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.tokenize
msgid "返回类型"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens:1
msgid ""
"Build model inputs from a sequence or a pair of sequences for sequence "
"classification tasks by concatenating and add special tokens. A ERNIE-CTM"
" sequence has the following format:"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens:4
msgid "single sequence: [CLS0][CLS1]... X [SEP]"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens:5
msgid "pair of sequences: [CLS0][CLS1]... X [SEP] X [SEP]"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens:7
msgid "List of IDs to which the special tokens will be added."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens:9
msgid "second list of IDs for sequence pairs. Defaults to ``None``."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.build_inputs_with_special_tokens:12
msgid "The input IDs with the appropriate special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask:1
msgid ""
"Creates a special tokens mask from the input sequences. This method is "
"called when adding special tokens using the tokenizer `encode` method."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:22
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask:4
msgid "A list of `inputs_ids` for the first sequence."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:24
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask:6
msgid ""
"Optional second list of `inputs_ids` for the second sequence. Defaults to"
" `None`."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask:9
msgid ""
"Whether or not the token list already contains special tokens for the "
"model. Defaults to `False`."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.get_special_tokens_mask:13
msgid ""
"A list of integers which is either 0 or 1: 1 for a special token, 0 for a"
" sequence token."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:1
msgid ""
"Creates a token_type mask from the input sequences. If `token_ids_1` is "
"not `None`, then a sequence pair token_type mask has the following "
"format:"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:10
msgid ""
"Else if `token_ids_1` is `None`, then a single sequence token_type mask "
"has the following format:"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:18
msgid "0 stands for the segment id of **first segment tokens**,"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:19
msgid "1 stands for the segment id of **second segment tokens**,"
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:20
msgid "2 stands for the segment id of **cls_token**."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.create_token_type_ids_from_sequences:28
msgid "List of token type IDs according to the given sequence(s)."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.num_special_tokens_to_add:1
msgid ""
"Returns the number of added tokens when encoding a sequence with special "
"tokens."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.num_special_tokens_to_add:5
msgid ""
"This encodes inputs and checks the number of added tokens, and is "
"therefore not efficient. Do not put this inside your training loop."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.num_special_tokens_to_add:8
msgid ""
"Whether the input is a sequence pair or a single sequence. Defaults to "
"`False` and the input is a single sequence."
msgstr ""

#: of
#: paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.num_special_tokens_to_add:12
msgid "Number of tokens added to sequences."
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.tokenize:1
msgid "Converts a string to a list of tokens."
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.tokenize:3
msgid "The text to be tokenized."
msgstr ""

#: of paddlenlp.transformers.ernie_ctm.tokenizer.ErnieCtmTokenizer.tokenize:6
msgid "A list of string representing converted tokens."
msgstr ""

