# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-09-24 16:20+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../source/paddlenlp.transformers.albert.tokenizer.rst:2
msgid "tokenizer"
msgstr ""

#: of paddlenlp.transformers.albert.tokenizer:1
msgid "Tokenization class for ALBERT model."
msgstr ""

#: of paddlenlp.transformers.albert.tokenizer.AlbertTokenizer:1
msgid "基类：:class:`paddlenlp.transformers.tokenizer_utils.PretrainedTokenizer`"
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_ids:1
msgid ""
"Converts a sequence of tokens into ids using the `vocab` attribute (an "
"instance of `Vocab`). Override it if needed."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_ids:5
msgid "Args："
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_ids:5
msgid "tokens (list[int]): List of token ids."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_ids_to_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_ids
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.num_special_tokens_to_add
msgid "返回"
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_ids:7
msgid "Converted id list."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_ids_to_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_ids
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.num_special_tokens_to_add
msgid "返回类型"
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_ids_to_tokens:1
msgid ""
"Converts a token id or a sequence of token ids (integer) to a token or a "
"sequence of tokens (str) by using the `vocab` attribute (an instance of "
"`Vocab`)."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_ids_to_tokens
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.save_resources
msgid "参数"
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_ids_to_tokens:5
msgid "A token id or a sequence of token ids."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_ids_to_tokens:7
msgid ""
"Whether to skip and not decode special tokens when converting. Defaults "
"to `False`."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_ids_to_tokens:11
msgid "Converted token or token sequence."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_string:1
msgid ""
"Converts a sequence of tokens (list of string) to a single string by "
"using ``' '.join(tokens)`` ."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_string:4
msgid "A sequence of tokens."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.convert_tokens_to_string:7
msgid "Converted string."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.num_special_tokens_to_add:1
msgid ""
"Returns the number of added tokens when encoding a sequence with special "
"tokens."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.num_special_tokens_to_add:3
msgid ""
"Whether the number of added tokens should be computed in the case of a "
"sequence pair or a single sequence. Defaults to `False`."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.num_special_tokens_to_add:7
msgid "Number of special tokens added to sequences."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens:1
msgid ""
"Build model inputs from a sequence or a pair of sequence for sequence "
"classification tasks by concatenating and adding special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens:4
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens:3
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences:3
msgid ""
"Should be overridden in a subclass if the model has a special way of "
"building those."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens:6
msgid "List of IDs to which the special tokens will be added."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens:8
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences:10
msgid "Optional second list of IDs for sequence pairs."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_inputs_with_special_tokens:11
msgid "List of input_id with the appropriate special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens:1
msgid ""
"Build offset map from a pair of offset map by concatenating and adding "
"offsets of special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens:5
msgid "List of char offsets to which the special tokens will be added."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens:7
msgid "Optional second list of char offsets for offset mapping pairs."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.build_offset_mapping_with_special_tokens:10
msgid "List of char offsets with the appropriate offsets of special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask:1
msgid ""
"Retrieves sequence ids from a token list that has no special tokens "
"added. This method is called when adding special tokens using the "
"tokenizer ``encode`` methods."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask:4
msgid "List of ids of the first sequence."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask:6
msgid "List of ids of the second sequence."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask:8
msgid ""
"Whether or not the token list is already formatted with special tokens "
"for the model. Defaults to None."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask:12
msgid ""
"The list of integers in the range [0, 1]:     1 for a special token, 0 "
"for a sequence token."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask:14
msgid "The list of integers in the range [0, 1]:"
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.get_special_tokens_mask:15
msgid "1 for a special token, 0 for a sequence token."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences:1
msgid ""
"Create a mask from the two sequences passed to be used in a sequence-pair"
" classification task."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences:6
msgid ""
"If `token_ids_1` is `None`, this method only returns the first portion of"
" the mask (0s)."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences:8
msgid "List of IDs."
msgstr ""

#: of
#: paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.create_token_type_ids_from_sequences:13
msgid "List of token_type_id according to the given sequence(s)."
msgstr ""

#: of paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.save_resources:1
msgid ""
"Save tokenizer related resources to `resource_files_names` indicating "
"files under `save_directory` by copying directly. Override it if "
"necessary."
msgstr ""

#: of paddlenlp.transformers.albert.tokenizer.AlbertTokenizer.save_resources:4
msgid "Directory to save files into."
msgstr ""

