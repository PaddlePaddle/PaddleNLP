# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-03-18 21:31+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../source/paddlenlp.transformers.skep.tokenizer.rst:2
msgid "tokenizer"
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:1
msgid "基类：:class:`paddlenlp.transformers.tokenizer_utils.PretrainedTokenizer`"
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:1
msgid ""
"Constructs a Skep tokenizer. It uses a basic tokenizer to do punctuation "
"splitting, lower casing and so on, and follows a WordPiece tokenizer to "
"tokenize as subwords."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:5
msgid ""
"This tokenizer inherits from "
":class:`~paddlenlp.transformers.tokenizer_utils.PretrainedTokenizer` "
"which contains most of the main methods. For more information regarding "
"those methods, please refer to this superclass."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.save_resources
msgid "参数"
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:9
msgid ""
"The vocabulary file path (ends with '.txt') required to instantiate a "
"`WordpieceTokenizer`."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:12
msgid "The vocabulary file path of a `BpeTokenizer`. Defaults to `None`."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:14
msgid "The json file path of a `BpeTokenizer`. Defaults to `None`."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:16
msgid "Whether or not to use BPE Encoder. Defaults to `False`."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:18
msgid "Whether or not to use token type id. Defaults to `True`."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:20
msgid "Whether or not to add two different `sep_token`. Defaults to `False`."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:22
msgid "The special token for unknown words. Defaults to \"[UNK]\"."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:25
msgid "The special token for separator token. Defaults to \"[SEP]\"."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:28
msgid "The special token for padding. Defaults to \"[PAD]\"."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:31
msgid "The special token for cls. Defaults to \"[CLS]\"."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:34
msgid "The special token for mask. Defaults to \"[MASK]\"."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer:39
msgid "实际案例"
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer.vocab_size:1
msgid "Return the size of vocabulary."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.vocab_size
msgid "返回"
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer.vocab_size:3
msgid "the size of vocabulary."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.vocab_size
msgid "返回类型"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.num_special_tokens_to_add:1
msgid ""
"Returns the number of added tokens when encoding a sequence with special "
"tokens."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.num_special_tokens_to_add:3
msgid ""
"Returns the number of added tokens in the case of a sequence pair if set "
"to True, returns the number of added tokens in the case of a single "
"sequence if set to False. Defaults to False."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.num_special_tokens_to_add:8
msgid "Number of tokens added to sequences"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:1
msgid ""
"Build model inputs from a sequence or a pair of sequence for sequence "
"classification tasks by concatenating and adding special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:4
msgid ""
"A skep_ernie_1.0_large_ch/skep_ernie_2.0_large_en sequence has the "
"following format:"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:6
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:11
msgid "single sequence:      ``[CLS] X [SEP]``"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:7
msgid "pair of sequences:        ``[CLS] A [SEP] B [SEP]``"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:9
msgid "A skep_roberta_large_en sequence has the following format:"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:12
msgid "pair of sequences:        ``[CLS] A [SEP] [SEP] B [SEP]``"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:14
msgid "List of IDs to which the special tokens will be added."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:16
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences:15
msgid "Optional second list of IDs for sequence pairs. Defaults to `None`."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.build_inputs_with_special_tokens:20
msgid "List of input_id with the appropriate special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences:1
msgid ""
"Create a mask from the two sequences passed to be used in a sequence-pair"
" classification task."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences:3
msgid ""
"A skep_ernie_1.0_large_ch/skep_ernie_2.0_large_en sequence pair mask has "
"the following format: ::"
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences:9
msgid ""
"If `token_ids_1` is `None`, this method only returns the first portion of"
" the mask (0s)."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences:11
msgid "note: There is no need token type ids for skep_roberta_large_ch model."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences:13
msgid "List of IDs."
msgstr ""

#: of
#: paddlenlp.transformers.skep.tokenizer.SkepTokenizer.create_token_type_ids_from_sequences:19
msgid "List of token_type_id according to the given sequence(s)."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer.save_resources:1
msgid "Save tokenizer related resources to files under `save_directory`."
msgstr ""

#: of paddlenlp.transformers.skep.tokenizer.SkepTokenizer.save_resources:3
msgid "Directory to save files into."
msgstr ""

