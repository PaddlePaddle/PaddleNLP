# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-03-18 21:31+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../source/paddlenlp.transformers.prophetnet.tokenizer.rst:2
msgid "tokenizer"
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.load_vocab:1
msgid "Loads a vocabulary file into a dictionary."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:1
msgid "基类：:class:`paddlenlp.transformers.tokenizer_utils.PretrainedTokenizer`"
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:1
msgid "Construct a ProphetNetTokenizer. Based on WordPiece."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:3
msgid ""
"This tokenizer inherits from [`PreTrainedTokenizer`] which contains most "
"of the main methods. Users should refer to this superclass for more "
"information regarding those methods."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_ids_to_tokens
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.save_vocabulary
msgid "参数"
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:6
msgid "File containing the vocabulary."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:8
msgid "Whether or not to lowercase the input when tokenizing."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:10
msgid "Whether or not to do basic tokenization before WordPiece."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:12
msgid ""
"The unknown token. A token that is not in the vocabulary cannot be "
"converted to an ID and is set to be this token instead."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:15
msgid ""
"The separator token, which is used when building a sequence from multiple"
" sequences, e.g. two sequences for sequence classification or for a text "
"and a question for question answering. It is also used as the last token "
"of a sequence built with special tokens."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:19
msgid ""
"Special second separator token, which can be generated by "
"[`ProphetNetForConditionalGeneration`]. It is used to separate bullet-"
"point like sentences in summarization, *e.g.*."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:23
msgid ""
"The token used for padding, for example when batching sequences of "
"different lengths."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:25
msgid ""
"The classifier token which is used when doing sequence classification "
"(classification of the whole sequence instead of per-token "
"classification). It is the first token of the sequence when built with "
"special tokens."
msgstr ""

#: of paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer:28
msgid ""
"The token used for masking values. This is the token used when training "
"this model with masked language modeling. This is the token which the "
"model will try to predict."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_tokens_to_ids:1
msgid ""
"Converts a sequence of tokens into ids using the `vocab` attribute (an "
"instance of `Vocab`). Override it if needed."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_tokens_to_ids:5
msgid "Args："
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_tokens_to_ids:5
msgid "tokens (list[int]): List of token ids."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_ids_to_tokens
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_tokens_to_ids
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask
msgid "返回"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_tokens_to_ids:7
msgid "Converted id list."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_ids_to_tokens
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_tokens_to_ids
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask
msgid "返回类型"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_ids_to_tokens:1
msgid ""
"Converts a single index or a sequence of indices to a token or a sequence"
" of tokens, using the vocabulary and added tokens."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_ids_to_tokens:4
msgid "The token id (or token ids) to be converted to token(s)."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_ids_to_tokens:6
msgid ""
"Whether or not to remove special tokens in the decoding. Defaults to "
"`False` and we do not remove special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_ids_to_tokens:10
msgid "The decoded token(s)."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.convert_tokens_to_string:1
msgid "Converts a sequence of tokens (string) in a single string."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask:1
msgid ""
"Retrieve sequence ids from a token list that has no special tokens added."
" This method is called when adding special tokens using the tokenizer "
"`prepare_for_model` method."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences:11
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask:4
msgid "List of IDs."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens:9
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences:13
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask:6
msgid "Optional second list of IDs for sequence pairs."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask:8
msgid ""
"Whether or not the token list is already formatted with special tokens "
"for the model."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask:11
msgid ""
"A list of integers in the range [0, 1]: 1 for a special token, 0 for a "
"sequence token."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens:13
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences:18
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.get_special_tokens_mask:12
msgid "`List[int]`"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences:1
msgid ""
"Create a mask from the two sequences passed to be used in a sequence-pair"
" classification task. A ProphetNet sequence pair mask has the following "
"format:"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences:4
msgid ""
"``` 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 | first sequence    | second "
"sequence | ```"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences:9
msgid ""
"If `token_ids_1` is `None`, this method only returns the first portion of"
" the mask (0s)."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.create_token_type_ids_from_sequences:16
msgid ""
"List of [token type IDs](../glossary#token-type-ids) according to the "
"given sequence(s)."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens:1
msgid ""
"Build model inputs from a sequence or a pair of sequence for sequence "
"classification tasks by concatenating and adding special tokens. A BERT "
"sequence has the following format:"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens:4
msgid "single sequence: `[CLS] X [SEP]`"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens:5
msgid "pair of sequences: `[CLS] A [SEP] B [SEP]`"
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens:7
msgid "List of IDs to which the special tokens will be added."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.build_inputs_with_special_tokens:12
msgid ""
"List of [input IDs](../glossary#input-ids) with the appropriate special "
"tokens."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.save_vocabulary:1
msgid ""
"Save all tokens to a vocabulary file. The file contains a token per line,"
" and the line number would be the index of corresponding token."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.save_vocabulary:4
msgid "File path to be saved to."
msgstr ""

#: of
#: paddlenlp.transformers.prophetnet.tokenizer.ProphetNetTokenizer.save_vocabulary:6
msgid "The `Vocab` or `dict` instance to be saved."
msgstr ""

