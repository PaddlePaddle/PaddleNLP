# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-03-16 16:04+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../source/paddlenlp.transformers.xlnet.tokenizer.rst:2
msgid "tokenizer"
msgstr ""

#~ msgid "Tokenization class for XLNet model."
#~ msgstr ""

#~ msgid "基类：:class:`paddlenlp.transformers.tokenizer_utils.PretrainedTokenizer`"
#~ msgstr ""

#~ msgid ""
#~ "Constructs an XLNet tokenizer. Based on"
#~ " `SentencePiece <https://github.com/google/sentencepiece>`__."
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid ""
#~ "``SentencePiece`` file (ends with .spm) "
#~ "that contains the vocabulary necessary "
#~ "to instantiate a tokenizer."
#~ msgstr ""

#~ msgid ""
#~ "Whether to lowercase the input when "
#~ "tokenizing. Defaults to ``False`` and we"
#~ " do not lowercase the input."
#~ msgstr ""

#~ msgid ""
#~ "Whether to strip the text when "
#~ "tokenizing. Defaults to ``True`` and we"
#~ " remove excess spaces before and "
#~ "after the string."
#~ msgstr ""

#~ msgid ""
#~ "Whether to keep accents when tokenizing."
#~ " Defaults to ``False`` and we don't"
#~ " keep accents."
#~ msgstr ""

#~ msgid ""
#~ "The beginning of sequence token that "
#~ "was used during pretraining. Defaults to"
#~ " ``\"<s>\"``."
#~ msgstr ""

#~ msgid "The end of sequence token. Defaults to ``\"</s>\"``."
#~ msgstr ""

#~ msgid ""
#~ "The unknown token. A token that is"
#~ " not in the vocabulary is set "
#~ "to be unk_token inorder to be "
#~ "converted to an ID. Defaults to "
#~ "``\"<unk>\"``."
#~ msgstr ""

#~ msgid "The separator token. Defaults to ``\"<sep>\"``."
#~ msgstr ""

#~ msgid "The token used for padding. Defaults to ``\"<pad>\"``."
#~ msgstr ""

#~ msgid ""
#~ "The classifier token which is used "
#~ "when doing sequence classification. It "
#~ "is the last token of the sequence"
#~ " when built with special tokens. "
#~ "Defaults to ``\"<cls>\"``."
#~ msgstr ""

#~ msgid ""
#~ "The token used for masking values. "
#~ "In the masked language modeling task,"
#~ " this is the token used and "
#~ "which the model will try to "
#~ "predict. Defaults to ``\"<mask>\"``."
#~ msgstr ""

#~ msgid ""
#~ "Additional special tokens used by the"
#~ " tokenizer. Defaults to ``[\"<eop>\", "
#~ "\"<eod>\"]``."
#~ msgstr ""

#~ msgid ""
#~ "The ``SentencePiece`` processor that is "
#~ "used for every conversion (string, "
#~ "tokens and IDs)."
#~ msgstr ""

#~ msgid "type"
#~ msgstr ""

#~ msgid "`SentencePieceProcessor`"
#~ msgstr ""

#~ msgid "End-to-end tokenization for XLNet models."
#~ msgstr ""

#~ msgid "The text to be tokenized."
#~ msgstr ""

#~ msgid "返回"
#~ msgstr ""

#~ msgid "A list of string representing converted tokens."
#~ msgstr ""

#~ msgid "返回类型"
#~ msgstr ""

#~ msgid "`List(str)`"
#~ msgstr ""

#~ msgid ""
#~ "Converts a token (or a sequence of"
#~ " tokens) to a single integer id "
#~ "(or a sequence of ids), using the"
#~ " vocabulary."
#~ msgstr ""

#~ msgid "One or several token(s) to convert to token id(s)."
#~ msgstr ""

#~ msgid "The token id or list of token ids or tuple of token ids."
#~ msgstr ""

#~ msgid "`int` or `List[int]` or `tuple(int)`"
#~ msgstr ""

#~ msgid ""
#~ "Converts a single index or a "
#~ "sequence of indices to a token or"
#~ " a sequence of tokens, using the "
#~ "vocabulary and added tokens."
#~ msgstr ""

#~ msgid "The token id (or token ids) to be converted to token(s)."
#~ msgstr ""

#~ msgid ""
#~ "Whether or not to remove special "
#~ "tokens in the decoding. Defaults to "
#~ "``False`` and we do not remove "
#~ "special tokens."
#~ msgstr ""

#~ msgid "The decoded token(s)."
#~ msgstr ""

#~ msgid "`str` or `List[str]`"
#~ msgstr ""

#~ msgid ""
#~ "Converts a sequence of tokens (strings"
#~ " for sub-words) in a single "
#~ "string."
#~ msgstr ""

#~ msgid ""
#~ "Returns the number of added tokens "
#~ "when encoding a sequence with special"
#~ " tokens."
#~ msgstr ""

#~ msgid ""
#~ "This encodes inputs and checks the "
#~ "number of added tokens, and is "
#~ "therefore not efficient. Do not put "
#~ "this inside your training loop."
#~ msgstr ""

#~ msgid ""
#~ "Whether the sequence is a sequence "
#~ "pair or a single sequence. Defaults "
#~ "to ``False`` and the input is a"
#~ " single sequence."
#~ msgstr ""

#~ msgid "Number of tokens added to sequences."
#~ msgstr ""

#~ msgid "`int`"
#~ msgstr ""

#~ msgid ""
#~ "Builds model inputs from a sequence "
#~ "or a pair of sequence for sequence"
#~ " classification tasks by concatenating and"
#~ " adding special tokens. An XLNet "
#~ "sequence has the following format:"
#~ msgstr ""

#~ msgid "single sequence:      ``X <sep> <cls>``"
#~ msgstr ""

#~ msgid "pair of sequences:    ``A <sep> B <sep> <cls>``"
#~ msgstr ""

#~ msgid "List of IDs for the first sequence."
#~ msgstr ""

#~ msgid "Optional second list of IDs for sequence pairs. Defaults to ``None``."
#~ msgstr ""

#~ msgid "List of input IDs with the appropriate special tokens."
#~ msgstr ""

#~ msgid "`List[int]`"
#~ msgstr ""

#~ msgid ""
#~ "Builds offset map from a pair of"
#~ " offset map by concatenating and "
#~ "adding offsets of special tokens."
#~ msgstr ""

#~ msgid "An XLNet offset_mapping has the following format:"
#~ msgstr ""

#~ msgid "single sequence:      ``X (0,0) (0,0)``"
#~ msgstr ""

#~ msgid "pair of sequences:    ``A (0,0) B (0,0) (0,0)``"
#~ msgstr ""

#~ msgid "List of char offsets to which the special tokens will be added."
#~ msgstr ""

#~ msgid ""
#~ "Optional second list of char offsets "
#~ "for offset mapping pairs. Defaults to"
#~ " ``None``."
#~ msgstr ""

#~ msgid "List of char offsets with the appropriate offsets of special tokens."
#~ msgstr ""

#~ msgid "`List[tuple]`"
#~ msgstr ""

#~ msgid ""
#~ "Creates a special tokens mask from "
#~ "the input sequences. This method is "
#~ "called when adding special tokens using"
#~ " the tokenizer ``encode`` method."
#~ msgstr ""

#~ msgid ""
#~ "Whether or not the token list is"
#~ " already formatted with special tokens "
#~ "for the model. Defaults to ``False``."
#~ msgstr ""

#~ msgid ""
#~ "A list of integers in the range"
#~ " [0, 1]: 1 for a special token,"
#~ " 0 for a sequence token."
#~ msgstr ""

#~ msgid ""
#~ "Creates a mask from the input "
#~ "sequences. An XLNet sequence pair mask"
#~ " has the following format:"
#~ msgstr ""

#~ msgid "0 stands for the segment id of **first segment tokens**,"
#~ msgstr ""

#~ msgid "1 stands for the segment id of **second segment tokens**,"
#~ msgstr ""

#~ msgid "2 stands for the segment id of **cls_token**."
#~ msgstr ""

#~ msgid ""
#~ "Optional second list of IDs for "
#~ "the sequence pair. Defaults to ``None``."
#~ msgstr ""

#~ msgid "List of token type IDs according to the given sequence(s)."
#~ msgstr ""

#~ msgid "Saves tokenizer related resources to files under `save_directory`."
#~ msgstr ""

#~ msgid "Directory to save files into."
#~ msgstr ""

