# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-09-24 16:20+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../source/paddlenlp.transformers.generation_utils.rst:2
msgid "generation\\_utils"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin:1
msgid "基类：:class:`object`"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin:1
msgid "This class implements the interface for generation task."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin:3
msgid ""
"It's used as the base class of `paddlenlp.transformers.PretrainedModel "
"<https://paddlenlp.readthedocs.io/zh/latest/source/paddlenlp.transformers.model_utils.html>`__."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:1
msgid ""
"The interface for generation task. This method can generate sequences by "
"using decoding strategy. Currently, there are three decoding strategies "
"supported: \"greedy_search\", \"sampling\" and \"beam_search\"."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate
msgid "参数"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:5
msgid ""
"The input sequence ids for the generation. It is a Tensor with shape "
"[batch_size, sequence_length]. The data type should be int32 or int64. "
"Default to None, which we will initialize it as a Tensor with shape [1, "
"1], filled with the value `bos_token_id`."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:11
msgid "The maximum length of the sequence to be generated. Default to 20."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:14
msgid "The minimum length of the sequence to be generated. Default to 0."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:17
msgid ""
"The decoding strategy in generation. Currently, there are three decoding "
"strategies supported: \"greedy_search\", \"sampling\" and "
"\"beam_search\". Default to \"greedy_search\"."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:22
msgid ""
"The value used to module the next token probabilities in the \"sampling\""
" strategy. Default to 1.0, which means no effect."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:26
msgid ""
"The number of highest probability tokens to keep for top-k-filtering in "
"the \"sampling\" strategy. Default to 0, which means no effect."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:30
msgid ""
"The cumulative probability for top-p-filtering in the \"sampling\" "
"strategy. The value should satisfy :math:`0 <= top\\_p < 1`. Default to "
"1.0, which means no effect."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:35
msgid "The number of beams in the \"beam_search\" strategy. Default to 1."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:38
msgid ""
"The exponential penalty to the sequence length in the \"beam_search\" "
"strategy. If :math:`length\\_penalty < 1.0`, the model will generate "
"shorter sequences. If :math:`length\\_penalty > 1.0`, the model will "
"generate longer sequences. Default to 1.0, which means no penalty."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:45
msgid ""
"Whether to stop searching in the \"beam_search\" strategy when at least "
"`num_beams` sentences are finished per batch or not. Default to False."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:49
msgid "The id of the `bos_token`. Default to None."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:52
msgid "The id of the `eos_token`. Default to None."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:55
msgid "The id of the `pad_token`. Default to None."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:58
msgid ""
"The number of returned sequences for each sequence in the batch. Default "
"to 1."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:61
msgid ""
"(bool, optional): Whether or not use the model cache to speed up "
"decoding. Default to True."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:63
msgid "It can be used to specify additional kwargs passed to the model."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate
msgid "返回"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:67
msgid ""
"It is a tuple contains two elements: ids and scores. Each element is a "
"Tensor.  With the fields:  - ids (Tensor):     The ids of the generated "
"sequences. It is a Tensor with shape     [batch_size * "
"num_return_sequences, sequence_length]. The data     type is same as the "
"input `input_ids`. - scores (Tensor):     The scores of the generated "
"sequences. It is a Tensor with shape     [batch_size * "
"num_return_sequences, 1]. The data type is float32     or float64, which "
"is the same as the parameters in the model."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:67
msgid ""
"It is a tuple contains two elements: ids and scores. Each element is a "
"Tensor."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:70
msgid "With the fields:"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:74
msgid "ids (Tensor):"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:73
msgid ""
"The ids of the generated sequences. It is a Tensor with shape [batch_size"
" * num_return_sequences, sequence_length]. The data type is same as the "
"input `input_ids`."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:78
msgid "scores (Tensor):"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:77
msgid ""
"The scores of the generated sequences. It is a Tensor with shape "
"[batch_size * num_return_sequences, 1]. The data type is float32 or "
"float64, which is the same as the parameters in the model."
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate
msgid "返回类型"
msgstr ""

#: of paddlenlp.transformers.generation_utils.GenerationMixin.generate:83
msgid "示例"
msgstr ""

