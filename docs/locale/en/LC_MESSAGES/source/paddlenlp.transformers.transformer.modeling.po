# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-07 11:40+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../source/paddlenlp.transformers.transformer.modeling.rst:2
msgid "modeling"
msgstr ""

#: of paddlenlp.transformers.transformer.modeling.position_encoding_init:1
msgid "Generate the initial values for the sinusoid position encoding table."
msgstr ""

#: of paddlenlp.transformers.transformer.modeling.CrossEntropyCriterion:1
#: paddlenlp.transformers.transformer.modeling.PositionalEmbedding:1
#: paddlenlp.transformers.transformer.modeling.TransformerDecodeCell:1
#: paddlenlp.transformers.transformer.modeling.TransformerModel:1
#: paddlenlp.transformers.transformer.modeling.WordEmbedding:1
msgid "基类：:class:`paddle.fluid.dygraph.layers.Layer`"
msgstr ""

#: of paddlenlp.transformers.transformer.modeling.WordEmbedding:1
msgid "Word Embedding + Scale"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.CrossEntropyCriterion.forward:1
#: paddlenlp.transformers.transformer.modeling.InferTransformerModel.forward:1
#: paddlenlp.transformers.transformer.modeling.PositionalEmbedding.forward:1
#: paddlenlp.transformers.transformer.modeling.TransformerDecodeCell.forward:1
#: paddlenlp.transformers.transformer.modeling.TransformerModel.forward:1
#: paddlenlp.transformers.transformer.modeling.WordEmbedding.forward:1
msgid ""
"Defines the computation performed at every call. Should be overridden by "
"all subclasses."
msgstr ""

#: of paddlenlp.transformers.transformer.modeling.CrossEntropyCriterion.forward
#: paddlenlp.transformers.transformer.modeling.InferTransformerModel.forward
#: paddlenlp.transformers.transformer.modeling.PositionalEmbedding.forward
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch
#: paddlenlp.transformers.transformer.modeling.TransformerDecodeCell.forward
#: paddlenlp.transformers.transformer.modeling.TransformerModel.forward
#: paddlenlp.transformers.transformer.modeling.WordEmbedding.forward
msgid "参数"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.CrossEntropyCriterion.forward:4
#: paddlenlp.transformers.transformer.modeling.InferTransformerModel.forward:4
#: paddlenlp.transformers.transformer.modeling.PositionalEmbedding.forward:4
#: paddlenlp.transformers.transformer.modeling.TransformerDecodeCell.forward:4
#: paddlenlp.transformers.transformer.modeling.TransformerModel.forward:4
#: paddlenlp.transformers.transformer.modeling.WordEmbedding.forward:4
msgid "unpacked tuple arguments"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.CrossEntropyCriterion.forward:6
#: paddlenlp.transformers.transformer.modeling.InferTransformerModel.forward:6
#: paddlenlp.transformers.transformer.modeling.PositionalEmbedding.forward:6
#: paddlenlp.transformers.transformer.modeling.TransformerDecodeCell.forward:6
#: paddlenlp.transformers.transformer.modeling.TransformerModel.forward:6
#: paddlenlp.transformers.transformer.modeling.WordEmbedding.forward:6
msgid "unpacked dict arguments"
msgstr ""

#: of paddlenlp.transformers.transformer.modeling.PositionalEmbedding:1
msgid "Positional Embedding"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder:1
msgid "基类：:class:`paddle.fluid.layers.rnn.BeamSearchDecoder`"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch:1
msgid ""
"Tile the batch dimension of a tensor. Specifically, this function takes a"
" tensor t shaped `[batch_size, s0, s1, ...]` composed of minibatch "
"entries `t[0], ..., t[batch_size - 1]` and tiles it to have a shape "
"`[batch_size * beam_size, s0, s1, ...]` composed of minibatch entries "
"`t[0], t[0], ..., t[1], t[1], ...` where each minibatch entry is repeated"
" `beam_size` times."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch:8
msgid ""
"A tensor with shape `[batch_size, ...]`. The data type should be float32,"
" float64, int32, int64 or bool."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch:11
msgid "The beam width used in beam search."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch
msgid "返回"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch:14
msgid ""
"A tensor with shape `[batch_size * beam_size, ...]`, whose \\     data "
"type is same as `x`."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch:16
msgid "A tensor with shape `[batch_size * beam_size, ...]`, whose \\"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch:17
msgid "data type is same as `x`."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.tile_beam_merge_with_batch
msgid "返回类型"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:1
msgid ""
"Perform a beam search decoding step, which uses `cell` to get "
"probabilities, and follows a beam search step to calculate scores and "
"select candidate token ids."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:5
msgid ""
"An `int64` tensor with shape `[1]` provided by the caller, representing "
"the current time step number of decoding."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:8
msgid ""
"A tensor variable. It is same as `initial_inputs` returned by "
"`initialize()` for the first decoding step and `next_inputs` returned by "
"`step()` for the others."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:12
msgid ""
"A structure of tensor variables. It is same as the `initial_states` "
"returned by `initialize()` for the first decoding step and "
"`beam_search_state` returned by `step()` for the others."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:17
msgid "Additional keyword arguments, provided by the caller."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:19
msgid ""
"A tuple( :code:`(beam_search_output, beam_search_state, next_inputs, "
"finished)` ). \\     `beam_search_state` and `next_inputs` have the same "
"structure, \\     shape and data type as the input arguments `states` and"
" `inputs` separately. \\     `beam_search_output` is a "
"namedtuple(including scores, predicted_ids, \\     parent_ids as fields) "
"of tensor variables, where \\     `scores, predicted_ids, parent_ids` all"
" has a tensor value shaped \\     `[batch_size, beam_size]` with data "
"type `float32, int64, int64`. \\     `finished` is a `bool` tensor with "
"shape `[batch_size, beam_size]`."
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:27
msgid ""
"A tuple( :code:`(beam_search_output, beam_search_state, next_inputs, "
"finished)` ). \\"
msgstr ""

#: of
#: paddlenlp.transformers.transformer.modeling.TransformerBeamSearchDecoder.step:22
msgid ""
"`beam_search_state` and `next_inputs` have the same structure, \\ shape "
"and data type as the input arguments `states` and `inputs` separately. \\"
" `beam_search_output` is a namedtuple(including scores, predicted_ids, \\"
" parent_ids as fields) of tensor variables, where \\ `scores, "
"predicted_ids, parent_ids` all has a tensor value shaped \\ `[batch_size,"
" beam_size]` with data type `float32, int64, int64`. \\ `finished` is a "
"`bool` tensor with shape `[batch_size, beam_size]`."
msgstr ""

#: of paddlenlp.transformers.transformer.modeling.TransformerModel:1
msgid "model"
msgstr ""

#: of paddlenlp.transformers.transformer.modeling.InferTransformerModel:1
msgid "基类：:class:`paddlenlp.transformers.transformer.modeling.TransformerModel`"
msgstr ""

