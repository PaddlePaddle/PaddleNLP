# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-03-18 21:31+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../source/paddlenlp.utils.batch_sampler.rst:2
msgid "batch\\_sampler"
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:1
msgid "Sampler that restricts data loading to a subset of the dataset."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:3
msgid ""
"In such case, each process can pass a DistributedBatchSampler instance as"
" a DataLoader sampler, and load a subset of the original dataset that is "
"exclusive to it."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:8
msgid "Dataset is assumed to be of constant size."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler
#: paddlenlp.utils.batch_sampler.DistributedBatchSampler.set_epoch
msgid "参数"
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:10
msgid ""
"this could be a `paddle.io.Dataset` implement or other python object "
"which implemented `__len__` for BatchSampler to get sample number of data"
" source."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:15
msgid "sample indice number in a mini-batch indices."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:17
msgid ""
"porcess number in distributed training. If :attr:`num_replicas` is None, "
":attr:`num_replicas` will be retrieved from "
":code:`paddle.distributed.ParallenEnv`. Default None."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:22
msgid ""
"the rank of the current process among :attr:`num_replicas` processes. If "
":attr:`rank` is None, :attr:`rank` is retrieved from "
":code:`paddle.distributed.ParallenEnv`. Default None."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:26
msgid ""
"whther to shuffle indices order before genrating batch indices. Default "
"False."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:29
msgid ""
"whether drop the last incomplete batch dataset size is not divisible by "
"the batch size. Default False"
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler:34
#: paddlenlp.utils.batch_sampler.DistributedBatchSampler.set_epoch:11
msgid "实际案例"
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler.set_epoch:1
msgid ""
"Sets the epoch number. When :attr:`shuffle=True`, this number is used as "
"seeds of random numbers. By default, users may not set this, all replicas"
" (workers) use a different random ordering for each epoch. If set same "
"number at each epoch, this sampler will yield the same ordering at all "
"epoches."
msgstr ""

#: of paddlenlp.utils.batch_sampler.DistributedBatchSampler.set_epoch:7
msgid "Epoch number."
msgstr ""

