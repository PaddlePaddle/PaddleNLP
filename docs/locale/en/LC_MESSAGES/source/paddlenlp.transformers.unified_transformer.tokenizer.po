# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-07 11:40+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../../source/paddlenlp.transformers.unified_transformer.tokenizer.rst:2
msgid "tokenizer"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer:1
msgid "基类：:class:`paddlenlp.transformers.tokenizer_utils.PretrainedTokenizer`"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.vocab_size:1
msgid ""
"return the size of vocabulary. :returns: the size of vocabulary. :rtype: "
"int"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.preprocess_text:1
msgid "preprocess data by removing extra space and normalize data."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.clean_text:1
msgid "Performs invalid character removal and whitespace cleanup on text."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.encode_pieces:1
msgid "turn sentences into word pieces."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.tokenize:1
msgid ""
"End-to-end tokenization for BERT models. :param text: The text to be "
"tokenized. :type text: str"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.num_special_tokens_to_add
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.tokenize
msgid "返回"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.tokenize:5
msgid "A list of string representing converted tokens."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.convert_tokens_to_string
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.tokenize
msgid "返回类型"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.merge_subword:1
msgid "Merge subword."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.convert_tokens_to_string:1
msgid ""
"Converts a sequence of tokens (list of string) in a single string. Since "
"the usage of WordPiece introducing `__` to concat subwords, also remove "
"`__` when converting. :param tokens: A list of string representing tokens"
" to be converted. :type tokens: list"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.convert_tokens_to_string:7
msgid "Converted string from tokens."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.convert_ids_to_string:1
msgid "Convert ids to string."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.num_special_tokens_to_add:1
msgid ""
"Returns the number of added tokens when encoding a sequence with special "
"tokens. .. note::"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_inputs_with_special_tokens
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.num_special_tokens_to_add
msgid "参数"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.num_special_tokens_to_add:8
msgid ""
"Returns the number of added tokens in the case of a sequence pair if set "
"to True, returns the number of added tokens in the case of a single "
"sequence if set to False. Default False."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.num_special_tokens_to_add:14
msgid "Number of tokens added to sequences"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_inputs_with_special_tokens:1
msgid ""
"Build model inputs from a sequence or a pair of sequence by concatenating"
" and adding special tokens. An UnifiedTransformer sequence has the "
"following format: ::"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_inputs_with_special_tokens:7
msgid "List of IDs to which the special tokens will be added."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_inputs_with_special_tokens:10
msgid "Optional second list of IDs for sequence pairs. Default None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_inputs_with_special_tokens:14
msgid "List of input_ids with the appropriate special tokens."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens:1
msgid ""
"Build offset map from a pair of offset map by concatenating and adding "
"offsets of special tokens. An UnifiedTransformer offset_mapping has the "
"following format: ::"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens:8
msgid "List of char offsets to which the special tokens will be added."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens:11
msgid ""
"Optional second list of char offsets for offset mapping pairs. Dafault "
"None"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens:15
msgid "List of char offsets with the appropriate offsets of special     tokens."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens:17
msgid "List of char offsets with the appropriate offsets of special"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.build_offset_mapping_with_special_tokens:18
msgid "tokens."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences:1
msgid "Create the token_type_ids from the two sequences passed for the model."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences:3
msgid "An UnifiedTransformer sequence token_type_ids has the following format: ::"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences:9
msgid "If `token_ids_1` is None, this method only returns the first portion (0s)."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences:11
msgid "List of IDs."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences:13
msgid "Optional second list of IDs for sequence pairs. Default None"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.create_token_type_ids_from_sequences:17
msgid "List of token_type_id according to the given sequence(s)."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask:1
msgid ""
"Retrieve sequence ids from a token list that has no special tokens added."
" This method is called when adding special tokens using the tokenizer "
"``prepare_for_model`` method. :param token_ids_0: List of IDs. :type "
"token_ids_0: list :param token_ids_1: Optional second list of IDs for "
"sequence"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask:7
msgid "pairs. Default None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask:9
msgid ""
"Whether or not the token list is already formatted with special tokens "
"for the model. Default False."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask:14
msgid ""
"A list of integers in the range [0, 1]. 1 for a special token,     0 for "
"a sequence token."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask:16
msgid "A list of integers in the range [0, 1]. 1 for a special token,"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.get_special_tokens_mask:17
msgid "0 for a sequence token."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.save_resources:1
msgid ""
"Save tokenizer related resources to files under `save_directory`. :param "
"save_directory: Directory to save files into. :type save_directory: str"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary:1
msgid ""
"Instantiate an instance of `Vocab` from a file reserving all tokens by "
"using `Vocab.from_dict`. The file contains a token and index of the token"
" per line, separated by '  '. :param filepath: path of file to construct "
"vocabulary. :type filepath: str :param unk_token: special token for "
"unknown token. If no need, it also"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary:7
msgid "could be None. Default: None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary:9
msgid ""
"special token for padding token. If no need, it also could be None. "
"Default: None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary:12
msgid ""
"special token for bos token. If no need, it also could be None. Default: "
"None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary:15
msgid ""
"special token for eos token. If no need, it also could be None. Default: "
"None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary:18
msgid "keyword arguments for `Vocab.from_dict`."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.load_vocabulary:21
msgid "An instance of `Vocab`."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:1
msgid ""
"Main method to encode the single-turn or multi-turn dialogue "
"conversation. It will return a dictionary containing the encoded sequence"
" and other relative informations which meets the input format "
"requirements of the UnifiedTransformer model. See detail at "
"https://github.com/PaddlePaddle/Knover/tree/luge-dialogue/luge-dialogue"
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:8
msgid ""
"The history of dialogue conversation. It is an utterance or list of "
"utterances to be encoded. Each utterance is a string."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:12
msgid ""
"The response of dialogue conversation. It should be set when training the"
" model. It should not be set when running inference. Default None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:16
msgid ""
"The knowledge information of dialogue conversation. It should be set if "
"the `task_type` is \"knowledge\" or \"recommend\". Default None."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:20
msgid ""
"The type of dialogue conversation. It is one of \"chitchat\", "
"\"knowledge\" and \"recommend\". They represent the chitchat dialogue, "
"knowledge grounded dialogue and conversational recommendation "
"respectively. Default \"chitchat\"."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:25
msgid "The maximum encoded sequence length. Default 512."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:28
msgid "The maximum encoded sequence length of the input `response`. Default 128."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:31
msgid "The maximum encoded sequence length of the input `knowledge`. Default 128."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:34
msgid "Whether to return the position_ids. Default True."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:37
msgid "Whether to return the token_type_ids. Default True."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:40
msgid "Whether to return the attention_mask. Default True."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:43
msgid "Whether to return the length of the encoded sequence. Default False."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:46
msgid ""
"Whether to add the special token [CLS] at the end of sequence as the "
"begining of the response when running inference to force the model to "
"start generating response sequence. Default False."
msgstr ""

#: of
#: paddlenlp.transformers.unified_transformer.tokenizer.UnifiedTransformerTokenizer.dialogue_encode:51
msgid ""
"Whether to pad the returned sequences to the `max_seq_len`. Note that, in"
" this method, returned sequences will be padded on the left. Default "
"False."
msgstr ""

