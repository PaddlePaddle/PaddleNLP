# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, PaddleNLP
# This file is distributed under the same license as the PaddleNLP package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PaddleNLP \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-03-18 21:31+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../data_prepare/data_preprocess.rst:3
msgid "数据处理"
msgstr "Data Processing"

#: ../data_prepare/data_preprocess.rst:5
msgid ""
"Dataset中通常为原始数据，需要经过一定的数据处理并进行采样组batch，而后通过 :class:`paddle.io.DataLoader`"
" 为训练或预测使用，PaddleNLP中为其中各环节提供了相应的功能支持。"
msgstr ""
"Normally, there are raw data in the Dataset, they need to be pre-processed and batchified, then used with  :class:`paddle.io.DataLoader`"
"for the use in training and prediction, PaddleNLP provides all functionalities to support these requirements."

#: ../data_prepare/data_preprocess.rst:8
msgid "基于预训练模型的数据处理"
msgstr "Data processing based on pre-trained model"

#: ../data_prepare/data_preprocess.rst:10
msgid ""
"在使用预训练模型做NLP任务时，需要加载对应的Tokenizer，PaddleNLP在 :class:`PreTrainedTokenizer` "
"中内置的 :func:`__call__` 方法可以实现基础的数据处理功能。PaddleNLP内置的所有预训练模型的Tokenizer都继承自 "
":class:`PreTrainedTokenizer` ，下面以BertTokenizer举例说明："
msgstr ""
"In the task of NLP with a pre-trained model, the relevant Tokenizer needs to be loaded, the PaddleNLP built-in :class:`PreTrainedTokenizer` "
"has  :func:`__call__`  which has implemented some basic data processing functionalities. ALL Tokenizers from PaddleNLP inherite from :class:`PreTrainedTokenizer`,"
"let's take BertTokenizer as an example:"

#: ../data_prepare/data_preprocess.rst:28
msgid "关于 :func:`__call__` 方法的其他参数和功能，请查阅PreTrainedTokenizer。"
msgstr "For the details of parameters and functionalities of :func:`__call__`, please refer to PreTrainedTokenizer."

#: ../data_prepare/data_preprocess.rst:30
msgid ""
"paddlenlp内置的 :class:`paddlenlp.datasets.MapDataset` 的 :func:`map` "
"方法支持传入一个函数，对数据集内的数据进行统一转换。下面我们以 :obj:`LCQMC` 的数据处理流程为例："
msgstr ""
"The built-in :class:`paddlenlp.datasets.MapDataset` has :func:`map` which supports function as a pass-in parameter, this :func:`map` converts the data inside dataset."
"Let's the :obj:`LCQMC` as an example:"

#: ../data_prepare/data_preprocess.rst:42
msgid ""
"可以看到， :obj:`LCQMC` 是一个句对匹配任务，即判断两个句子的意思是否相似的2分类任务。我们需要处理的是key为 **query** "
"和 **title** 的文本数据，我们编写基于 :class:`PreTrainedTokenizer` 的数据处理函数并传入数据集的 "
":func:`map` 方法。"
msgstr ""
"As you can see above, :obj:`LCQMC` is a sentence matching task, i.e. a binary classification task which aims at identifying the similarity between two sentences."
"The data we need to process which have the keys **query** and **title** , we need to implement the data processing function which is based on  :class:`PreTrainedTokenizer` and then "
"pass it to the :func:`map`."

#: ../data_prepare/data_preprocess.rst:69
msgid "可以看到，数据集中的文本数据已经被处理成了模型可以接受的 *feature* 。"
msgstr "We can see above, that the text data in the dataset have been processed and converted to the *feature* which can be understood by models."

#: ../data_prepare/data_preprocess.rst:71
msgid ""
":func:`map` 方法有一个重要的参数 :attr:`batched`，当设置为 :obj:`True` 时（默认为 "
":obj:`False` ），数据处理函数 :func:`trans_func` 的输入不再是单条数据，而是数据集的所有数据："
msgstr ""
":func:`map` has an important parameter :attr:`batched`, when it is set to :obj:`True` (default :obj:`False`), the input of its data processing method :func:`trans_func` is not single data record, but the entire data in the dataset."

#: ../data_prepare/data_preprocess.rst:99
msgid ""
"可以看到，在本例中两种实现的结果是相同的。但是在诸如阅读理解，对话等任务中，一条原始数据可能会产生多个 *feature* 的情况（参见 "
"`run_squad.py "
"<https://github.com/PaddlePaddle/PaddleNLP/blob/develop/examples/machine_reading_comprehension/SQuAD/run_squad.py>`__"
" ）通常需要将 :attr:`batched` 参数设置为 :obj:`True` 。"
msgstr ""
"As you can see above, the results of the two approaches are the same. However, it could generate multiple **feature** for one raw data()"
" (refers to `run_squad.py <https://github.com/PaddlePaddle/PaddleNLP/blob/develop/examples/machine_reading_comprehension/SQuAD/run_squad.py>`__) "
". In this case, we need to set :attr:`batched` as :obj:`True` ."

#: ../data_prepare/data_preprocess.rst:101
msgid ""
":func:`map` 方法还有一个 :attr:`num_workers` "
"参数，当其大于0时进行多进程数据处理，可以提高处理速度。但是需要注意如果在数据处理的函数中用到了 **数据index** "
"的相关信息，多进程处理可能会导致错误的结果。"
msgstr ""
"There is another parameter called :attr:`num_workers` in :func:`map`, it will conduct multi-threading processing when this parameter set greater than 0."
"Pay attention to **data index** if you used it in the data processing function, the multi-threading processing could lead to errors."

#: ../data_prepare/data_preprocess.rst:103
msgid ""
"关于 :func:`map` 方法的其他参数和 :class:`paddlenlp.datasets.MapDataset` "
"的其他数据处理方法，请查阅 :doc:`dataset <../source/paddlenlp.datasets.dataset>` 。"
msgstr ""
"Regarding to the other parameters for  :func:`map` and usage of :class:`paddlenlp.datasets.MapDataset`, please refer to  :doc:`dataset <../source/paddlenlp.datasets.dataset>`."

#: ../data_prepare/data_preprocess.rst:106
msgid "Batchify"
msgstr ""

#: ../data_prepare/data_preprocess.rst:108
msgid ""
"PaddleNLP内置了多种collate function，配合 :class:`paddle.io.BatchSampler` "
"可以协助用户简单的完成组batch的操作。"
msgstr ""
"PaddleNLP has built in many collate functions, by using it with :class:`paddle.io.BatchSampler` users can do batchify easily."

#: ../data_prepare/data_preprocess.rst:110
msgid ""
"我们继续以 :obj:`LCQMC` 的数据处理流程为例。从上一节最后可以看到，处理后的单条数据是一个 **字典** ，包含 "
"`input_ids` ， `token_type_ids` 和 `label` 三个key。"
msgstr ""
"Let's the the data processing flow of :obj:`LCQMC` as an example. As we can see from the last section, the processed data is a **dict**, "
"which includes 3 keys: `input_ids` ， `token_type_ids` and `label`."

#: ../data_prepare/data_preprocess.rst:112
msgid ""
"其中 `input_ids` 和 `token_type_ids` 是需要进行 **padding** 操作后输入模型的，而 `label` "
"是需要 **stack** 之后传入loss function的。"
msgstr ""
"The `input_ids` and `token_type_ids` need to be processed by **padding** before feeding to the model, "
"for `label`, it needs to be **stacked** and then pass to the loss function."

#: ../data_prepare/data_preprocess.rst:114
msgid ""
"因此，我们使用PaddleNLP内置的 :func:`Dict` ，:func:`Stack` 和 :func:`Pad` "
"函数整理batch中的数据。最终的 :func:`batchify_fn` 如下："
msgstr ""
"Therefore, we need to use the PaddleNLP built-in methods, :func:`Dict` ，:func:`Stack` and :func:`Pad` to batchify the data."
"The final code of :func:`batchify_fn` looks like below:"

#: ../data_prepare/data_preprocess.rst:127
msgid ""
"之后使用 :class:`paddle.io.BatchSampler` 和 :func:`batchify_fn` 构建 "
":class:`paddle.io.DataLoader` ："
msgstr ""
"Then we use :class:`paddle.io.BatchSampler` and :func:`batchify_fn` to construct :class:`paddle.io.DataLoader` ："

#: ../data_prepare/data_preprocess.rst:137
msgid ""
"到此，一个完整的数据准备流程就完成了。关于更多batchify方法，请查阅 :doc:`collate "
"<../source/paddlenlp.data.collate>`。"
msgstr ""
"At this point, a complete data preparation process is completed. For more methods of batchify, please refer to :doc:`collate "
"<../source/paddlenlp.data.collate>`。"

#: ../data_prepare/data_preprocess.rst:141
msgid ""
"当需要进行 **单机多卡** 训练时，需要将 :class:`BatchSampler` 更换为 "
":class:`DistributedBatchSampler` 。更多有关 :class:`paddle.io.BatchSampler` "
"的信息，请查阅 `BatchSampler "
"<https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/fluid/dataloader/batch_sampler/BatchSampler_cn.html>`_。"
msgstr ""
"For the training with multiple GPUs on a single machine, we need to swap :class:`BatchSampler` with :class:`DistributedBatchSampler`."
"For more details about  :class:`paddle.io.BatchSampler` , please refer to `BatchSampler "
"<https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/fluid/dataloader/batch_sampler/BatchSampler_cn.html>`_."

#: ../data_prepare/data_preprocess.rst:143
msgid ""
"当需要诸如batch内排序，按token组batch等更复杂的组batch功能时。可以使用PaddleNLP内置的 "
":class:`SamplerHelper` 。相关用例请参考 `reader.py "
"<https://github.com/PaddlePaddle/PaddleNLP/blob/develop/examples/machine_translation/transformer/reader.py>`__。"
msgstr ""
"When we need to sort inside a batch, or grouping by tokens inside a batch, we can use the built-in :class:`SamplerHelper`."
"For more details, please refer to `reader.py <https://github.com/PaddlePaddle/PaddleNLP/blob/develop/examples/machine_translation/transformer/reader.py>`__."

#: ../data_prepare/data_preprocess.rst:146
msgid "基于非预训练模型的数据处理"
msgstr "Data Processing Based On The Non-pre-trained Model"

#: ../data_prepare/data_preprocess.rst:148
msgid ""
"在使用非预训练模型做NLP任务时，我们可以借助PaddleNLP内置的 :class:`JiebaTokenizer` 和 "
":class:`Vocab` 完成数据处理的相关功能，整体流程与使用预训练模型基本相似。我们以中文情感分析 :obj:`ChnSentiCorp`"
" 数据集为例："
msgstr ""
"When we use a non-pre-trained model to do NLP tasks, we can use the :class:`JiebaTokenizer` and :class:`Vocab` to do data processing,"
"the whole process is similar to the approach which uses the pre-trained models. Let's take the dataset of Chinese Sentiment Analysis :obj:`ChnSentiCorp` as an example:"

#: ../data_prepare/data_preprocess.rst:169
msgid ""
":class:`Vocab` 除了可以从本地词典文件初始化之外，还提供多种初始化方法，包括从 :class:`dictionary` "
"创建、从数据集创建等。详情请查阅Vocab。"
msgstr ""
":class:`Vocab` can be initialized with a local dict, it can also be initialized by many other ways, e.g. :class:`dictionary`, datasets etc. For more details please refer to Vocab."

#: ../data_prepare/data_preprocess.rst:170
msgid ""
"除了使用内置的 :class:`JiebaTokenizer` 外，用户还可以使用任何自定义的方式或第三方库进行分词，之后使用 "
":func:`Vocab.to_indices` 方法将token转为id。"
msgstr ""
"In addition to the use of the built-in :class:`JiebaTokenizer`, users can also use any custom or thrid-party libraries for tokenization, "
"then use :func:`Vocab.to_indices` to convert tokens to IDs."

#: ../data_prepare/data_preprocess.rst:172
msgid "之后与基于预训练模型的数据处理流程相似，编写数据处理函数并传入 :func:`map` 方法："
msgstr ""
"Then it is similar to the pre-trained model approach, we need to implement the data processing method and pass it to :func:`map` method:"

#: ../data_prepare/data_preprocess.rst:195
msgid ""
"可以看到，原始数据已经被处理成了 *feature* 。但是这里我们发现单条数据并不是一个 **字典** ，而是 **元组** 。所以我们的 "
":func:`batchify_fn` 也要相应的做一些调整："
msgstr ""
"As you can see above, the raw data have been converted to *feature*. Here, pay attention to the data, it is not a **dict**, but a **tuple**. "
"Thus, :func:`batchify_fn` needs to be adjusted accordingly:"

#: ../data_prepare/data_preprocess.rst:208
msgid ""
"可以看到，:func:`Dict` 函数是将单条数据中的键值与 :func:`Pad` 等函数进行对应，适用于单条数据是字典的情况。而 "
":func:`Tuple` 是通过单条数据中不同部分的index进行对应的。"
msgstr ""
"From the example we can see that, :func:`Dict` matches the key-value pairs to the :func:`Pad`, it is suitable for the case which the data is type of dict for a single data record."
"For :func:`Tuple`, it uses index in a data record. "

#: ../data_prepare/data_preprocess.rst:210
msgid "所以需要 **注意** 的是 :func:`convert_example` 方法和 :func:`batchify_fn` 方法的匹配。"
msgstr "Pay **attention** to the correlation between :func:`convert_example` and :func:`batchify_fn`."

#: ../data_prepare/data_preprocess.rst:212
msgid "之后的流程与基于预训练模型的数据处理相同。"
msgstr "The following steps are same to the approaches based on the pre-trained model."

