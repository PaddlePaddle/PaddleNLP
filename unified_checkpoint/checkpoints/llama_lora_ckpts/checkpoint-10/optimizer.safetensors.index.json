{
    "metadata": {
        "total_size": 10093440
    },
    "weight_map": {
        "llama.layers.0.self_attn.q_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.self_attn.q_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_A/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_B/moment1_0": "optimizer-00001-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_A/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_B/moment1_0": "optimizer-00002-of-00008.safetensors",
        "llama.layers.0.self_attn.q_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.self_attn.q_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_A/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_B/moment2_0": "optimizer-00003-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_A/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_B/moment2_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.0.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.1.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.2.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.3.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00004-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_A/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_B/moment1_0": "optimizer-00005-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_A/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_B/moment1_0": "optimizer-00006-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_A/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_B/moment2_0": "optimizer-00007-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_A/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_B/moment2_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_A/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_B/beta1_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.4.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.5.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.6.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.q_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.k_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.v_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.self_attn.o_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.gate_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.up_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_A/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors",
        "llama.layers.7.mlp.down_proj.lora_B/beta2_pow_acc_0": "optimizer-00008-of-00008.safetensors"
    },
    "master_weights": true
}