# Copyright (c) 2023 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import time

import arxiv
import gradio as gr

# from ulits import  single_paper_sum
from utils import merge_summary, pdf2image, single_paper_abs_sum, translation

from pipelines.document_stores import FAISSDocumentStore
from pipelines.nodes import (
    DensePassageRetriever,
    ErnieBot,
    ErnieRanker,
    PromptTemplate,
    TruncatedConversationHistory,
)

os.environ["no_proxy"] = "localhost,10.9.189.4,::1"
from create_base import chat_papers

from pipelines.pipelines import Pipeline

paper_all = []
index_name = "dureader_index"
import multiprocessing
from multiprocessing import Manager, Pool

manager = Manager()
all_data_result = manager.dict()
papers_sum = manager.list()


def clear_session():
    global all_data_result
    global paper_all
    all_data_result = {}
    paper_all = []
    return None, "https://arxiv.org/abs/2303.08774"


def chat_file(
    query,
    history=None,
    index_paper=None,
    api_key="",
    secret_key="",
):
    if history is None:
        history = []
    if index_paper is None:
        index = "document"
    else:
        index = index_paper.split("/")[-1].replace(".pdf", "").replace(".", "_")
    document_store = FAISSDocumentStore.load(index_name)
    retriever = DensePassageRetriever(
        document_store=document_store,
        query_embedding_model="moka-ai/m3e-base",
        passage_embedding_model="moka-ai/m3e-base",
        params_path="checkpoints/model_40/model_state.pdparams",
        output_emb_size=None,
        max_seq_len_query=64,
        max_seq_len_passage=256,
        batch_size=16,
        use_gpu=True,
        embed_title=False,
        pooling_mode="mean_tokens",
    )
    ranker = ErnieRanker(model_name_or_path="rocketqa-zh-dureader-cross-encoder", use_gpu=True)
    query_pipeline = Pipeline()
    query_pipeline.add_node(component=retriever, name="Retriever", inputs=["Query"])
    query_pipeline.add_node(component=ranker, name="Ranker", inputs=["Retriever"])
    query_pipeline.add_node(component=PromptTemplate("èƒŒæ™¯ï¼š{documents} é—®é¢˜ï¼š{query}"), name="Template", inputs=["Ranker"])
    query_pipeline.add_node(
        component=TruncatedConversationHistory(max_length=256), name="TruncateHistory", inputs=["Template"]
    )
    ernie_bot = ErnieBot(api_key=api_key, secret_key=secret_key)
    query_pipeline.add_node(component=ernie_bot, name="ErnieBot", inputs=["TruncateHistory"])
    prediction = query_pipeline.run(
        query=query, params={"Retriever": {"top_k": 30, "index": str(index)}, "Ranker": {"top_k": 3}}
    )
    history.append(["user: {}".format(query), "assistant: {}".format(prediction["result"])])
    return "", history, history


def tackle_paper(root_path, path, api_key, secret_key, lang="ç®€ä½“ä¸­æ–‡"):
    pdf_image = pdf2image(path, root_path)
    if lang == "English":
        translation_str, translation_file, sum_str, sum_file = translation(
            root_path, path, api_key=api_key, secret_key=secret_key
        )
        all_data_result[path.split("/")[-1].replace(".pdf", "").replace(".", "_")] = [
            pdf_image,
            path,
            translation_str,
            translation_file,
            sum_str,
            sum_file,
        ]
    else:
        data_split, sum_str, sum_file = single_paper_abs_sum(root_path, path, api_key=api_key, secret_key=secret_key)
        all_data_result[path.split("/")[-1].replace(".pdf", "").replace(".", "_")] = [
            pdf_image,
            path,
            "",
            None,
            sum_str,
            sum_file,
        ]
    papers_sum.append({"content": sum_str, "meta": {"name": path}})
    index = path.split("/")[-1].replace(".pdf", "").replace(".", "_")
    return index, data_split


def mul_tackle(
    p_m,
    root_path_list,
    path_list,
    api_key="",
    secret_key="",
    lang="ç®€ä½“ä¸­æ–‡",
):
    from functools import partial

    func = partial(tackle_paper, api_key=api_key, secret_key=secret_key, lang=lang)
    pool = Pool(processes=min(p_m, multiprocessing.cpu_count()))
    result = pool.starmap(func, [(root_path, path) for root_path, path in zip(root_path_list, path_list)])
    pool.close()
    pool.join()
    return result


def predict(
    file_upload,
    input1=None,
    lang="ç®€ä½“ä¸­æ–‡",
    api_key="",
    secret_key="",
):

    if os.path.exists("faiss_document_store.db"):
        os.remove("faiss_document_store.db")
    if os.path.exists(index_name):
        import shutil

        shutil.rmtree(index_name)
    if lang == "English":
        if file_upload:
            path_list = [path.name for path in file_upload]
            root_path_list = [os.path.dirname(path) for path in path_list]
        else:
            paths = input1.split(";")
            path_list = []
            root_path_list = ["./" for i in range(len(path_list))]
            root_path = root_path_list[0]
            for index, path_item in enumerate(paths):
                paper = next(arxiv.Search(id_list=[path_item.split("/")[-1]]).results())
                path_name = "{}.pdf".format(path_item.split("/")[-1])
                paper.download_pdf(dirpath=root_path, filename=path_name)
                path = os.path.join(root_path, path_name)
                path_list.append(path)
    else:
        path_list = [path.name for path in file_upload]
        root_path_list = [os.path.dirname(path) for path in path_list]
        document_store = FAISSDocumentStore(
            embedding_dim=768, faiss_index_factory_str="Flat", duplicate_documents="skip"
        )
        retriever = DensePassageRetriever(
            document_store=document_store,
            query_embedding_model="moka-ai/m3e-base",
            passage_embedding_model="moka-ai/m3e-base",
            output_emb_size=None,
            max_seq_len_query=64,
            max_seq_len_passage=256,
            batch_size=16,
            use_gpu=True,
            embed_title=False,
            pooling_mode="mean_tokens",
        )
    # import pdb;pdb.set_trace()
    multi_result = mul_tackle(
        p_m=3, root_path_list=root_path_list, path_list=path_list, api_key=api_key, secret_key=secret_key, lang=lang
    )
    for index, split_text in multi_result:
        split_text = retriever.run_indexing(split_text)[0]["documents"]
        document_store.write_documents(split_text, index=str(index))
        # document_store.update_embeddings(retriever,index=str(index))
        document_store.write_documents(split_text)
    # document_store.update_embeddings(retriever)
    document_store.save(index_name)
    mul_sum = merge_summary(papers_sum, api_key=api_key, secret_key=secret_key)
    file_name_sum = root_path_list[0] + "/" + "mul_papers_sum.txt"
    with open(file_name_sum, "w", encoding="utf-8") as f:
        f.write(mul_sum)
    return (
        gr.Textbox.update(value="å¯ä»¥å¼€å§‹chatfileåŠŸèƒ½"),
        gr.Textbox.update(value="å¯ä»¥å¼€å§‹chatfileåŠŸèƒ½"),
        gr.Textbox.update(value="å¯ä»¥å¼€å§‹chatfileåŠŸèƒ½"),
        mul_sum,
        file_name_sum,
    )


def tr_result(file_name):
    global all_data_result
    file_name = file_name.split("/")[-1].replace(".pdf", "").replace(".", "_")
    while True:
        if file_name in all_data_result.keys():
            tr_result = all_data_result[file_name]
            break
        else:
            time.sleep(60)
    return tr_result[:4]


def sum_result(file_name):
    global all_data_result
    file_name = file_name.split("/")[-1].replace(".pdf", "").replace(".", "_")
    while True:
        if file_name in all_data_result.keys():
            sum_result = all_data_result[file_name]
            break
        else:
            time.sleep(60)
    return sum_result[:2] + sum_result[4:]


def retriever_papers(
    query,
    history=None,
    api_key="",
    secret_key="",
    retriever_top=30,
    ranker_top=3,
):
    if history is not None:
        history = []
    message = chat_papers(
        query, api_key=api_key, secret_key=secret_key, retriever_top=retriever_top, ranker_top=ranker_top
    )
    # import pdb;pdb.set_trace()
    history.append(["user: {}".format(query), "assistant: {}".format(message["result"])])
    return "", history, history


def Dropdown_list(papers, inputs):
    global paper_all
    if papers is not None:
        paper_list = [paper.name.split("/")[-1] for paper in papers]
    else:
        paper_list = inputs.split(";")
    paper_all += [i for i in paper_list if i not in paper_all]
    return gr.Dropdown.update(choices=paper_all, value=paper_all[0]), gr.Dropdown.update(
        choices=paper_all, value=paper_all[0]
    )


with gr.Blocks() as demo:
    with gr.Tab("è®ºæ–‡ç¿»è¯‘æ€»ç»“"):
        with gr.Accordion("è®ºæ–‡ç¿»è¯‘ç²¾è¯»ï¼šè¾“å…¥åŒº", open=True, elem_id="input-panel") as area_input_primary:
            with gr.Row():
                file_upload = gr.inputs.File(label="(è¾“å…¥æ–¹å¼1) è¯·ä¸Šä¼ è®ºæ–‡PDF(ä»…æ”¯æŒPDFï¼Œæ”¯æŒå¤šç¯‡æ–‡ç« ç¿»è¯‘)", file_count="multiple")
                with gr.Accordion("(è¾“å…¥æ–¹å¼2) è¾“å…¥è®ºæ–‡çš„arxivé“¾æ¥ï¼ˆæ”¯æŒå¤šç¯‡æ–‡ç« ç¿»è¯‘ï¼Œé“¾æ¥ç›´æ¥ç”¨è‹±æ–‡;éš”å¼€ï¼‰"):
                    input1 = gr.Textbox(
                        label="", value="https://arxiv.org/abs/2303.08774", placeholder="", interactive=True
                    )
                    output1 = gr.Dropdown(choices=["ç®€ä½“ä¸­æ–‡", "English"], label="è¾“å‡ºè¯­è¨€")
                    output2 = gr.Dropdown(choices=["ç®€ä½“ä¸­æ–‡", "English"], label="è¾“å…¥è®ºæ–‡ç±»åˆ«", value="ç®€ä½“ä¸­æ–‡")
        with gr.Row():
            clear = gr.Button(value="æ¸…ç©ºè¾“å…¥åŒº")
            submit = gr.Button(value="å¼€å§‹ç¿»è¯‘ç²¾è¯»")

        with gr.Accordion("è®ºæ–‡ç¿»è¯‘æ€»ç»“ï¼šè¾“å‡ºåŒº", open=True, elem_id="input-panel") as area_input_primary:
            with gr.Tab("å•æ–‡ç¿»è¯‘"):  # åŒ…å«ä¸‹è½½åŠŸèƒ½
                file_name = gr.Dropdown(choices=[""], max_choices=1, label="é€‰æ‹©å±•ç¤ºè®ºæ–‡")
                with gr.Row():
                    with gr.Column():
                        gr.Dropdown(choices=["è‹±æ–‡", "ä¸­æ–‡"], max_choices=1, label="è®ºæ–‡åŸæ–‡-PDFæ’ä»¶-æ”¯æŒä¸‹è½½ï¼›æ­¤å¤„ä¸ºPDFå ä½ç¬¦")
                        ori_paper = gr.Gallery(label="è®ºæ–‡åŸæ–‡", show_label=False, elem_id="gallery").style(
                            columns=[2], rows=[2], object_fit="contain", height="auto"
                        )
                        ori_pdf = gr.File(label="åŸæ–‡ä¸‹è½½é“¾æ¥")
                    with gr.Accordion("   "):
                        gr.Dropdown(choices=["è‹±æ–‡", "ä¸­æ–‡"], max_choices=1, label="æ•´ä½“ç¿»è¯‘-PDFæ’ä»¶-æ”¯æŒä¸‹è½½ï¼›æ­¤å¤„ä¸ºPDFå ä½ç¬¦")
                        trans_paper = gr.Textbox(label="ç¿»è¯‘ç»“æœ", value="", max_lines=10)
                        trans_down = gr.File(label="ç¿»è¯‘ä¸‹è½½é“¾æ¥")
                        with gr.Group():
                            start_chatfile_tr = textbox = gr.Textbox(value="æš‚æ—¶æ— æ³•é—®ç­”", label="é—®ç­”å¯åŠ¨")
                            chatbot = gr.Chatbot(label="Chatbot")
                            state = gr.State()
                            with gr.Row():
                                textbox = gr.Textbox(
                                    container=False,
                                    show_label=False,
                                    placeholder="è¿™ç¯‡è®ºæ–‡æœ€å¤§çš„è´¡çŒ®æ˜¯ä»€ä¹ˆ?",
                                    scale=10,
                                )
                                submit_button = gr.Button("ğŸš€ æäº¤", variant="primary", scale=2, min_width=0)
                                submit_button.click(
                                    chat_file, inputs=[textbox, state, file_name], outputs=[textbox, chatbot, state]
                                )
            with gr.Tab("å•æ–‡æ€»ç»“"):  # åŒ…å«ä¸‹è½½åŠŸèƒ½
                file_sum = gr.Dropdown(choices=[""], max_choices=1, label="é€‰æ‹©è®ºæ–‡")
                with gr.Row():
                    with gr.Column():
                        gr.Dropdown(choices=["è‹±æ–‡", "ä¸­æ–‡"], max_choices=1, label="è®ºæ–‡åŸæ–‡-PDFæ’ä»¶-æ”¯æŒä¸‹è½½ï¼›æ­¤å¤„ä¸ºPDFå ä½ç¬¦")
                        ori_paper_c = gr.Gallery(label="è®ºæ–‡åŸæ–‡", show_label=False, elem_id="gallery").style(
                            columns=[2], rows=[2], object_fit="contain", height="auto"
                        )
                        ori_pdf_c = gr.File(label="åŸæ–‡ä¸‹è½½é“¾æ¥")
                    with gr.Accordion("   "):
                        gr.Dropdown(choices=["è‹±æ–‡", "ä¸­æ–‡"], max_choices=1, label="æ•´ä½“ç¿»è¯‘-PDFæ’ä»¶-æ”¯æŒä¸‹è½½ï¼Œæ­¤å¤„ä¸ºPDFå ä½ç¬¦")
                        sum_parper = gr.Markdown(label="ç²¾è¯»å…¨æ–‡", value="")
                        sum_down = gr.File(label="å…¨æ–‡ç²¾åº¦é“¾æ¥ ")
                        with gr.Group():
                            start_chatfile_sum = textbox = gr.Textbox(value="æš‚æ—¶æ— æ³•é—®ç­”", label="é—®ç­”å¯åŠ¨")
                            chatbot = gr.Chatbot(label="Chatbot")
                            state = gr.State()
                            with gr.Row():
                                textbox = gr.Textbox(
                                    container=False,
                                    show_label=False,
                                    placeholder="è¿™ç¯‡è®ºæ–‡æœ€å¤§çš„è´¡çŒ®æ˜¯ä»€ä¹ˆ?",
                                    scale=10,
                                )
                                submit_button = gr.Button("ğŸš€ æäº¤", variant="primary", scale=2, min_width=0)
                                submit_button.click(
                                    chat_file, inputs=[textbox, state, file_sum], outputs=[textbox, chatbot, state]
                                )
            with gr.Tab("å¤šæ–‡æ€»ç»“"):  # åŒ…å«ä¸‹è½½åŠŸèƒ½
                with gr.Accordion("   "):
                    gr.Dropdown(choices=["è‹±æ–‡", "ä¸­æ–‡"], max_choices=1, label="å®Œæ•´æ€»ç»“æ’ä»¶-æ”¯æŒä¸‹è½½ï¼Œæ­¤å¤„ä¸ºå¤šæ–‡æ€»ç»“å ä½ç¬¦ï¼Œéœ€è¦æ”¯æŒä¸Šä¸‹æ‹–åŠ¨")
                    sum_mul_papers = gr.Textbox(label="å¤šæ–‡æ¡£æ‘˜è¦", value="")
                    sum_mul_papers_down = gr.File(label="å…¨æ–‡ç²¾åº¦é“¾æ¥ ")
                    with gr.Group():
                        start_chatfile_mul = gr.Textbox(value="æš‚æ—¶æ— æ³•é—®ç­”", label="é—®ç­”å¯åŠ¨")
                        chatbot = gr.Chatbot(label="Chatbot")
                        state = gr.State()
                        with gr.Row():
                            textbox = gr.Textbox(
                                container=False,
                                show_label=False,
                                placeholder="è¿™ç¯‡è®ºæ–‡æœ€å¤§çš„è´¡çŒ®æ˜¯ä»€ä¹ˆ?",
                                scale=10,
                            )
                            submit_button = gr.Button("ğŸš€ æäº¤", variant="primary", scale=2, min_width=0)
                            submit_button.click(chat_file, inputs=[textbox, state], outputs=[textbox, chatbot, state])
            file_upload.change(Dropdown_list, inputs=[file_upload, input1], outputs=[file_name, file_sum])
            input1.change(Dropdown_list, inputs=[file_upload, input1], outputs=[file_name, file_sum])
            submit.click(
                predict,
                inputs=[file_upload, input1, output2],
                outputs=[
                    start_chatfile_tr,
                    start_chatfile_sum,
                    start_chatfile_mul,
                    sum_mul_papers,
                    sum_mul_papers_down,
                ],
            )
            clear.click(clear_session, inputs=[], outputs=[file_upload, input1])
            file_name.change(tr_result, inputs=file_name, outputs=[ori_paper, ori_pdf, trans_paper, trans_down])
            # file_name.change(tr_result,inputs=file_name,outputs=[ori_paper,ori_pdf,trans_paper,trans_down])
            file_sum.change(sum_result, inputs=file_sum, outputs=[ori_paper_c, ori_pdf_c, sum_parper, sum_down])

    with gr.Tab("æŠ€æœ¯ç»¼è¿°"):
        with gr.Group():
            chatbot = gr.Chatbot(label="Chatbot")
            with gr.Row():
                textbox = gr.Textbox(
                    container=False,
                    show_label=False,
                    placeholder="æŠ€æœ¯ç»¼è¿°è¾“å…¥æ¡†å£",
                    scale=10,
                )
                submit_button = gr.Button("ğŸš€ æäº¤", variant="primary", scale=2, min_width=0)

    with gr.Tab("å­¦æœ¯æ£€ç´¢"):
        with gr.Group():
            chatbot = gr.Chatbot(label="Chatbot")
            state = gr.State()
            with gr.Row():
                textbox = gr.Textbox(
                    container=False,
                    show_label=False,
                    placeholder="æ£€ç´¢å†…å®¹è¾“å…¥æ¡†å£",
                    scale=10,
                )
                submit_button = gr.Button("ğŸš€ æäº¤", variant="primary", scale=2, min_width=0)
            submit_button.click(retriever_papers, inputs=[textbox, state], outputs=[textbox, chatbot, state])
demo.launch(server_name="0.0.0.0", server_port=8084)
