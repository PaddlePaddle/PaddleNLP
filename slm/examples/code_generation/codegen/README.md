# ä»£ç ç”Ÿæˆï¼šå†™ä»£ç çš„ AI åŠ©ç†

**ç›®å½•**
- [ä»£ç ç”Ÿæˆ](#ä»£ç ç”Ÿæˆ)
  - [ç®€ä»‹](#ç®€ä»‹)
    - [ç‰¹è‰²](#ç‰¹è‰²)
  - [æ•ˆæœå±•ç¤º](#æ•ˆæœå±•ç¤º)
  - [Github Copilot æ’ä»¶é…ç½®](#GithubCopilot æ’ä»¶é…ç½®)
    - [ç¯å¢ƒä¾èµ–](#ç¯å¢ƒä¾èµ–)
    - [ä»£ç ç»“æ„è¯´æ˜](#ä»£ç ç»“æ„è¯´æ˜)
    - [å¯åŠ¨æœåŠ¡](#å¯åŠ¨æœåŠ¡)
      - [é…ç½®å‚æ•°](#é…ç½®å‚æ•°è¯´æ˜)
    - [æµ‹è¯•æœåŠ¡](#æµ‹è¯•æœåŠ¡)
    - [é…ç½®æ’ä»¶](#é…ç½®æ’ä»¶)
    - [æ³¨æ„äº‹é¡¹](#æ³¨æ„äº‹é¡¹)
  - [è®­ç»ƒå®šåˆ¶](#è®­ç»ƒå®šåˆ¶)
    - [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
      - [ä»æœ¬åœ°æ–‡ä»¶åˆ›å»ºæ•°æ®é›†](#ä»æœ¬åœ°æ–‡ä»¶åˆ›å»ºæ•°æ®é›†)
    - [æ¨¡å‹è®­ç»ƒ](#æ¨¡å‹è®­ç»ƒ)
  - [TaskFlow è°ƒç”¨](#TaskFlow è°ƒç”¨)
  - [æ›´å¤šä½¿ç”¨æ¡ˆä¾‹](#æ›´å¤šä½¿ç”¨æ¡ˆä¾‹)
  - [æ¨¡å‹åˆ—è¡¨](#æ¨¡å‹åˆ—è¡¨)
  - [References](#references)


## ç®€ä»‹
ä»£ç ç”Ÿæˆæ˜¯æ ¹æ®ç¼–ç¨‹äººå‘˜çš„è¾“å…¥ï¼Œç”Ÿæˆå‡ºç¼–ç¨‹äººå‘˜æƒ³è¦çš„ä»£ç ï¼Œèƒ½å¤Ÿå¸®åŠ©ç¼–ç¨‹äººå‘˜ç”šè‡³ç‹¬ç«‹ç”Ÿæˆä»£ç ï¼Œæé«˜ç¼–ç¨‹æ•ˆç‡ã€‚


### ç‰¹è‰²

æœ¬é¡¹ç›®æ˜¯åŸºäºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ CodeGen çš„ä»£ç ç”Ÿæˆï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š
- **æ•ˆæœé¢†å…ˆ**ã€‚CodeGenï¼ˆ16Bï¼‰åœ¨ HumanEval benchmark ä¸Šè¯„ä¼°æŒ‡æ ‡å·²ç»è¶…è¿‡[OpenAI's Codex](https://arxiv.org/pdf/2107.03374.pdf)ã€‚
- **å…è´¹çš„ Github Copilot**ã€‚æ”¯æŒé€šè¿‡ Github Copilot è°ƒç”¨è¯¥æ¨¡å‹ï¼Œè®©ä½ å…è´¹ä½“éªŒä»£ç  AI åŠ©ç†ã€‚
- **æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒ**ã€‚å¯å¢åŠ è‡ªå·±çš„ä»£ç æ•°æ®åŠ ä»¥å¾®è°ƒï¼Œè®©å…¶æ›´æ™ºèƒ½ã€‚
- **å¼€ç®±å³ç”¨**ã€‚æœ¬é¡¹ç›®æä¾› TaskFlow æ¥å£ï¼Œæ— éœ€è®­ç»ƒï¼Œä»…éœ€å‡ è¡Œä»£ç ä¾¿å¯é¢„æµ‹ã€‚


## æ•ˆæœå±•ç¤º

- Github Copilot ä»£ç æç¤ºæ•ˆæœå±•ç¤º
<p align="center">
<img src="https://user-images.githubusercontent.com/24390500/189046785-6c04a3c3-ce89-4684-9aff-a7dc2e7a7041.gif"/> <br />
</p>

- è§£ç®—æ³•é¢˜æ•ˆæœå±•ç¤ºã€‚æ±‚è§£æ— é‡å¤å­—ç¬¦çš„æœ€é•¿å­ä¸²çš„é•¿åº¦
```python
from paddlenlp import Taskflow

prompt = "def lengthOfLongestSubstring(self, s: str) -> int:"
codegen = Taskflow("code_generation", model="Salesforce/codegen-2B-mono",decode_strategy="greedy_search", repetition_penalty=1.0)
print(codegen(prompt))
```
ç»“æœè¾“å‡ºä¸ºï¼š
```python
        if not s:
            return 0

        start = 0
        end = 0
        max_len = 0

        while end < len(s):
            if s[end] not in s[start:end]:
                max_len = max(max_len, end - start + 1)
                end += 1
            else:
                start += 1

        return max_len
```
<p align="center">
<img src="https://user-images.githubusercontent.com/24390500/182512164-946d959c-57b1-49e6-b9a5-be47281d1ee2.png"/> <br />
</p>


## Jupyter Lab æ’ä»¶é…ç½®

è¯·å‚è€ƒ[codegenJupyterLabExt](https://github.com/chenqianhe/codegenJupyterLabExt), æ„Ÿè°¢ç”Ÿæ€å¼€å‘è€…[@chenqianhe](https://github.com/chenqianhe)çš„è´¡çŒ®ï¼ğŸ‘ğŸ‘

## GithubCopilot æ’ä»¶é…ç½®

**ä»¥ VS Code çš„æ’ä»¶ä¸ºä¾‹**

### ç¯å¢ƒä¾èµ–
- PaddleNLP >= 2.4.0
- PaddlePaddle >= 2.3.1

å…¶ä»–ä¾èµ–ï¼š`pip install -r requirements.txt`

### ä»£ç ç»“æ„è¯´æ˜

ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®ä¸»è¦ä»£ç ç»“æ„åŠè¯´æ˜ï¼š

```text
codegen/
â”œâ”€â”€ requirements.txt # ç¯å¢ƒä¾èµ–
â”œâ”€â”€ codegen_server.py # serverå¯åŠ¨è„šæœ¬
â”œâ”€â”€ run_clm.py # è®­ç»ƒè¯„ä¼°è„šæœ¬
â”œâ”€â”€ run_clm.sh # å¯åŠ¨è„šæœ¬
â””â”€â”€ README.md # è¯´æ˜æ–‡æ¡£
```

### å¯åŠ¨æœåŠ¡

```python
python codegen_server.py
```

##### é…ç½®å‚æ•°è¯´æ˜
åœ¨ codegen_server.py ä¸­é…ç½®å¦‚ä¸‹å‚æ•°ï¼š
- `model_name_or_path`ï¼šæ¨¡å‹åï¼Œé»˜è®¤ä¸º "Salesforce/codegen-350M-mono"
- `device`ï¼šè¿è¡Œè®¾å¤‡ï¼Œé»˜è®¤ä¸º"gpu"
- `temperature`ï¼šè§£ç å‚æ•° temperatureï¼Œé»˜è®¤ä¸º0.5
- `top_k`ï¼šè§£ç å‚æ•° top_kï¼Œé»˜è®¤ä¸º10
- `top_p`ï¼šè§£ç å‚æ•° top_pï¼Œé»˜è®¤ä¸º1.0
- `repetition_penalty`ï¼šè§£ç é‡å¤æƒ©ç½šé¡¹ï¼Œé»˜è®¤ä¸º1.0
- `min_length`ï¼šç”Ÿæˆçš„æœ€å°é•¿åº¦ï¼Œé»˜è®¤ä¸º0
- `max_length`ï¼šç”Ÿæˆçš„æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ä¸º16
- `decode_strategy`ï¼šè§£ç ç­–ç•¥ï¼Œé»˜è®¤ä¸º"greedy_search"
- `use_fast`ï¼šæ˜¯å¦ä½¿ç”¨ FastGenerationï¼Œå¯åŠ é€Ÿæ¨ç†ï¼Œé»˜è®¤ä¸º True
- `use_fp16_decoding`ï¼šæ˜¯å¦ä½¿ç”¨ fp16æ¨ç†ï¼Œå¯èŠ‚çœæ˜¾å­˜å’ŒåŠ é€Ÿæ¨ç†ï¼Œé»˜è®¤ä¸º True

### æµ‹è¯•æœåŠ¡
```python
import openai
openai.api_key = 'dummy'
openai.api_base = 'http://127.0.0.1:8978'
result = openai.Completion.create(
    engine='codegen', prompt='def hello', max_tokens=16, temperature=0.1)
print(result)
'''
<OpenAIObject text_completion id=cmpl-dmhoeHmcw9DJ4NeqOJDQVKv3iivJ0 at 0x7fe7a81d42c0> JSON: {
  "id": "cmpl-dmhoeHmcw9DJ4NeqOJDQVKv3iivJ0",
  "choices": [
    {
      "text": "_world():\n    print(\"Hello World!\")\n\n\n#",
      "index": 0,
      "finish_reason": "stop",
      "logprobs": null,
    }
  ],
  "usage": {
    "completion_tokens": null,
    "prompt_tokens": null,
    "total_tokens": null
  }
}
'''
```
**æ³¨æ„**ï¼šå¦‚æœè¦ä»æœ¬åœ°è®¿é—®æœåŠ¡å™¨ï¼Œ`127.0.0.1`éœ€è¦æ¢æˆæœåŠ¡å™¨çš„å¯¹å¤– IPã€‚


### é…ç½®æ’ä»¶
æ‰“å¼€ç”¨æˆ·è®¾ç½®ï¼ˆ[settings.json](https://code.visualstudio.com/docs/getstarted/settings#_settings-file-locations)ï¼‰ï¼Œå¢åŠ ä¸€è¡Œé…ç½®
```json
    "github.copilot.advanced": {
        "debug.overrideEngine": "codegen",
        "debug.testOverrideProxyUrl": "http://127.0.0.1:8978",
        "debug.overrideProxyUrl": "http://127.0.0.1:8978"
    },
```
æ¥ä¸‹æ¥å°±å¯ä»¥æ„‰å¿«åœ°ä½¿ç”¨äº†ğŸ˜Šã€‚


#### æ³¨æ„äº‹é¡¹
- å¦‚æœä½¿ç”¨ FastGenerationï¼Œéœ€è¦è®¾ç½®[codegen_server.py](#é…ç½®å‚æ•°è¯´æ˜)ä¸­`use_fast=True`ï¼Œç¬¬ä¸€æ¬¡æ¨ç†ä¼šæ¶‰åŠåˆ°ç¼–è¯‘ï¼Œä¼šè€—è´¹ä¸€äº›æ—¶é—´ã€‚
- å¦‚æœè¦ä½¿ç”¨è‡ªå·±è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯ä»¥è®¾ç½®[codegen_server.py](#é…ç½®å‚æ•°è¯´æ˜)ä¸­`model_name_or_path`ä¸ºæœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚
- å¦‚æœè¦ä»æœ¬åœ°è®¿é—®æœåŠ¡å™¨ï¼Œä¸Šè¿°çš„`127.0.0.1`éœ€è¦æ¢æˆæœåŠ¡å™¨çš„å¯¹å¤– IPã€‚
- å¦‚æœå‡ºç°ä¸‹æ–¹çš„æç¤ºå’ŒæŠ¥é”™ï¼Œåˆ™è¯´æ˜ FastGeneration æ²¡æœ‰å¯åŠ¨æˆåŠŸï¼Œéœ€è¦å®šä½ä¸‹å¤±è´¥çš„åŸå› ã€‚æˆ–è€…ä¹Ÿå¯è®¾ç½®`use_fast=False`ï¼Œä¸å¯åŠ¨ FastGeneration åŠ é€Ÿï¼Œä½†æ¨ç†é€Ÿåº¦ä¼šè¾ƒæ…¢ã€‚
```shell
  FastGeneration is not available, and the original version would be used instead.
```
```shell
  RuntimeError: (NotFound) There are no kernels which are registered in the unsqueeze2 operator.
  [Hint: Expected kernels_iter != all_op_kernels.end(), but received kernels_iter == all_op_kernels.end().] (at /home/Paddle/paddle/fluid/imperative/prepared_operator.cc:341)
  [operator < unsqueeze2 > error]
```
- æœ¬ä»£ç ä¹Ÿæ”¯æŒæ’ä»¶[fauxpilot](https://marketplace.visualstudio.com/items?itemName=Venthe.fauxpilot)ï¼Œæ„Ÿè°¢[@linonetwo](https://github.com/linonetwo)æµ‹è¯•ã€‚`settings.json`ä¸­é…ç½®"fauxpilot.server": "http://æœåŠ¡å™¨ ip:8978/v1/engines"

## è®­ç»ƒå®šåˆ¶

### æ•°æ®å‡†å¤‡

#### ä»æœ¬åœ°æ–‡ä»¶åˆ›å»ºæ•°æ®é›†

åœ¨è®¸å¤šæƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æœ¬åœ°æ•°æ®é›†æ¥è®­ç»ƒæˆ‘ä»¬çš„ä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œæœ¬é¡¹ç›®æ”¯æŒä½¿ç”¨å›ºå®šæ ¼å¼æœ¬åœ°æ•°æ®é›†æ–‡ä»¶è¿›è¡Œè®­ç»ƒã€‚

æœ¬åœ°æ•°æ®é›†æ–‡ä»¶æ ¼å¼å¦‚ä¸‹ï¼š
- train.json/test.json æ–‡ä»¶æ ¼å¼ï¼š
æ¯è¡Œä¸ºä¸€ä¸ª jsonline
```text
{
    "code": "from paddlenlp.transformers import CodeGenForCausalLM\n\n\nmodel = CodeGenForCausalLM.from_pretrained('Salesforce/codegen-2B-mono')\n"
}
```

æ›´å¤šæ•°æ®é›†è¯»å–æ ¼å¼è¯¦è§[æ•°æ®é›†åŠ è½½](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_load.html#)å’Œ[è‡ªå®šä¹‰æ•°æ®é›†](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_self_defined.html)ã€‚


### æ¨¡å‹è®­ç»ƒ
è¿è¡Œå¦‚ä¸‹å‘½ä»¤å³å¯åœ¨æ ·ä¾‹è®­ç»ƒé›†ä¸Šè¿›è¡Œ finetuneï¼Œå¹¶åœ¨æ ·ä¾‹éªŒè¯é›†ä¸Šè¿›è¡ŒéªŒè¯ã€‚

```shell
# GPUå¯åŠ¨ï¼Œå‚æ•°`--gpus`æŒ‡å®šè®­ç»ƒæ‰€ç”¨çš„GPUå¡å·ï¼Œå¯ä»¥æ˜¯å•å¡ï¼Œä¹Ÿå¯ä»¥å¤šå¡
unset CUDA_VISIBLE_DEVICES

python -m paddle.distributed.launch --gpus 0,1 run_clm.py \
            --model_name_or_path Salesforce/codegen-350M-mono \
            --block_size 1024 \
            --output_dir output \
            --train_file train.json \
            --validation_file test.json \
            --num_train_epochs 5 \
            --logging_steps 10 \
            --save_steps 1000 \
            --per_device_train_batch_size 2 \
            --per_device_eval_batch_size 2 \
            --learning_rate 1e-4 \
            --warmup_ratio 0.1 \
            --do_train \
            --do_eval \
            --device gpu
```
ä½¿ç”¨å¤šå¡è®­ç»ƒå¯ä»¥æŒ‡å®šå¤šä¸ª GPU å¡å·ï¼Œä¾‹å¦‚ --gpus "0,1"

å…³é”®å‚æ•°é‡Šä¹‰å¦‚ä¸‹ï¼š
- `gpus` æŒ‡ç¤ºäº†è®­ç»ƒæ‰€ç”¨çš„ GPU å¡å·ã€‚
- `model_name_or_path` æŒ‡ç¤ºäº† finetune ä½¿ç”¨çš„å…·ä½“é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥æ˜¯ PaddleNLP æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆè¯¦è§[æ¨¡å‹åˆ—è¡¨](#æ¨¡å‹åˆ—è¡¨)ï¼‰ï¼Œæˆ–è€…æ˜¯æœ¬åœ°çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚å¦‚æœä½¿ç”¨æœ¬åœ°çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥é…ç½®æœ¬åœ°æ¨¡å‹çš„ç›®å½•åœ°å€ï¼Œä¾‹å¦‚: ./checkpoints/model_xx/ï¼Œç›®å½•ä¸­éœ€åŒ…å« paddle é¢„è®­ç»ƒæ¨¡å‹ model_state.pdparamsã€‚å¦‚æœä½¿ç”¨ PaddleNLP æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥é€‰æ‹©ä¸‹é¢å…¶ä¸­ä¹‹ä¸€ã€‚
- `block_size` è¡¨ç¤ºè®­ç»ƒæ—¶å€™æ•°æ®è¢«æ‹†åˆ†çš„å—æ•°ã€‚
- `output_dir` è¡¨ç¤ºæ¨¡å‹çš„ä¿å­˜è·¯å¾„ã€‚
- `train_file` æœ¬åœ°è®­ç»ƒæ•°æ®åœ°å€ï¼Œæ•°æ®æ ¼å¼å¿…é¡»ä¸`dataset_name`æ‰€æŒ‡æ•°æ®é›†æ ¼å¼ç›¸åŒã€‚
- `validation_file` æœ¬åœ°æµ‹è¯•æ•°æ®åœ°å€ï¼Œæ•°æ®æ ¼å¼å¿…é¡»ä¸`dataset_name`æ‰€æŒ‡æ•°æ®é›†æ ¼å¼ç›¸åŒã€‚
- `num_train_epochs` è¡¨ç¤ºè®­ç»ƒè½®æ•°ã€‚
- `logging_steps` è¡¨ç¤ºæ—¥å¿—æ‰“å°é—´éš”ã€‚
- `save_steps` è¡¨ç¤ºæ¨¡å‹ä¿å­˜åŠè¯„ä¼°é—´éš”ã€‚
- `per_device_train_batch_size` è¡¨ç¤ºè®­ç»ƒæ—¶**æ¯å¼ å¡**ä¸Šçš„æ ·æœ¬æ•°ç›®ã€‚
- `per_device_eval_batch_size` è¡¨ç¤ºæµ‹è¯•æ—¶**æ¯å¼ å¡**ä¸Šçš„æ ·æœ¬æ•°ç›®ã€‚
- `learning_rate` è¡¨ç¤ºåŸºç¡€å­¦ä¹ ç‡å¤§å°ï¼Œå°†äº learning rate scheduler äº§ç”Ÿçš„å€¼ç›¸ä¹˜ä½œä¸ºå½“å‰å­¦ä¹ ç‡ã€‚
- `warmup_ratio` è¡¨ç¤ºå­¦ä¹ ç‡é€æ¸å‡é«˜åˆ°åŸºç¡€å­¦ä¹ ç‡ï¼ˆå³ä¸Šé¢é…ç½®çš„ learning_rateï¼‰æ‰€éœ€è¦çš„è¿­ä»£æ•°å æ€»æ­¥æ•°çš„æ¯”ä¾‹ï¼Œæœ€æ—©çš„ä½¿ç”¨å¯ä»¥å‚è€ƒ[è¿™ç¯‡è®ºæ–‡](https://arxiv.org/pdf/1706.02677.pdf)ã€‚
- `do_train` è¡¨ç¤ºæ˜¯å¦è®­ç»ƒã€‚
- `do_eval` è¡¨ç¤ºæ˜¯å¦è¯„æµ‹ã€‚
- `device` è¡¨ç¤ºä½¿ç”¨çš„è®¾å¤‡ï¼Œä» gpu å’Œ cpu ä¸­é€‰æ‹©ã€‚

å¯é€šè¿‡`bash run_clm.sh`å¯åŠ¨è®­ç»ƒï¼Œæ›´å¤šå‚æ•°è¯¦æƒ…å’Œå‚æ•°çš„é»˜è®¤å€¼è¯·å‚è€ƒ`run_clm.py`ã€‚

ç¨‹åºè¿è¡Œæ—¶å°†ä¼šè‡ªåŠ¨è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ä¿å­˜æ¨¡å‹åœ¨æŒ‡å®šçš„`save_dir`ä¸­ã€‚
å¦‚ï¼š
```text
./output/
â”‚â”€â”€ model_config.json
â”‚â”€â”€ model_state.pdparams
â”‚â”€â”€ tokenizer_config.json
â”‚â”€â”€ special_tokens_map.json
â”‚â”€â”€ added_tokens.json
â”‚â”€â”€ vocab.json
â”‚â”€â”€ merges.txt
â””â”€â”€ ...
```

**NOTE:** å¦‚éœ€æ¢å¤æ¨¡å‹è®­ç»ƒï¼Œ`model_name_or_path`é…ç½®æœ¬åœ°æ¨¡å‹çš„ç›®å½•åœ°å€å³å¯ã€‚


## TaskFlow è°ƒç”¨
å‚è€ƒ[TaskFlow æ–‡æ¡£](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/model_zoo/taskflow.md)

## æ›´å¤šä½¿ç”¨æ¡ˆä¾‹

- æ ¹æ®æ³¨é‡Š/åŠŸèƒ½æè¿°å†™ä»£ç 

```python
import re
import paddle
from paddlenlp.transformers import CodeGenTokenizer, CodeGenForCausalLM

# The supported models are shown in the following table
model_name = 'Salesforce/codegen-2B-mono'
# Init tokenizer
tokenizer = CodeGenTokenizer.from_pretrained(model_name)
# Init model
model = CodeGenForCausalLM.from_pretrained(model_name)

prompt = "# this function prints hello world"
inputs = tokenizer([prompt])
inputs = {k: paddle.to_tensor(v) for (k, v) in inputs.items()}
# Generate
output, score = model.generate(inputs['input_ids'],
                               max_length=128,
                               decode_strategy='greedy_search')
# Decode the result
print(
    tokenizer.decode(output[0],
                     truncate_before_pattern=[r"\n\n^#", "^'''", "\n\n\n"],
                     skip_special_tokens=True,
                     spaces_between_special_tokens=False))
```
ç»“æœè¾“å‡ºä¸ºï¼š
```python
def hello_world():
    print("Hello World")

hello_world()
```

## æ¨¡å‹åˆ—è¡¨
æ¨¡å‹åˆ—è¡¨
| æ¨¡å‹åç§°                           | è¯´æ˜                         |
| :--------------------------------- | -------------------------------- |
| Salesforce/codegen-350M-mono             | åŸºäº Python æ•°æ®é›† BIGPYTHON è®­ç»ƒ  |
| Salesforce/codegen-2B-mono             | åŸºäº Python æ•°æ®é›† BIGPYTHON è®­ç»ƒ  |
| Salesforce/codegen-6B-mono             | åŸºäº Python æ•°æ®é›† BIGPYTHON è®­ç»ƒ  |
| Salesforce/codegen-16B-mono             | åŸºäº Python æ•°æ®é›† BIGPYTHON è®­ç»ƒ  |
| Salesforce/codegen-350M-nl             | åŸºäºè‡ªç„¶è¯­è¨€æ•°æ®é›† THEPILE è®­ç»ƒ  |
| Salesforce/codegen-2B-nl             | åŸºäºè‡ªç„¶è¯­è¨€æ•°æ®é›† THEPILE è®­ç»ƒ  |
| Salesforce/codegen-6B-nl             | åŸºäºè‡ªç„¶è¯­è¨€æ•°æ®é›† THEPILE è®­ç»ƒ  |
| Salesforce/codegen-16B-nl             | åŸºäºè‡ªç„¶è¯­è¨€æ•°æ®é›† THEPILE è®­ç»ƒ  |
| Salesforce/codegen-350M-multi             | åŸºäºå¤šç¼–ç¨‹è¯­è¨€æ•°æ®é›† BIGQUERY è®­ç»ƒ  |
| Salesforce/codegen-2B-multi            | åŸºäºå¤šç¼–ç¨‹è¯­è¨€æ•°æ®é›† BIGQUERY è®­ç»ƒ  |
| Salesforce/codegen-6B-multi             | åŸºäºå¤šç¼–ç¨‹è¯­è¨€æ•°æ®é›† BIGQUERY è®­ç»ƒ  |
| Salesforce/codegen-16B-multi             | åŸºäºå¤šç¼–ç¨‹è¯­è¨€æ•°æ®é›† BIGQUERY è®­ç»ƒ  |

## References
- Nijkamp, Erik, et al. "A conversational paradigm for program synthesis." arXiv preprint arXiv:2203.13474 (2022).
- [https://github.com/features/copilot/](https://github.com/features/copilot/)
- [https://github.com/AndPuQing/Papilot](https://github.com/AndPuQing/Papilot)
