# onnxruntime 后端
platform: "onnxruntime_onnx"
max_batch_size: 64
input [
    {
      name: "input_ids"
      data_type: TYPE_INT64
      dims: [ -1 ]
    },
    {
      name: "token_type_ids"
      data_type: TYPE_INT64
      dims: [ -1 ]
    }
]
output [
    {
      name: "linear_113.tmp_1"
      data_type: TYPE_FP32
      dims: [ 15 ]
    }
]

instance_group [
  {
      # 创建1个实例
      count: 1
      # 使用GPU推理(KIND_CPU、KIND_GPU)
      kind: KIND_GPU
  }
]

optimization { 
  # 图优化级别: 默认开启所有优化，-1开启基本优化，1开启额外扩展优化(比如fuse)
  graph: {level: 1}
}

# 设置节点内并行的线程数， 0代表采用默认值，即CPU核心数
parameters { key: "intra_op_thread_count" value: { string_value: "0" } }
# 设置执行图时顺序执行还是并行执行，0表示顺序，1表示并行(适合分支很多的模型)
parameters { key: "execution_mode" value: { string_value: "0" } }
# 设置并行执行图的线程数，当execution_mode设置为1时才生效
parameters { key: "inter_op_thread_count" value: { string_value: "0" } }
