msra_ner:
  model_name_or_path: gpt-cpm-small-cn-distill
  max_seq_length: 128
  per_device_eval_batch_size: 32
  learning_rate: 2e-5
  num_train_epochs: 3
  logging_steps: 25
  save_steps: 250
  output_dir: ./tmp/msra_ner/
  device: gpu 
  do_train: true

glue:
  model_name_or_path: gpt2-medium-en
  task_name: SST-2
  max_seq_length: 128
  per_device_train_batch_size: 32  
  learning_rate: 2e-5
  num_train_epochs: 3
  logging_steps: 1
  save_steps: 500
  output_dir: ./output_dir/glue
  eval_steps: 1
  device: gpu
  do_train: true

pretrain:
  model_name_or_path: gpt2-en
  input_dir: ./data
  output_dir: ./output_dir/pretrain
  weight_decay: 0.01
  max_steps: 500000
  save_steps: 100000
  device: gpu
  lr_decay_style: none
  warmup_steps: 320000
  warmup_ratio: 0.01
  per_device_train_batch_size: 4
  eval_steps: 100
  do_train: true
  do_predict: true

generation:
  model_type: gpt2-cn
  model_name_or_path: gpt-cpm-small-cn-distill
