## Ernie 4D hybrid parallelism pretrain

ERNIE千亿级模型采用100多层transformer网络结构，计算复杂，训练需要占用T级显存资源，如果想用更少的机器高效训练，必须采取一系列性能优化和显存优化措施。

### ERNIE 模型简介
TODO

### 使用方法
TODO
```shell

# 下载样例数据集，并解压
wget https://paddlenlp.bj.bcebos.com/data/ernie_hybrid_parallelism_data.tar
tar -xvf ernie_hybrid_parallelism_data.tar

# 运行Pretrain 脚本
sh pretrain.sh
```


### 4D 并行原理介绍

首先看如何性能优化。我们通过一个公式来看哪些因素可以影响训练速度，在固定的硬件环境下：

```
总训练速度∝单卡速度∗卡数∗多卡加速比
```

其中单卡速度由数据读取和计算速度决定；多卡加速比由计算/通信效率决定。显而易见，这三个是关键因素。除了单卡可以使用的算子融合、混合精度之类的基础性能优化策略之外，分布式训练还引入一系列并行策略。并行策略的核心思想是将数据和计算有关的图/算子切分到不同设备上，同时尽可能降低设备间通信所需的代价，合理使用多台设备资源，实现高效的并发调度训练，最大化提升训练速度。常见并行策略有数据并行DP（Data Parallel）、Layer间并行（流水线并行PP，Pipeline Parallel）、Layer内并行（模型并行MP，Model Parallel）。我们从设备资源和计算/通信效率来分析三种策略的优缺点：

- 数据并行训练加速比最高，但要求每个设备上都备份一份模型，显存占用比较高。为此我们的改进方案是分组参数切片数据并行策略（具体原理后文介绍），兼容了MP+DP的优势，但缺点是通信量大。

- 模型并行，通信量比较高，适合在机器内做模型并行。

- 流水线并行，训练设备容易出现空闲状态，加速效率没有DP高；但能减少通信边界支持更多的层数，适合在机器间使用。

其次看显存问题，通过下表分析的显存占用来源可以看出，上述的并行策略同样可以很好的应对不同来源的显存占用，更多的层数可以通过流水线并行和分组参数切分策略来解决；某层参数很大可以通过模型并行来解决；其次飞桨还提供一些其它灵活的优化方式，例如每层输出占用的显存，可以通过重计算和offload来解决。

综上所述，针对性能优化和显存优化，几种并行策略都有用武之地，但是同时也有各自的局限性，所以如果想高效训练千亿模型，需要这几种策略相互组合，取长补短，发挥各自的优势。

### 参考文献
TODO
