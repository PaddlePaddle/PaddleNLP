## ğŸš£â€â™‚ï¸ ä½¿ç”¨PaddleNLPåœ¨XPUä¸‹è·‘é€šllama2-7bæ¨¡å‹  ğŸš£
PaddleNLPåœ¨æ˜†ä»‘XPUï¼ˆ[äº†è§£æ˜†ä»‘](https://www.kunlunxin.com/)ï¼‰ä¸Šå¯¹llama2-7Bæ¨¡å‹è¿›è¡Œäº†æ·±åº¦é€‚é…å’Œä¼˜åŒ–,ä¸‹é¢ç»™å‡ºè¯¦ç»†å®‰è£…æ­¥éª¤ã€‚

##  ğŸš€ å¿«é€Ÿå¼€å§‹ ğŸš€

### ï¼ˆ0ï¼‰åœ¨å¼€å§‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦æœ‰ä¸€å°æ˜†ä»‘XPUæœºå™¨ï¼Œå¯¹æ­¤æœºå™¨çš„ç³»ç»Ÿè¦æ±‚å¦‚ä¸‹ï¼š

 | èŠ¯ç‰‡ç±»å‹ | å¡å‹å· | é©±åŠ¨ç‰ˆæœ¬ |
 | --- | --- | --- |
 | æ˜†ä»‘R480 | R300 | 4.31.0 |

#### ä¾èµ–ç¯å¢ƒè¯´æ˜
- **æœºå™¨ï¼š** æ˜†ä»‘R480 32Gï¼Œå¤§æ¦‚éœ€è¦ 17.5Gï¼ˆbs=1ï¼‰
- **é•œåƒï¼š** registry.baidubce.com/device/paddle-xpu:ubuntu20-x86_64-gcc84-py310
- **GCCè·¯å¾„ï¼š** /usr/bin/gcc (8.4)
- **pythonç‰ˆæœ¬ï¼š**3.10
**æ³¨ï¼šæœ¬ç¤ºä¾‹ä½¿ç”¨8å¡æœºå™¨ï¼šå¦‚æœè¦éªŒè¯æ‚¨çš„æœºå™¨æ˜¯å¦ä¸ºæ˜†ä»‘èŠ¯ç‰‡ï¼Œåªéœ€ç³»ç»Ÿç¯å¢ƒä¸‹è¾“å…¥å‘½ä»¤ï¼Œçœ‹æ˜¯å¦æœ‰è¾“å‡ºï¼š**
```
lspci | grep 1d22
#ä¾‹å¦‚ï¼š$ lspci | grep 1d22 , è¾“å‡ºå¦‚ä¸‹
53:00.0 Communication controller: Device 1d22:3684
56:00.0 Communication controller: Device 1d22:3684
6d:00.0 Communication controller: Device 1d22:3684
70:00.0 Communication controller: Device 1d22:3684
b9:00.0 Communication controller: Device 1d22:3684
bc:00.0 Communication controller: Device 1d22:3684
d2:00.0 Communication controller: Device 1d22:3684
d5:00.0 Communication controller: Device 1d22:3684
```

### (1ï¼‰ç¯å¢ƒå‡†å¤‡ï¼š(è¿™å°†èŠ±è´¹æ‚¨5ï½15minæ—¶é—´)

1. æ‹‰å–é•œåƒ
```
# æ³¨æ„æ­¤é•œåƒä»…ä¸ºå¼€å‘ç¯å¢ƒï¼Œé•œåƒä¸­ä¸åŒ…å«é¢„ç¼–è¯‘çš„é£æ¡¨å®‰è£…åŒ…docker pull registry.baidubce.com/device/paddle-xpu:ubuntu20-x86_64-gcc84-py310
```

2. å‚è€ƒå¦‚ä¸‹å‘½ä»¤å¯åŠ¨å®¹å™¨
```
docker run -it --privileged=true  --net host --device=/dev/xpu0:/dev/xpu0 --device=/dev/xpu1:/dev/xpu1 --device=/dev/xpu2:/dev/xpu2 --device=/dev/xpu3:/dev/xpu3 --device=/dev/xpu4:/dev/xpu4 --device=/dev/xpu5:/dev/xpu5 --device=/dev/xpu6:/dev/xpu6 --device=/dev/xpu7:/dev/xpu7 --device=/dev/xpuctrl:/dev/xpuctrl --name paddle-xpu-dev -v $(pwd):/work -w=/work -v xxx registry.baidubce.com/device/paddle-xpu:ubuntu20-x86_64-gcc84-py310 /bin/bash
```

3. å®‰è£…paddlepaddle-xpu
```
# paddlepaddleã€é£æ¡¨ã€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæä¾›è¿ç®—åŸºç¡€èƒ½åŠ›
wget https://paddle-whl.bj.bcebos.com/nightly/xpu/paddlepaddle-xpu/paddlepaddle_xpu-3.0.0.dev20240612-cp310-cp310-linux_x86_64.whl
python -m pip install paddlepaddle_xpu-3.0.0.dev20240612-cp310-cp310-linux_x86_64.whl

nightlyç‰ˆæœ¬é“¾æ¥ï¼š
https://www.paddlepaddle.org.cn/packages/nightly/xpu/paddlepaddle-xpu/
```

4. å…‹éš†PaddleNLPä»“åº“ä»£ç ï¼Œå¹¶å®‰è£…ä¾èµ–
```
# PaddleNLPæ˜¯åŸºäºpaddlepaddleã€é£æ¡¨ã€çš„è‡ªç„¶è¯­è¨€å¤„ç†å’Œå¤§è¯­è¨€æ¨¡å‹(LLM)å¼€å‘åº“ï¼Œå­˜æ”¾äº†åŸºäºã€é£æ¡¨ã€æ¡†æ¶å®ç°çš„å„ç§å¤§æ¨¡å‹ï¼Œllama2-7Bæ¨¡å‹ä¹ŸåŒ…å«å…¶ä¸­ã€‚ä¸ºäº†ä¾¿äºæ‚¨æ›´å¥½åœ°ä½¿ç”¨PaddleNLPï¼Œæ‚¨éœ€è¦cloneæ•´ä¸ªä»“åº“ã€‚
# Clone PaddleNLP
git clone https://github.com/PaddlePaddle/PaddleNLP
cd PaddleNLP
# åˆ‡æ¢åˆ°å¯¹åº”æŒ‡å®šä¾èµ–çš„æäº¤
git checkout 0844a5b730c636ad77975fd30a485ad5dc217eac
# å®‰è£…ä¾èµ–
pip install -r requirements.txt
python -m pip install -e .

# ä¸‹è½½XPUè‡ªå®šä¹‰ç®—å­
cd csrc/xpu/src
# è®¾ç½® XDNN, XRE and XTDK çš„è·¯å¾„åä¸€é”®æ‰§è¡Œã€‚
wget https://baidu-kunlun-product.su.bcebos.com/KL-SDK/klsdk-dev/release_paddle/20240429/xdnn-ubuntu_x86_64.tar.gz
wget https://baidu-kunlun-product.su.bcebos.com/KL-SDK/klsdk-dev/release_paddle/20240429/xre-ubuntu_x86_64.tar.gz
wget https://klx-sdk-release-public.su.bcebos.com/xtdk_llvm15/release_paddle/2.7.98.2/xtdk-llvm15-ubuntu1604_x86_64.tar.gz

# è§£å‹åˆ°å½“å‰ç›®å½•
tar -xf xdnn-ubuntu_x86_64.tar.gz
tar -xf xre-ubuntu_x86_64.tar.gz
tar -xf xtdk-llvm15-ubuntu1604_x86_64.tar.gz

# è®¾ç½®ç¯å¢ƒå˜é‡
export PWD=$(pwd)
export XDNN_PATH=${PWD}/xdnn-ubuntu_x86_64/
export XRE_PATH=${PWD}/xre-ubuntu_x86_64/
export CLANG_PATH=${PWD}/xtdk-llvm15-ubuntu1604_x86_64/

#XPUè®¾å¤‡å®‰è£…è‡ªå®šä¹‰ç®—å­
bash ./cmake_build.sh
cd -
```

### ï¼ˆ2ï¼‰æ•°æ®å‡†å¤‡ï¼š(è¿™å°†èŠ±è´¹æ‚¨2ï½5minæ—¶é—´)
ç²¾è°ƒï¼šä¸ºäº†æ–¹ä¾¿æµ‹è¯•ï¼Œæˆ‘ä»¬ä¹Ÿæä¾›äº†æ•°æ®é›†å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š
```
# è¿›å…¥llmç›®å½•
cd llm
# ä¸‹è½½æ•°æ®é›†
wget https://baidu-kunlun-customer.su.bcebos.com/paddle-llm/infernce.tar.gz
# è§£å‹
tar -zxvf infernce.tar.gz
```

### (3ï¼‰æ¨ç†ï¼š(è¿™å°†èŠ±è´¹æ‚¨10~15minæ—¶é—´)
```
#å¯ä»¥é€šè¿‡è®¾ç½® FLAGS_selected_xpus æŒ‡å®šå®¹å™¨å¯è§çš„æ˜†ä»‘èŠ¯ç‰‡å¡å·
export FLAGS_selected_xpus=0
#è®¾ç½®ç¯å¢ƒå˜é‡
export PYTHONPATH=$PYTHONPATH:../../PaddleNLP/
```

é«˜æ€§èƒ½åŠ¨æ€å›¾æ¨ç†å‘½ä»¤å‚è€ƒ
```
python predictor.py --model_name_or_path ./inference --dtype float16 --src_length 2048 --max_length 2048 --mode "static" --batch_size 1 --inference_model --block_attn --device xpu
```

æœ€ç»ˆï¼Œé¢„æœŸç»“æœï¼š
```
[[2024-08-22 13:23:34,969] [    INFO] - preprocess spend 0.012732744216918945
[2024-08-22 13:23:34,994] [    INFO] - We are using <class 'paddlenlp.transformers.llama.tokenizer.LlamaTokenizer'> to load './inference'.
[2024-08-22 13:23:35,014] [    INFO] - Start read result message
[2024-08-22 13:23:35,014] [    INFO] - Current path is /home/workspace/wangy_test/PaddleNLP/llm
[2024-08-22 13:23:53,313] [    INFO] - running spend 18.322898864746094
[2024-08-22 13:23:53,326] [    INFO] - Finish read result message
[2024-08-22 13:23:53,327] [    INFO] - End predict
***********Source**********
è§£é‡Šä¸€ä¸‹â€œæ¸©æ•…è€ŒçŸ¥æ–°â€
***********Target**********

***********Output**********
"æ¸©æ•…è€ŒçŸ¥æ–°" (wÄ“n gÇ” Ã¨r zhÄ« xÄ«n) is a Chinese idiom that means "to understand the old in order to appreciate the new."
The word "æ¸©æ•…" (wÄ“n gÇ”) means "old" or "ancient," while "çŸ¥æ–°" (zhÄ« xÄ«n) means "to know or understand something new." The idiom as a whole suggests that in order to fully appreciate something new, one must first have a deep understanding of the past or the traditional ways of doing things.
In other words, "æ¸©æ•…è€ŒçŸ¥æ–°" means that one should have a foundation of knowledge and understanding before being open to new ideas or experiences. This can help prevent one from being too quick to dismiss the old in favor of the new, and instead allow for a more nuanced and informed appreciation of both.
For example, if someone is learning a new language, they may find it helpful to study the grammar and syntax of the language's ancestor languages in order to better understand the nuances of the new language. Similarly, if someone is learning a new skill or craft, they may find it helpful to study the traditional techniques and methods of the craft in order to better understand the new approaches and technologies that are being introduced.
Overall, "æ¸©æ•…è€ŒçŸ¥æ–°" is a reminder to approach new things with a sense of respect and appreciation for the past, and to be open to learning and growing in a way that is informed by a deep understanding of both the old and the new.
[2024-08-22 13:23:53,328] [    INFO] - Start predict
[2024-08-22 13:23:53,335] [    INFO] - preprocess spend 0.007447242736816406
[2024-08-22 13:23:53,357] [    INFO] - We are using <class 'paddlenlp.transformers.llama.tokenizer.LlamaTokenizer'> to load './inference'.
[2024-08-22 13:23:53,386] [    INFO] - Start read result message
[2024-08-22 13:23:53,386] [    INFO] - Current path is /home/workspace/wangy_test/PaddleNLP/llm
[2024-08-22 13:23:57,859] [    INFO] - running spend 4.506801605224609
[2024-08-22 13:23:57,863] [    INFO] - Finish read result message
[2024-08-22 13:23:57,864] [    INFO] - End predict
***********Source**********
ä½ å¥½ï¼Œè¯·é—®ä½ æ˜¯è°?
***********Target**********

***********Output**********
Hello! I'm just an AI assistant, I don't have a personal identity or ego, but I'm here to help you with any questions or tasks you may have. I'm a machine learning model trained to provide helpful and informative responses, and I'm here to assist you in a safe and respectful manner. Is there anything else I can help you with?
```