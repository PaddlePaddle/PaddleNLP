{
    "model_name_or_path": "__internal_testing__/tiny-random-llama",
    "per_device_train_batch_size": 2,
    "per_device_eval_batch_size": 2,
    "eval_accumulation_steps":16,
    "src_length": 1024,
    "max_length": 2048,
    "fp16": true,
    "fp16_opt_level": "O2",
    "dataset_name_or_path": "./data",
    "output_dir": "./checkpoints/llama_ptq_ckpts",
    "do_eval": false,
    "eval_with_do_generation": false,
    "do_ptq": true,
    "ptq_step": 4,
    "smooth": true,
    "smooth_step": 4,
    "smooth_all_linears": true,
    "smooth_piecewise_search": true,
    "smooth_k_piece": true,
    "smooth_search_piece": true
  }