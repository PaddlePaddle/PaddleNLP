# é£æ¡¨å¤§è¯­è¨€æ¨¡å‹å·¥å…·é“¾

é£æ¡¨å¤§è¯­è¨€æ¨¡å‹å·¥å…·é“¾åŸºäºé£æ¡¨4Dåˆ†å¸ƒå¼å¹¶è¡ŒæŠ€æœ¯å¼€å‘ï¼Œæ—¨åœ¨æä¾›é«˜æ€§èƒ½ã€çµæ´»æ˜“ç”¨å¤§è¯­è¨€æ¨¡å‹å…¨æµç¨‹å¼€å‘èƒ½åŠ›ï¼Œè¦†ç›–å¼€å‘ã€é¢„è®­ç»ƒã€ç²¾è°ƒã€å‹ç¼©ã€æ¨ç†ã€éƒ¨ç½²çš„å…¨æµç¨‹ã€‚

| Model | Pretrain | SFT | LoRA | Prefix Tuning | Generation | Quantization |
| --- | --- | --- | --- | --- | --- | --- |
| [LLaMA v1/v2](./llama) | âœ…  | âœ… | âœ… | âœ… | âœ… | âœ…  |
| [BaiChuan v1/v2](./llama) | âœ…  | âœ… | âœ… | âœ… | âœ… | âœ…  |
| [ChatGLM-6B](./chatglm) |  âŒ  |  âœ…  |  âœ…  |  âœ…  |  âœ…  |  âœ…  |
| [ChatGLM2-6B](./chatglm2) |  âŒ  |  âœ…  |  âœ…  |  âœ…  |  âœ…  |  âœ…  |
| [Bloom](./bloom) | âŒ  | âœ… | âœ… | âœ… | âœ… | âœ… |
| [GPT-3](./gpt-3) |   âœ…  |  âœ…  |  âœ…  |  ğŸš§  | âœ…   | ğŸš§ |
| [OPT](./opt) | ğŸš§ | âœ… | âœ… | ğŸš§ |  âœ… | ğŸš§ |
| [GLM](./glm) | âŒ  | âœ… | âœ… | ğŸš§ |  âœ… | ğŸš§ |
| [Qwen](./qwen) | âœ… | âœ… | âœ… | âœ… |  âœ… | ğŸš§ |


* âœ…: Supported
* ğŸš§: In Progress
* âŒ: Not Supported

# LLMå…¨æµç¨‹å·¥å…·ä»‹ç»
æˆ‘ä»¬æä¾›äº†æ¨¡å‹é¢„è®­ç»ƒã€ç²¾è°ƒï¼ˆSFTã€LoRAã€Prefix Tuningï¼‰ã€é‡åŒ–ã€æ¨ç†ã€éƒ¨ç½²å…¨æµç¨‹è„šæœ¬ï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚å®šåˆ¶åŒ–è‡ªå·±çš„å¤§è¯­è¨€æ¨¡å‹ã€‚

<div align="center">
    <img width="800" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/63761690/009bbb4e-baee-4c4a-a52e-94ac44c73c90">
</div>

<div align="center">
    <font size ="1">
    LLMå…¨æµç¨‹å·¥å…·æµç¨‹å›¾ï¼ˆä¸Šå›¾ï¼šPaddleNLP 2.6è¿›å±• ä¸‹å›¾ï¼šæœ€ç»ˆç›®æ ‡ï¼‰
     </font>
</div>

## 1. ç¯å¢ƒå‡†å¤‡

- paddlepaddle-gpu >= 2.5.1
- paddlenlp >= 2.6.1
- tiktoken (ä»… Qwen éœ€è¦)

## 2. é¢„è®­ç»ƒ
[LLaMA v1/v2](./llama)ã€[GPT-3](./gpt-3)ã€[BaiChuan]ã€[Qwen] ç­‰å¤§æ¨¡å‹çš„é¢„è®­ç»ƒæ”¯æŒã€‚

æ•°æ®è¯¦ç»†åˆ¶ä½œæµç¨‹å¯å‚è€ƒ[æ­¤å¤„](../../model_zoo/ernie-1.0/preprocess/README.md)ï¼Œä¾‹ï¼šOpenWebText2é¢„è®­ç»ƒæ•°æ®åˆ¶ä½œå‚è€ƒ[æ­¤å¤„](../../model_zoo/ernie-1.0/preprocess/docs/OpenWebText2.md)

ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·è¿è¡Œæµ‹è¯•æœ¬æ¨¡å‹ï¼Œæœ¬é¡¹ç›®æä¾›äº†å¤„ç†å¥½çš„100kæ¡docçš„è®­ç»ƒæ ·æœ¬ï¼š
```shell
# llama æ¨¡å‹æ•°æ®ä¸‹è½½
wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k_ids.npy
wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k_idx.npz

# gpt æ¨¡å‹æ•°æ®ä¸‹è½½
# wget https://bj.bcebos.com/paddlenlp/models/transformers/gpt/data/gpt_en_dataset_300m_ids.npy
# wget https://bj.bcebos.com/paddlenlp/models/transformers/gpt/data/gpt_en_dataset_300m_idx.npz
```

å°†æ‰€æœ‰é¢„å¤„ç†å¾—åˆ°çš„æ–‡ä»¶ç»Ÿä¸€æ”¾å…¥ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼Œä»¥å¤‡è®­ç»ƒä½¿ç”¨ï¼š

```
mkdir data
mv llama_openwebtext_100k_ids.npy ./data
mv llama_openwebtext_100k_idx.npz ./data
```


```shell
# ç¼–è¯‘è‡ªå®šä¹‰ç®—å­ï¼Œå¯é€‰
cd ../model_zoo/gpt-3/external_ops/ && python3 setup.py install && cd -

# llama æ¨¡å‹é¢„è®­ç»ƒ
python -u  -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" run_pretrain.py ./llama/pretrain-llama2_7b-tp2sd4_stage2.json

# Qwen æ¨¡å‹é¢„è®­ç»ƒ
python -u  -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" run_pretrain.py ./qwen/pretrain_argument_stage2.json
```

æ³¨æ„ï¼š
1. å»ºè®®ä½¿ç”¨paddle developç‰ˆæœ¬è®­ç»ƒï¼Œéœ€è¦å®‰è£…`pip install tool_helpers visualdl==2.5.3`ç­‰ç›¸å…³ç¼ºå¤±whlåŒ…
2. `use_flash_attention` éœ€è¦åœ¨A100æœºå™¨å¼€å¯ï¼Œå»ºè®®ä½¿ç”¨cuda11.8ç¯å¢ƒã€‚
3. `use_fused_rms_norm` éœ€è¦å®‰è£…[æ­¤ç›®å½•](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/gpt-3/external_ops)ä¸‹çš„è‡ªå®šä¹‰OP, `python setup.py install`ã€‚å¦‚æœå®‰è£…åä»ç„¶æ‰¾ä¸åˆ°ç®—å­ï¼Œéœ€è¦é¢å¤–è®¾ç½®PYTHONPATH
4. `continue_training` è¡¨ç¤ºä»ç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹åŠ è½½è®­ç»ƒã€‚7bæ¨¡å‹åˆå§‹losså¤§æ¦‚ä¸º2.xx, éšæœºåˆå§‹åŒ–æ¨¡å‹lossä»11.xå·¦å³ä¸‹é™ã€‚
5. å½“å‰è„šæœ¬ä¸ºshardingç‰ˆæœ¬ï¼Œéœ€è¦4Då¹¶è¡Œè®­ç»ƒï¼ˆæ•°æ®ã€shardingã€å¼ é‡ã€æµæ°´çº¿å¹¶è¡Œï¼‰çš„ç”¨æˆ·ï¼Œè¯·å‚è€ƒ `run_trainer_tp4pp2.sh`è„šæœ¬ã€‚
6. å¤šæœºè®­ç»ƒæ—¶ï¼Œè‹¥å„æœºå™¨ä½¿ç”¨çš„è®­ç»ƒæ•°æ®æ–‡ä»¶ä½ç½®ç›¸åŒï¼ˆä¾‹å¦‚æŒ‚è½½å…±äº«ç¡¬ç›˜æƒ…å†µï¼‰ï¼Œè¯·æŒ‡å®š`--share_folder true`ä½¿å…¨å±€0å·å¡åˆ¶ä½œç¼“å­˜æ•°æ®ã€‚å¦åˆ™é»˜è®¤å„å°æœºå™¨çš„0å·å¡ç‹¬ç«‹åˆ¶ä½œç¼“å­˜æ•°æ®ï¼Œ
7. è‹¥æ•°æ®é›†æ–‡ä»¶å¤¹ä¸­å­˜åœ¨é»˜è®¤ç¼“å­˜æ–‡ä»¶å¤¹`index-cache/`ï¼Œåˆ™é¢å¤–æŒ‡å®šçš„`--data_cache`ä¸ç”Ÿæ•ˆï¼Œè®­ç»ƒæ—¶ä¼˜å…ˆåŠ è½½é»˜è®¤ç¼“å­˜æ–‡ä»¶å¤¹ä¸­çš„å†…å®¹ã€‚


## 3. ç²¾è°ƒ
ç›®å‰ç²¾è°ƒç»Ÿä¸€è„šæœ¬åªæ”¯æŒ[LLaMA v1/v2](./llama)ã€[ChatGLM-6B](./chatglm)ã€[ChatGLM2-6B](./chatglm2)ã€[Bloom](./bloom)ã€[OPT](./opt)ã€[Qwen](./qwen)ï¼Œå…¶ä»–æ¨¡å‹ç²¾è°ƒä½¿ç”¨è¯¦è§å¯¹åº”æ¨¡å‹ç›®å½•ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä»¥**Llama 2**ä¸ºä¾‹ä»‹ç»å¦‚ä½•ä½¿ç”¨ç»Ÿä¸€è„šæœ¬è¿›è¡ŒSFTã€LoRAã€Prefix Tuningã€‚æ›´å¤šLoRAã€Prefix Tuningè¯·å‚è§[PEFTæ–‡æ¡£](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/peft.md)ã€‚

### 3.1 ç²¾è°ƒè®­ç»ƒæ•°æ®æ ¼å¼

ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·æµ‹è¯•ï¼Œæˆ‘ä»¬ä¹Ÿæä¾›ç¤ºä¾‹æ•°æ®é›†[å¹¿å‘Šç”Ÿæˆæ•°æ®é›†](https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz)ï¼Œç”¨æˆ·ä¹Ÿå¯ä»¥ä»¿ç…§æ•°æ®é›†çš„æ ¼å¼åˆ¶ä½œè‡ªå·±çš„æ•°æ®é›†è¿›è¡Œç²¾è°ƒã€‚æˆ‘ä»¬æ”¯æŒçš„æ•°æ®æ ¼å¼æ˜¯æ¯è¡ŒåŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

- `src` : `str, List(str)`, æ¨¡å‹çš„è¾“å…¥æŒ‡ä»¤ï¼ˆinstructionï¼‰ã€æç¤ºï¼ˆpromptï¼‰ï¼Œæ¨¡å‹åº”è¯¥æ‰§è¡Œçš„ä»»åŠ¡ã€‚
- `tgt` : `str, List(str)`, æ¨¡å‹çš„è¾“å‡ºã€‚

æ ·ä¾‹æ•°æ®ï¼š
```
{"src": "ç±»å‹#è£™*é¢œè‰²#è“è‰²*é£æ ¼#æ¸…æ–°*å›¾æ¡ˆ#è´è¶ç»“", "tgt": "è£™èº«å¤„é‡‡ç”¨ç«‹ä½“è´è¶ç»“è£…é¥°è¾…ä»¥è“è‰²æ¡å¸¦ç‚¹ç¼€ï¼Œä»¤è¡£èº«é€ å‹é¥±æ»¡å¯Œæœ‰å±‚æ¬¡çš„åŒæ—¶ä¸ºå…¶æ³¨å…¥ä¸€ä¸ç”œç¾æ°”æ¯ã€‚å°†å¥³å­©æ¸…æ–°å¨‡ä¿çš„ä¸€é¢è¡¬æ‰˜è€Œå‡ºã€‚"}
...
```



### 3.2 SFT

SFTï¼ˆSupervised Fine-Tuningï¼‰ä¾æ‰˜é£æ¡¨æå‡ºçš„[4Dæ··åˆåˆ†å¸ƒå¼å¹¶è¡Œ](https://ai.baidu.com/forum/topic/show/987996)èƒ½åŠ›ï¼Œæ”¯æŒä½¿ç”¨Trainer APIè½»æ¾åˆ‡æ¢æ•°æ®å¹¶è¡Œ(DP)ã€[å¼ é‡å¹¶è¡Œï¼ˆTP, Tensor Parallelismï¼‰](https://arxiv.org/abs/1909.08053)ã€[æµæ°´çº¿å¹¶è¡Œï¼ˆPP, Pipeline Parallelismï¼‰](https://arxiv.org/abs/1811.06965)ï¼ˆç›®å‰ä»…æ”¯æŒLlamaï¼‰ç­‰å¤šç§åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ã€‚

4D æ··åˆå¹¶è¡Œç­–ç•¥çš„æœ€ä½³é…ç½®å®è·µå¦‚å›¾ä¸‹æ‰€ç¤ºï¼Œåœ¨å•æœºå†…ä½¿ç”¨é€šä¿¡é‡è¾ƒå¤§ï¼Œé€‚åˆä½¿ç”¨æœºå™¨å†…å¡é—´é€šä¿¡çš„å¼ é‡å¹¶è¡Œï¼ˆå¼ é‡å¹¶è¡Œåˆç§°æ¨¡å‹å¹¶è¡Œï¼ŒMPï¼‰å’Œåˆ†ç»„å‚æ•°åˆ‡ç‰‡ï¼ˆShardingï¼‰çš„2Dç»„åˆç­–ç•¥ï¼›è®­ç»ƒåƒäº¿è§„æ¨¡æ¨¡å‹æ—¶ï¼Œå åŠ æµæ°´çº¿å¹¶è¡Œç­–ç•¥ä½¿ç”¨å¤šå°æœºå™¨å…±åŒåˆ†æ‹…ï¼›åŒæ—¶å åŠ æ•°æ®å¹¶è¡Œæ¥å¢åŠ å¹¶å‘æ•°é‡ï¼Œæå‡è®­ç»ƒé€Ÿåº¦ã€‚
<div align="center">
    <img src="https://ai.bdstatic.com/file/63F5EBB1E188457ABAFD311CFC1D8658" width=50% height=50%>
</div>

```
# å¼ é‡å¹¶è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼ˆå¸¸ç”¨ï¼‰
python -u  -m paddle.distributed.launch --gpus "0,1,2,3" finetune_generation.py ./llama/sft_argument.json

# ç›®å‰ChatGLM2ã€OPTä¸æ”¯æŒå¼ é‡å¹¶è¡Œï¼Œé»˜è®¤ä½¿ç”¨Shardingç­–ç•¥ï¼ˆPaddle 2.5.1æ”¯æŒSharding Stage2ï¼ŒSharding Stage3éœ€è¦ä½¿ç”¨Paddle developç‰ˆæœ¬ï¼‰
python -u  -m paddle.distributed.launch --gpus "0,1,2,3" finetune_generation.py ./chatglm2/sft_argument.json

# å¼ é‡å¹¶è¡Œ&æµæ°´çº¿å¹¶è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼ˆç›®å‰ä»…æ”¯æŒLlamaï¼‰
python -u  -m paddle.distributed.launch --gpus "0,1,2,3" finetune_generation.py ./llama/sft_pp_argument.json
```

### 3.3 LoRA

Transformeræ¨¡å‹ä¸­åŒ…å«è®¸å¤šLinearå±‚éœ€è¦è¿›è¡Œå¯†é›†çš„çŸ©é˜µä¹˜æ³•è®¡ç®—ï¼Œè€Œè¿™äº›é€šå¸¸å…·æœ‰å…¨ç§©(full rank)ç‰¹æ€§ã€‚[LoRA](https://arxiv.org/abs/2106.09685)æå‡ºå†»ç»“é¢„è®­ç»ƒçš„æƒé‡çŸ©é˜µ, é€šè¿‡å¼•å…¥ä¸¤ä¸ªä½ rank çŸ©é˜µ $AB$(å›¾ä¸­æ©™è‰²çš„ä¸¤ä¸ªçŸ©é˜µ) æ¥è¿‘ä¼¼æƒé‡çš„æ›´æ–°è¿‡ç¨‹ $W_0+\Delta W=W_0+B A$ , å…¶ä¸­ $B \in \mathbb{R}^{d \times r}, A \in \mathbb{R}^{r \times k}$ï¼Œå®éªŒè¡¨æ˜å°†è¾“å…¥è¡¨è¾¾éšæœºæŠ•å½±åˆ°è¾ƒå°çš„å­ç©ºé—´æ¨¡å‹ä»ç„¶å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶å¤§å¹…é™ä½è®¡ç®—çš„æ˜¾å­˜éœ€æ±‚ã€‚


<div align="center">
<img src=https://github.com/PaddlePaddle/PaddleNLP/assets/37530985/63d56558-247a-4a8d-a6ca-121c820f7534 width=50% height=50% />
</div>


PaddleNLP LoRA APIæ”¯æŒæ•°æ®å¹¶è¡Œã€å¼ é‡å¹¶è¡Œç­‰å¤šç§åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ï¼Œå¯ä»¥é€šè¿‡æ§åˆ¶`tensor_parallel_degree` è°ƒæ•´å¹¶è¡Œè®­ç»ƒç­–ç•¥ã€‚LoRAç­–ç•¥é»˜è®¤åº”ç”¨åœ¨æ‰€æœ‰Linearå±‚ï¼Œå¯æ‹“å±•è‡³**å•æœºLoRAå¾®è°ƒåƒäº¿æ¨¡å‹**ã€‚


```
# å•å¡è®­ç»ƒ
python  finetune_generation.py ./llama/lora_argument.json

# å¼ é‡å¹¶è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼ˆChatGLM2ã€OPTä¸æ”¯æŒå¼ é‡å¹¶è¡Œï¼‰
# å°†lora_argument.jsonä¸­tensor_parallel_degreeä¿®æ”¹ä¸º2
python  -u  -m paddle.distributed.launch --gpus "0,1"  finetune_generation.py ./llama/lora_argument.json
```


### 3.4 Prefix Tuning

[Prefix Tuning](https://arxiv.org/abs/2101.00190)å—æç¤ºå­¦ä¹ ï¼ˆPrompt learningï¼‰çš„å½±å“ï¼ŒåŠ å…¥çš„ä¸€éƒ¨åˆ† Prefix Embedding ä½œä¸ºè¿ç»­å‹æç¤ºè¿›è¡Œè®­ç»ƒã€‚Prefix Embeddingæ˜¯ç”±ä¸“é—¨çš„ Prefix Encoder ç½‘ç»œç”Ÿæˆçš„æ•°ä¸ªå¼ é‡ï¼Œä¼šä»¥ `past_key_value` çš„æ–¹å¼è¢«æ’å…¥åˆ°è¯­è¨€æ¨¡å‹æ¯ä¸€å±‚çš„ hidden_state ä¹‹å‰ã€‚

<div align="center">
<img src=https://github.com/PaddlePaddle/PaddleNLP/assets/37530985/8baf6943-4540-4c02-8540-35f977acc077 width=40% height=40% />
</div>

PaddleNLP Prefix Tuning APIæ”¯æŒæ•°æ®å¹¶è¡Œï¼ˆDPï¼‰ã€å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰ç­‰å¤šç§åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ï¼Œå¯ä»¥é€šè¿‡æ§åˆ¶`tensor_parallel_degree` è°ƒæ•´å¹¶è¡Œè®­ç»ƒç­–ç•¥ã€‚
```
# å•å¡è®­ç»ƒ
python  finetune_generation.py ./llama/pt_argument.json

# å¼ é‡å¹¶è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼ˆChatGLM2ã€OPTä¸æ”¯æŒå¼ é‡å¹¶è¡Œï¼‰
# å°†pt_argument.jsonä¸­tensor_parallel_degreeä¿®æ”¹ä¸º2
python  -u  -m paddle.distributed.launch --gpus "0,1"  finetune_generation.py ./llama/pt_argument.json
```
### 3.5 ç²¾è°ƒå‚æ•°ä»‹ç»
<details><summary>&emsp; æ¨¡å‹å‚æ•°ï¼ˆModelArgumentï¼‰ </summary><div>

- `model_name_or_path`: é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è€…æœ¬åœ°çš„æ¨¡å‹è·¯å¾„ï¼Œç”¨äºçƒ­å¯æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œé»˜è®¤ä¸ºNoneã€‚æ¯ä¸ªæ¨¡å‹**æ”¯æŒæ¨¡å‹æƒé‡**è¯¦è§å„æ¨¡å‹ç›®å½•ã€‚
- `use_flash_attention`: æ¨¡å‹æ˜¯å¦ä½¿ç”¨FlashAttention2ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `lora`: æ˜¯å¦å¼€å¯LoRAå¾®è°ƒç­–ç•¥ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `lora_path`: LoRAå‚æ•°å’Œé…ç½®è·¯å¾„ï¼Œå¯¹LoRAå‚æ•°è¿›è¡Œåˆå§‹åŒ–ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `lora_rank`: LoRAç®—æ³•ä¸­rankï¼ˆç§©ï¼‰çš„å€¼ï¼Œé»˜è®¤ä¸º8ã€‚
- `prefix_tuning`: æ˜¯å¦ä½¿ç”¨Prefix Tuningç­–ç•¥ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `num_prefix_tokens`: Prefix Tuningç­–ç•¥ä¸­Prefix Tokenæ•°é‡ï¼Œé»˜è®¤ä¸º128ã€‚
- `from_aistudio`: æ¨¡å‹æƒé‡æ˜¯å¦ä»Aistudioä¸‹è½½ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `save_to_aistudio`: æ¨¡å‹æƒé‡æ˜¯å¦ä¿å­˜åˆ°Aistudioï¼Œé»˜è®¤ä¸ºFalseã€‚
- `aistudio_repo_id`: æ¨¡å‹æƒé‡ä¿å­˜åˆ°Aistudioçš„repo idï¼Œé»˜è®¤ä¸ºNoneã€‚
- `aistudio_repo_private`: æ¨¡å‹æƒé‡ä¿å­˜åˆ°Aistudioçš„repoæ˜¯å¦ä¸ºç§æœ‰ï¼Œé»˜è®¤ä¸ºTrueã€‚
- `aistudio_repo_license`: æ¨¡å‹æƒé‡ä¿å­˜åˆ°Aistudioçš„repo licenseï¼Œé»˜è®¤ä¸º"Apache License 2.0"ã€‚
- `aistudio_token`: æ¨¡å‹æƒé‡ä¿å­˜åˆ°Aistudioçš„tokenï¼Œé»˜è®¤ä¸ºNoneã€‚å¦‚æœsave_to_aistudioä¸ºTrueï¼Œä¸”ç¯å¢ƒå˜é‡æ²¡æœ‰è®¾ç½®ç›¸åº”tokenï¼Œå¿…é¡»ä¼ å…¥ã€‚
- `neftune`: æ˜¯å¦ä½¿ç”¨[NEFT](https://arxiv.org/abs/2310.05914)ï¼Œè¿›è¡Œå¾®è°ƒã€‚é»˜è®¤ä¸ºFalseã€‚
- `neftune_noise_alpha`: NEFT alphaå‚æ•°ï¼Œé»˜è®¤ä¸º5.0ã€‚

</div></details>

<details><summary>&emsp; æ•°æ®å‚æ•°ï¼ˆDataArgumentï¼‰</summary><div>

- `dataset_name_or_path`: æœ¬åœ°æ•°æ®é›†ç›®å½•æˆ–å†…ç½®æ•°æ®é›†åç§°ï¼Œé»˜è®¤ä¸ºNoneã€‚è„šæœ¬å·²é€‚é…å•æ–‡ä»¶å’Œå¤šæ–‡ä»¶ï¼Œä¼šè‡ªå·±å¯»æ‰¾`dataset_name_or_path/train.json` æˆ–è€… `dataset_name_or_path/train/*.json`ä½œä¸ºè®­ç»ƒé›†æ–‡ä»¶, ä»¥åŠ`dataset_name_or_path/dev.json` æˆ–è€… `dataset_name_or_path/dev/*.json`ä½œä¸ºéªŒè¯é›†æ–‡ä»¶ã€‚
- `task_name`: ç”¨äºé€‰æ‹©å†…ç½®æ•°æ®é›†ä¸­çš„å…·ä½“ä»»åŠ¡ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `eval_with_do_generation`: åœ¨æ¨¡å‹æ•ˆæœè¯„ä¼°çš„æ—¶å€™æ˜¯å¦è°ƒç”¨model.generate,é»˜è®¤ä¸ºFalseã€‚è®¾ç½®ä¸ºTrueæ—¶ï¼ŒæŒ‡æ ‡ä¸ºppl, accuracyï¼›è®¾ç½®ä¸ºFalseæ—¶ï¼ŒæŒ‡æ ‡ä¸ºBLEU4/Rougeï¼Œå»ºè®®å°†`metric_for_best_model`è®¾ä¸ºbleu4ã€‚
- `save_generation_output`: å½“`eval_with_do_generation`è®¾ä¸ºTrueï¼Œæ˜¯å¦å°†ç”Ÿæˆç»“æœä¿å­˜åœ¨`generated_output.json`æ–‡ä»¶ä¸­ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `intokens`:æ˜¯å¦ä½¿ç”¨InTokenæ•°æ®æµï¼ˆå‡å°‘Paddingå†—ä½™è®¡ç®—ï¼Œå¤§å¹…æå‡æœ‰æ•ˆTokenè®¡ç®—æ•ˆç‡ï¼‰ï¼Œé»˜è®¤ä¸ºFalseã€‚å½“`eval_with_do_generation`è®¾ä¸ºTrue,è¯„ä¼°è¿‡ç¨‹ä¸æ”¯æŒInTokenæ•°æ®æµã€‚ã€‚
- `src_length`: æ¨¡å‹è¾“å…¥ä¸Šä¸‹æ–‡æœ€å¤§tokené•¿åº¦ï¼Œé»˜è®¤ä¸º1024ã€‚
- `max_length`:æ¨¡å‹è¾“å…¥ï¼ˆä¸Šä¸‹æ–‡+ç”Ÿæˆå†…å®¹ï¼‰çš„æœ€å¤§tokené•¿åº¦, é»˜è®¤ä¸º2048ã€‚å½“`intokens`è®¾ä¸ºTrueçš„æ—¶å€™ï¼ŒåŒæ—¶ä¹Ÿä¸ºInTokenæ•°æ®æµæ¨¡å‹è®­ç»ƒè¾“å…¥æœ€å¤§é•¿åº¦ï¼Œé€šå¸¸å»ºè®®è®¾ä¸ºæ¨¡å‹å…è®¸è¾“å…¥æœ€å¤§é•¿åº¦ï¼ŒåŒæ—¶`per_device_train_batch_size`è®¾ä¸º1ï¼Œä½¿ç”¨`gradient_accumulation_steps`æ§åˆ¶batch sizeã€‚
- `lazy`:è®¾ç½®ä¸ºFalseåˆ™ä½¿ç”¨`MapDataset`ï¼Œè®¾ç½®ä¸ºTrueåˆ™ä½¿ç”¨`IterDataset`ï¼Œé»˜è®¤ä¸ºFalseã€‚å¯¹äºæ•°æ®é‡è¾ƒå¤§çš„æ—¶å€™å»ºè®®è®¾ä¸ºTrueï¼Œ`IterDataset`å¯ä»¥é¿å…ä¸€æ¬¡æ€§å°†æ‰€æœ‰æ•°æ®è¯»å…¥å†…å­˜ï¼Œæ³¨æ„éœ€è¦è®¾ç½®`max_steps`å¹¶ä¸”`evaluation_strategy`å’Œ`save_strategy`è®¾ä¸º`steps`

</div></details>


<details><summary>&emsp; ç”Ÿæˆå‚æ•°ï¼ˆGenerateArgumentï¼‰</summary><div>

æ³¨ï¼šä»¥ä¸‹å‚æ•°ä»…åœ¨`eval_with_do_generation`ä¸ºTrueï¼Œè°ƒç”¨model.generate()æ—¶ç”Ÿæ•ˆã€‚

- `top_k`: â€œé‡‡æ ·â€ç­–ç•¥ä¸­ä¸º top-k è¿‡æ»¤ä¿ç•™çš„æœ€é«˜æ¦‚ç‡æ ‡è®°çš„æ•°é‡ã€‚é»˜è®¤ä¸º1ï¼Œç­‰ä»·äºè´ªå¿ƒç­–ç•¥ã€‚
- `top_p`:â€œé‡‡æ ·â€ç­–ç•¥ä¸­ top-p è¿‡æ»¤çš„ç´¯ç§¯æ¦‚ç‡ã€‚é»˜è®¤ä¸º1.0ï¼Œè¡¨ç¤ºä¸èµ·ä½œç”¨ã€‚
</div></details>

<details><summary>&emsp; è®­ç»ƒå‚æ•°ï¼ˆTrainingArgumentsï¼‰</summary><div>

ä»¥ä¸‹ä»…ä»‹ç»TrainingArgumentséƒ¨åˆ†å¸¸ç”¨å‚æ•°ï¼Œè¯¦æƒ…è¯·å‚è§[TrainingArgumentsæ–‡æ¡£](https://paddlenlp.readthedocs.io/zh/latest/trainer.html)ã€‚

- `output_dir`: ç”¨äºä¿å­˜ç›¸å…³çš„æ–‡ä»¶ç›®å½•ï¼Œä¸»è¦åŒ…æ‹¬æ¨¡å‹ç›¸å…³æ–‡ä»¶ã€è®­ç»ƒè¿‡ç¨‹ä¸­çš„checkpointã€åˆ†è¯å™¨ç›¸å…³æ–‡ä»¶ã€è¯„ä¼°çš„ç»“æœæ–‡ä»¶ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `per_device_train_batch_size`: è®­ç»ƒé›†è®­ç»ƒè¿‡ç¨‹æ‰¹å¤„ç†å¤§å°ï¼Œå¯¹åº” micro batch sizeï¼Œé»˜è®¤ä¸º8ã€‚è¯¥å‚æ•°éœ€è¦æ ¹æ®å…·ä½“çš„æ•°æ®é›†æ¥è®¾å®šï¼Œè¯¥å‚æ•°è¶Šå¤§ï¼Œå ç”¨æ˜¾å­˜è¶Šé«˜ï¼Œè®­ç»ƒä»£ä»·è¶Šå¤§ï¼›åä¹‹ï¼Œå ç”¨æ˜¾å­˜è¶Šå°ï¼Œè®­ç»ƒé€Ÿåº¦è¶Šå¿«ã€‚
- `gradient_accumulation_steps`:æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯å°†å¤šæ¬¡è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦å€¼è¿›è¡Œç´¯åŠ ï¼Œç„¶åä¸€æ¬¡æ€§è¿›è¡Œå‚æ•°æ›´æ–°ï¼Œé»˜è®¤ä¸º1ã€‚ç­‰æ•ˆäºå°†åŸæœ‰è®­ç»ƒbatch size*gradient_accumulation_stepsã€‚
- `per_device_eval_batch_size`: éªŒè¯é›†æ‰¹å¤„ç†å¤§å°ï¼Œå¯¹åº” micro batch sizeï¼Œé»˜è®¤ä¸º8ã€‚è¯¥å‚æ•°è¶Šå¤§ï¼Œå ç”¨æ˜¾å­˜è¶Šé«˜ï¼›è¯¥å‚æ•°è¶Šå°ï¼Œå ç”¨æ˜¾å­˜è¶Šä½ã€‚
- `eval_accumulation_steps`:åœ¨å°†ç»“æœç§»åŠ¨åˆ°CPUä¹‹å‰ï¼Œç´¯ç§¯è¾“å‡ºå¼ é‡çš„é¢„æµ‹æ­¥éª¤æ•°ã€‚å¦‚æœå¦‚æœæœªè®¾ç½®ï¼Œåˆ™åœ¨ç§»åŠ¨åˆ°CPUä¹‹å‰ï¼Œæ•´ä¸ªé¢„æµ‹éƒ½ä¼šåœ¨GPUä¸Šç´¯ç§¯ï¼ˆé€Ÿåº¦æ›´å¿«éœ€è¦æ›´å¤šçš„æ˜¾å­˜ï¼‰ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `num_train_epochs`:æ¨¡å‹è®­ç»ƒçš„è½®æ¬¡ï¼Œé»˜è®¤ä¸º3ã€‚
- `learning_rate`:ä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ï¼Œé»˜è®¤ä¸º 5e-05ã€‚
- `warmup_steps`: warmupçš„æ­¥æ•°ï¼Œé»˜è®¤ä¸º0ã€‚å½“warmup_steps>0æ—¶ï¼Œä¼šè¦†ç›–warmup_ratioçš„è®¾ç½®ã€‚
- `logging_steps`: æ—¥å¿—æ‰“å°çš„é¢‘ç‡ï¼Œä»…å½“logging_strategy=="step"ç”Ÿæ•ˆï¼Œé»˜è®¤ä¸º 500ã€‚å¦‚æœå¸Œæœ›çœ‹åˆ°è¾ƒå¿«çš„æ—¥å¿—åé¦ˆæˆ–è€…å³æ—¶çš„è®­ç»ƒçš„é€Ÿåº¦ï¼Œå¯ä»¥å‡å°logging_stepsã€‚
- `evaluation_strategy`: è¯„ä¼°ç­–ç•¥ï¼Œé»˜è®¤ä¸ºnoã€‚"no"ï¼šè®­ç»ƒæœŸé—´ä¸è¿›è¡Œè¯„ä¼°ï¼›"steps"ï¼šåœ¨æ¯eval_stepsç»“æŸè¿›è¡Œï¼›"epoch"ï¼šåœ¨æ¯ä¸ª epoch ç»“æŸæ—¶è¿›è¡Œã€‚
- `save_strategy`: ä¿å­˜ç­–ç•¥ï¼Œé»˜è®¤ä¸ºnoã€‚"no"ï¼šè®­ç»ƒæœŸé—´ä¸è¿›è¡Œè¯„ä¼°ï¼›"steps"ï¼šåœ¨æ¯eval_stepsç»“æŸè¿›è¡Œï¼›"epoch"ï¼šåœ¨æ¯ä¸ª epoch ç»“æŸæ—¶è¿›è¡Œã€‚
- `fp16`: æ˜¯å¦éœ€è¦å¼€å¯FP16è®­ç»ƒï¼Œå¼€å¯FP16è®­ç»ƒå¯ä»¥åŠ é€Ÿè®­ç»ƒï¼Œé»˜è®¤ä¸ºFalseã€‚
- `bf16`: æ˜¯å¦éœ€è¦å¼€å¯BF16è®­ç»ƒï¼Œå¼€å¯BF16è®­ç»ƒå¯ä»¥åŠ é€Ÿè®­ç»ƒï¼Œé»˜è®¤ä¸ºFalseã€‚
- `fp16_opt_level`: å¯è®¾ç½®O1æˆ–è€…O2ï¼Œåœ¨ O1 çº§åˆ«ä¸‹ï¼Œåœ¨ç™½åå•ä¸­çš„ç®—å­å°†ä½¿ç”¨ float16/bfloat16 è®¡ç®—ï¼Œåœ¨é»‘åå•ä¸­çš„ç®—å­å°†ä½¿ç”¨ float32 è®¡ç®—ã€‚åœ¨ O2 çº§åˆ«ä¸‹ï¼Œæ¨¡å‹çš„å‚æ•°è¢«è½¬æ¢ä¸º float16/bfloat16ï¼Œ å¦‚æœç®—å­çš„æµ®ç‚¹å‹è¾“å…¥å…¨æ˜¯ float16/bfloat16ï¼Œç®—å­æ‰ä¼šé‡‡ç”¨ float16/bfloat16 è®¡ç®—ï¼Œè‹¥ä»»æ„æµ®ç‚¹å‹è¾“å…¥æ˜¯ float32 ç±»å‹ï¼Œç®—å­å°†é‡‡ç”¨ float32 è®¡ç®—ã€‚é»˜è®¤ä¸ºO1ã€‚
- `do_train`: æ˜¯å¦æ‰“å¼€è®­ç»ƒï¼Œé»˜è®¤ä¸ºFalseã€‚
- `do_eval`: æ˜¯å¦æ‰“å¼€è¯„ä¼°ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `disable_tqdm`: æ˜¯å¦å…³æ‰tqdmçš„è¿›åº¦æ¡ï¼Œé»˜è®¤ä¸ºFalseã€‚å¦‚æœéœ€è¦é¢„ä¼°æ•´ä½“çš„è®­ç»ƒæ—¶é•¿ï¼Œå¯ä»¥æ‰“å¼€è¯¥é…ç½®ï¼Œå®æ—¶è§‚å¯Ÿè®­ç»ƒè¿›åº¦ã€‚
- `load_best_model_at_end`: è®­ç»ƒç»“æŸåæ˜¯å¦åŠ è½½æœ€ä¼˜æ¨¡å‹ï¼Œé€šå¸¸ä¸`metric_for_best_model`é…åˆä½¿ç”¨,é»˜è®¤ä¸ºFalseã€‚
- `metric_for_best_model`: æœ€ä¼˜æ¨¡å‹æŒ‡æ ‡ï¼Œå¦‚"accuarcy"ç­‰ï¼Œç”¨äºæ¯”è¾ƒæ¨¡å‹å¥½åï¼Œé»˜è®¤ä¸ºNoneã€‚
- `recompute`: é‡è®¡ç®—ï¼Œæš‚æ”¯æŒfullç­–ç•¥ã€‚å¼€å¯åå¯é™ä½æ˜¾å­˜ä»¥è¾¾åˆ°å¢å¤§batch sizeçš„ç›®çš„ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `save_total_limit`: ä¿ç•™checkpointçš„ä¸ªæ•°ï¼Œè€çš„checkpointä¼šè¢«åˆ é™¤ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `tensor_parallel_degree`: æ­¤å‚æ•°tensor_parallel_degreeè¡¨ç¤ºå°†ä¸€å±‚transformerç»“æ„çš„ä»½æ•°ï¼Œè¯¥æ–¹æ³•å¯¹é€šä¿¡å¼€é”€è¾ƒå¤§, å»ºè®® tensor_parallel_degree<=8, å°½é‡ä½¿ç”¨æœºå™¨å†…éƒ¨é€šä¿¡ã€‚é»˜è®¤ä¸º-1ï¼Œè¡¨ç¤ºä¸å¯ç”¨å¼ é‡å¹¶è¡Œã€‚
- `pipeline_parallel_degree`: è¡¨ç¤ºåˆ’åˆ†æµæ°´çº¿çš„å¤§å°.(å‡è®¾è¯¥å‚æ•°ä¸º4, æ¨¡å‹12å±‚, åˆ™æ¯ä¸€ä¸ªpp stage åŒ…å«3å±‚æ¨¡å‹) é»˜è®¤å€¼-1, è¡¨ç¤ºä¸å¯ç”¨æµæ°´çº¿å¹¶è¡Œã€‚

</div></details>


### 3.6 å¼ é‡å¹¶è¡Œå‚æ•°åˆå¹¶

æˆ‘ä»¬ä½¿ç”¨å¼ é‡å¹¶è¡Œï¼ˆTPï¼ŒTensor Parallelismï¼‰è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸ºäº†èŠ‚çœTPå‚æ•°åˆå¹¶æ—¶é—´é€šå¸¸åœ¨ä¸­é—´checkpointå°†å‚æ•°å­˜å‚¨ä¸ºå¤šä¸ªTPå‚æ•°åˆ†ç‰‡ï¼Œå¯ä»¥ä½¿ç”¨æä¾›çš„åˆ†ç‰‡åˆå¹¶å‚æ•°è„šæœ¬è¿›è¡Œå‚æ•°åˆå¹¶ã€‚

```
python merge_tp_params.py \
    --model_name_or_path ./checkpoints/llama_sft_ckpts/checkpoint-100
```

<details><summary>&emsp; è„šæœ¬å‚æ•°ä»‹ç»</summary><div>
- `model_name_or_path`: å¿…é¡»ï¼Œæœ¬åœ°çš„TPæ¨¡å‹å‚æ•°è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `device`: è¿è¡Œç¯å¢ƒï¼Œé»˜è®¤ä¸ºgpuã€‚
</div></details>

### 3.7 LoRA å‚æ•°åˆå¹¶

ä¸ºäº†åç»­çš„**å‹ç¼©**å’Œ**é™æ€å›¾æ¨ç†**æ–¹ä¾¿ï¼Œæˆ‘ä»¬æä¾›LoRAå‚æ•°åˆå¹¶è„šæœ¬ï¼Œå¯ä»¥å°†LoRAå‚æ•°åˆå¹¶åˆ°ä¸»å¹²æ¨¡å‹å¹¶ä¿å­˜ç›¸åº”çš„æƒé‡ã€‚
```
python merge_lora_params.py \
    --model_name_or_path meta-llama/Llama-2-7b-chat \
    --lora_path ./checkpoints/llama_lora_ckpts
```
<details><summary>&emsp; è„šæœ¬å‚æ•°ä»‹ç»</summary><div>

- `model_name_or_path`: å¿…é¡»ï¼Œé¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è€…æœ¬åœ°çš„æ¨¡å‹è·¯å¾„ï¼Œç”¨äºçƒ­å¯æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `lora_path`: LoRAå‚æ•°å’Œé…ç½®è·¯å¾„ï¼Œå¯¹LoRAå‚æ•°è¿›è¡Œåˆå§‹åŒ–ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `merge_model_path`: å¿…é¡»ï¼Œåˆå¹¶å‚æ•°åä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `device`: è¿è¡Œç¯å¢ƒï¼Œé»˜è®¤ä¸ºgpuã€‚
</div></details>

### 3.8 å¤šè½®å¯¹è¯ç²¾è°ƒ

å½“å‰å¼€æºChat ç±»å‹æ¨¡å‹è¶Šæ¥è¶Šå¤šï¼ŒPaddleNLP å·²ç»é›†æˆäº† [Llama](./llama/README.md)ã€[Qwen](./qwen/README.md)ã€[ChatGLM](./chatglm/README.md) ç­‰ç³»åˆ—æ¨¡å‹ï¼Œä¹Ÿæ”¯æŒ[å¤šè½®å¯¹è¯ Prompt Template æ¨ç†](https://paddlenlp.readthedocs.io/zh/latest/get_started/chat_template.html)ï¼Œåªéœ€è¦è°ƒç”¨`apply_chat_template` å‡½æ•°å³å¯æ„é€ å°†å¯¹è¯å†å²å’Œç”¨æˆ·æœ€æ–° query æŒ‰ç…§æ¨¡å‹æŒ‡å®šè§„åˆ™æ‹¼æ¥åˆ°ä¸€èµ·ï¼Œå®ç°ä¸åŒæ¨¡å‹çš„å®šåˆ¶åŒ– Prompt è§„åˆ™æ¨ç†ã€‚

æ­¤å¤–å¤šè½®å¯¹è¯è®­ç»ƒç²¾è°ƒçš„åº”ç”¨åœºæ™¯ä¹Ÿæ˜¯è¶Šæ¥è¶Šå¤šï¼Œä¸åŒæ¨¡å‹çš„å¤šè½®å¯¹è¯æ¨¡æ¿æ„é€ è§„åˆ™éƒ½ä¸ä¸€è‡´ï¼Œä¸ºäº†åœ¨è®­ç»ƒä¾§æ ‡å‡†åŒ–å‰å¤„ç†ä¸Šçš„åŒºåˆ«ï¼Œè®¾è®¡äº†`chat_template`æ¥è§£å†³æ­¤é—®é¢˜ã€‚

#### 3.8.1 å¦‚ä½•æ„é€  `chat_template`

åªéœ€è¦æ·»åŠ ä¸€ä¸ª chat_template çš„é…ç½®å³å¯ä¸ºè¯¥æ¨¡å‹æ·»åŠ ç›¸åº”çš„å¤šè½®å¯¹è¯ç²¾è°ƒè®­ç»ƒæ”¯æŒï¼Œä»¥`qwen-14b-chat`é…ç½®æ–‡ä»¶

> ä»¥ä¸‹é…ç½®å‚è€ƒï¼šhttps://huggingface.co/Qwen/Qwen-14B-Chat/blob/main/qwen_generation_utils.py#L119

```json
{
    "system": "You are a helpful assistant.",
    "conversation": ["\n<|im_start|>user\n{{user}}<|im_end|>\n<|im_start|>assistant\n", "{{bot}}<|im_end|>"],
    "query": "\n<|im_start|>user\n{{query}}<|im_end|>\n<|im_start|>assistant\n",
}
```

æ³¨æ„ç‚¹ï¼š

1. é…ç½®æ–‡ä»¶åé»˜è®¤ä¸ºï¼š`chat_template.json`ã€‚
1. å¯¹äº `chat_template.json`é…ç½®æ–‡ä»¶ `query`å’Œ`conversation`å­—æ®µä¸ºå¿…é€‰é¡¹ï¼Œä¸”å†…å®¹éå¸¸ç±»ä¼¼ï¼Œä¸»è¦æ˜¯ä¸ºåº”å¯¹æ¨ç†å’Œè®­ç»ƒä¸¤ç§åœºæ™¯è®¾è®¡ä½¿ç”¨ï¼šquery åªç”¨äºæ¨ç†ï¼Œquery å’Œ conversation ç”¨äºè®­ç»ƒã€‚
1. ç”±äºè®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä¼šåœ¨æ–‡æœ¬ä¸­æ·»åŠ  ç‹¬ç‰¹token æ ‡è®°ï¼Œå…¶ä¸­åŒ…æ‹¬ bos_token, eos_token ä»¥åŠåƒä¸Šè¿°çš„ <|im_start|> è‡ªå®šä¹‰æ ‡è®°ç­‰ï¼Œæ•…åŸºäº chat_template çš„åˆ†è¯æ˜¯ä¸ä¼šæ·»åŠ  special_tokenï¼Œä¹Ÿå°±æ˜¯è¯´ tokenizer ä¸­çš„ `add_special_tokens` å‚æ•°å§‹ç»ˆè¦è®¾ç½®ä¸º `False`ã€‚
1. `conversation`å­—æ®µä¸ºæ•°ç»„ï¼Œä¸”å¿…é¡»ä¸ºä¸¤ä¸ªå…ƒç´ ï¼Œåˆ†åˆ«å¯¹åº”ç€ User å’Œ Bot çš„å¯¹è¯å†…å®¹ï¼Œå‰è€…åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å‚ä¸ loss çš„è®¡ç®—ï¼Œåè€…çš„å‚ä¸ Loss çš„è®¡ç®—ã€‚
1. åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œsystem æ–‡æœ¬çš„é•¿åº¦ä¸å¯å¤§äº `max_length`ï¼Œå½“å¯¹è¯è½®æ¬¡åªæœ‰ä¸€è½®æ—¶ï¼ŒåŸºäº token é•¿åº¦æ¥æˆªæ–­ï¼Œä¼ªä»£ç ä¸ºï¼š`(system_tokens + conversation_tokens)[:max_length]`ï¼›å¦åˆ™å°†åŸºäºå¯¹è¯è½®æ¬¡æ¥æˆªæ–­ï¼Œè¯¦ç»†æ¥è¯´å°±æ˜¯åœ¨è®¡ç®—è®­ç»ƒ token æ€»é•¿åº¦æ—¶ï¼Œä¼šä»åå¾€å‰è®¡ç®—æ¯ä¸€è½®çš„å¯¹è¯é•¿åº¦ï¼Œå¦‚æœæˆªæ­¢å½“å‰çš„å¯¹è¯ï¼ˆåŒ…å« User å’Œ Bot çš„æ€» tokens é•¿åº¦ï¼‰token é•¿åº¦å¤§äº `max_length`ï¼Œæ­¤æ—¶å°†å½“å‰å¯¹è¯è½®æ¬¡ç»™æˆªæ–­ï¼Œä¹Ÿä¸è®¡ç®—åç»­å†å²å¯¹è¯æ•°æ®ï¼Œç›´æ¥æ„é€ è®­ç»ƒæ•°æ®ã€‚
1. åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œsystem å¿…é¡»å­˜åœ¨ï¼Œä¸èƒ½è¢«æˆªæ–­ã€‚

#### 3.8.2 å¦‚ä½•ä½¿ç”¨ `chat_template` è¿›è¡Œè®­ç»ƒ

ä»¥`qwen-14b-chat`åŸºåº§æ¨¡å‹ä¸ºä¾‹ï¼Œé¦–å…ˆéœ€è¦è°ƒæ•´çš„æ˜¯è®­ç»ƒæ•°æ®éƒ¨åˆ†ï¼Œéœ€è¦ä¿è¯å¦‚ä¸‹æ ¼å¼ï¼š

```json
{"src": ["user-1", "user-2", ..., "user-n"], "tgt": ["bot-1", "bot-2", ..., "bot-n"]}
...
```

å…¶æ¬¡å°±æ˜¯å°†æ„é€ å¥½çš„`chat_template.json`æ–‡ä»¶ä¼ å…¥åˆ° `llm/finetune_generation.py` æ¨¡å—å½“ä¸­ï¼š

* ä½¿ç”¨æ¨¡å‹è‡ªå¸¦chat-template

> å¹¶ä¸æ˜¯æ‰€æœ‰çš„æ¨¡å‹æ”¯æŒchat-templateï¼ŒPaddleNLP æ­£åœ¨å…¨åŠ›æ”¯æŒï¼Œå¯æ ¹æ®æ˜¯å¦æœ‰ä¸‹è½½ `chat_template.json` æ–‡ä»¶æ¥åˆ¤æ–­è¯¥æ¨¡å‹æ˜¯å¦æ”¯æŒ chat-templateã€‚

```shell
python finetune_generation.py ... --model_name_or_path qwen/qwen-7b-chat --chat_template qwen/qwen-7b-chat
```

æ­¤æ—¶å½“ `chat_template` å‚æ•°å’Œ `model_name_or_path` å‚æ•°ä¸€è‡´æ—¶ï¼Œæ­¤æ—¶å°†é»˜è®¤ä½¿ç”¨æ¨¡å‹è‡ªå¸¦çš„chat_template.json` æ–‡ä»¶ã€‚

* ä½¿ç”¨è‡ªå®šä¹‰ chat-template

```shell
python finetune_generation.py ... --chat_template ./qwen_14b_chat_template.json
```

1. å½“ `chat_template` å‚æ•°å’Œ `model_name_or_path` å‚æ•°ä¸€è‡´æ—¶ï¼Œæ­¤æ—¶å°†é»˜è®¤ä½¿ç”¨æ¨¡å‹è‡ªå¸¦çš„ `chat_template.json` æ–‡ä»¶ã€‚
1. å½“ `chat_template` å‚æ•°ä¸ºæ–‡ä»¶è·¯å¾„æ—¶ï¼Œæ­¤æ—¶å°†ä½¿ç”¨è¯¥æ–‡ä»¶ä¸­çš„ `chat_template` é…ç½®ã€‚
1. å½“ `chat_template` å‚æ•°ä¸ºç©ºæ—¶ï¼Œæ­¤æ—¶ä¸ä½¿ç”¨ `chat_template` é…ç½®è¿›è¡Œè®­ç»ƒã€‚

## 4. æ¨¡å‹æ¨ç†

æ­¤å¤– PaddleNLP è¿˜æä¾›äº†é«˜æ€§èƒ½æ¨ç†æ¨¡å‹ï¼Œä»è€ŒåŠ é€Ÿ LLM æ¨¡å‹çš„éƒ¨ç½²è½åœ°ï¼Œè¯¦ç»†æ–‡æ¡£è¯·çœ‹ï¼š[Inference Model](./inference.md)

### 4.1 åŠ¨æ€å›¾æ¨ç†

```shell
# é¢„è®­ç»ƒ&SFTåŠ¨æ€å›¾æ¨¡å‹æ¨ç†
python predictor.py \
    --model_name_or_path meta-llama/Llama-2-7b-chat \
    --data_file ./data/dev.json \
    --dtype float16

# LoRAåŠ¨æ€å›¾æ¨¡å‹æ¨ç†
python predictor.py \
    --model_name_or_path meta-llama/Llama-2-7b-chat \
    --lora_path ./checkpoints/llama_lora_ckpts

# Prefix TuningåŠ¨æ€å›¾æ¨¡å‹æ¨ç†
python predictor.py \
    --model_name_or_path meta-llama/Llama-2-7b-chat \
    --data_file ./data/dev.json \
    --prefix_path ./checkpoints/llama_pt_ckpts
```

### 4.2 é™æ€å›¾æ¨ç†

```shell
# é¦–å…ˆéœ€è¦è¿è¡Œä¸€ä¸‹å‘½ä»¤å°†åŠ¨æ€å›¾å¯¼å‡ºä¸ºé™æ€å›¾
# LoRAéœ€è¦å…ˆåˆå¹¶å‚æ•°ï¼Œè¯¦è§3.7LoRAå‚æ•°åˆå¹¶
# Prefix Tuningæš‚ä¸æ”¯æŒ
python export_model.py \
    --model_name_or_path meta-llama/Llama-2-7b-chat \
    --output_path ./inference \
    --dtype float16


# é™æ€å›¾æ¨¡å‹æ¨ç†
python predictor.py \
    --model_name_or_path inference \
    --data_file ./data/dev.json \
    --dtype float16 \
    --mode static
```

### 4.3 Inference Model æ¨ç†

æ­¤å¤– PaddleNLP è¿˜æä¾›äº†é«˜æ€§èƒ½æ¨ç†æ¨¡å‹ï¼Œä»è€ŒåŠ é€Ÿ LLM æ¨¡å‹çš„éƒ¨ç½²è½åœ°ï¼Œè¯¦ç»†æ–‡æ¡£è¯·çœ‹ï¼š[Inference Model](./inference.md)

æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨å¦‚ä¸‹æ‰€ç¤ºï¼š

| Model                       | Inference Model | PTuning | Wint8 | PTQ |
|-----------------------------|-----------------|---------|-------|-----|
| [LLaMA1/2](./llama)         | âœ…               | âœ…       | âœ…     | âœ…   |
| [ChatGLM](./chatglm)        | âœ…               | âœ…       | âœ…     | âŒ   |
| [ChatGLM2](./chatglm2)      | âœ…               | âŒ       | âŒ     | âŒ   |
| [BaiChuan1](./baichuan)     | âœ…               | âœ…       | âœ…     | âœ…   |
| [BaiChuan2-7B](./baichuan)  | âŒ               | âŒ       | âŒ     | âŒ   |
| [BaiChuan2-13B](./baichuan) | âœ…               | âœ…       | âœ…     | âœ…   |
| [Bloom](./bloom)            | âœ…               | âœ…       | âœ…     | âŒ   |
| [GPT-3](./gpt-3)            | âœ…               | âŒ       | âŒ     | âŒ   |
| [Qwen](./qwen)              | âŒ               | âŒ       | âŒ     | âŒ   |

## 5. æœåŠ¡éƒ¨ç½²

### 5.1 ç¯å¢ƒå‡†å¤‡

- python >= 3.8
- gradio
- flask

### 5.2 Flask & Gradio UIæœåŠ¡åŒ–éƒ¨ç½²

æˆ‘ä»¬æä¾›äº†ä¸€å¥—ç®€å•æ˜“ç”¨çš„UIæœåŠ¡åŒ–éƒ¨ç½²è„šæœ¬:


```
python -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" flask_server.py \
    --model_name_or_path meta-llama/Llama-2-7b-chat \
    --port 8010 \
    --flask_port 8011 \
    --src_length 1024 \
    --dtype "float16"
```

<details><summary>&emsp; è„šæœ¬å‚æ•°ä»‹ç»</summary><div>

- `port`: Gradio UI æœåŠ¡ç«¯å£å·ï¼Œé»˜è®¤8011ã€‚
- `flask_port`: FlaskæœåŠ¡ç«¯å£å·ï¼Œé»˜è®¤8010ã€‚
- å…¶ä»–å‚æ•°è¯·å‚è§åŠ¨æ€å›¾æ¨ç†ä¸­å‚æ•°ã€‚

</div></details>

## 6. é‡åŒ–

é‡åŒ–ç®—æ³•å¯ä»¥å°†æ¨¡å‹æƒé‡å’Œæ¿€æ´»è½¬ä¸ºæ›´ä½æ¯”ç‰¹æ•°å€¼ç±»å‹è¡¨ç¤ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æ˜¾å­˜å ç”¨å’Œè®¡ç®—å¼€é”€ã€‚ä¸‹é¢æˆ‘ä»¬æä¾›GPTQå’ŒPaddleSlimè‡ªç ”çš„PTQç­–ç•¥ï¼Œåˆ†åˆ«å®ç°WINT4å’ŒW8A8é‡åŒ–ã€‚æ›´å¤šæŠ€æœ¯ç»†èŠ‚è¯¦è§[é‡åŒ–ç­–ç•¥è¯¦ç»†æ•™ç¨‹](https://github.com/PaddlePaddle/PaddleSlim/blob/develop/docs/zh_cn/tutorials/quant/advanced_quantization.md)

### 6.1 ç¯å¢ƒå®‰è£…
- PaddleSlim developç‰ˆæœ¬
- PaddlePaddle developç‰ˆæœ¬

### 6.2 æ•°æ®å‡†å¤‡

é‡åŒ–ä¸­é»˜è®¤ä½¿ç”¨è®­ç»ƒé›†ä½œä¸ºæ ¡æ­£ï¼ˆCalibartionï¼‰æ•°æ®é›†ï¼Œå¼€å‘é›†ä½œä¸ºè¯„ä¼°æ•°æ®é›†ã€‚å¦‚æœå¸Œæœ›ä½¿ç”¨å…¶ä»–æ•°æ®ä½œä¸ºæ ¡æ­£æ•°æ®é›†ï¼Œåˆ™åœ¨æ•°æ®ç›®å½•ä¸‹æ–°å¢`quant.json`æ–‡ä»¶ï¼Œæ–‡ä»¶æ ¼å¼è¯·å‚ç…§ç²¾è°ƒè®­ç»ƒæ•°æ®æ ¼å¼ã€‚

### 6.3 PTQ é‡åŒ–

```
python  finetune_generation.py ./llama/ptq_argument.json
```

### 6.4 GPTQ é‡åŒ–

```
python  finetune_generation.py ./llama/gptq_argument.json
```

### 6.5 é‡åŒ–å‚æ•°ä»‹ç»

<details><summary>&emsp; é‡åŒ–å‚æ•°ï¼ˆQuantArgumentï¼‰</summary><div>

- `quant_type`: PTQ,QATé‡åŒ–ç±»å‹ï¼Œé»˜è®¤ä¸ºA8W8ã€‚æ”¯æŒA8W8,WINT4ï¼ŒWINT8ï¼šA8W8æŒ‡å¯¹æ¿€æ´»ï¼ˆè¾“å…¥ï¼‰è¿›è¡ŒINT8é‡åŒ–ï¼Œå¯¹æ¨¡å‹æƒé‡è¿›è¡ŒINT8é‡åŒ–ï¼›WINT4æŒ‡ä»…å¯¹æ¨¡å‹æƒé‡è¿›è¡ŒINT4é‡åŒ–ï¼Œåç»­ä½¿ç”¨WeightOnlyè¿›è¡Œæ¨ç†ï¼›WINT8æŒ‡ä»…å¯¹æ¨¡å‹æƒé‡è¿›è¡ŒINT8é‡åŒ–ï¼Œåç»­ä½¿ç”¨WeightOnlyè¿›è¡Œæ¨ç†ã€‚
- `do_ptq`: æ˜¯å¦è¿›è¡ŒPTQé‡åŒ–ï¼Œé»˜è®¤ä¸ºFalseã€‚
- `ptq_step`: PTQé‡åŒ–æ­¥æ•°ï¼Œä¹Ÿå³æ¨¡å‹å‰å‘æ¬¡æ•°ï¼Œé»˜è®¤ä¸º32ã€‚
- `shift`: æ˜¯å¦åœ¨PTQé‡åŒ–å‰è¿›è¡Œ[Shiftç­–ç•¥](https://arxiv.org/abs/2304.09145)ï¼Œé»˜è®¤ä¸ºFalseã€‚ä½¿ç”¨Shiftç­–ç•¥éœ€è¦è®¾`do_ptq`ä¸ºTrueã€‚
- `shift_all_linear`: æ˜¯å¦å¯¹æ¨¡å‹ä¸­æ‰€æœ‰Linearå±‚åº”ç”¨Shiftï¼Œå¦‚æœä¸ºTrueï¼Œå°†ä¼šå¯¹éLayerNorm-Linearç»„åˆçš„Linearè¿›è¡ŒShiftï¼Œå¹¶ä¸”æ·»åŠ ä¸¤ä¸ªopï¼Œé»˜è®¤ä¸ºFalse
- `shift_sampler`: Shiftç­–ç•¥ä½¿ç”¨çš„samplerï¼Œé»˜è®¤ä¸ºnoneã€‚å¯é€‰noneï¼Œemaï¼šnoneæŒ‡ç›´æ¥åˆ©ç”¨MinMaxè®¡ç®—Shiftä¸­çš„é›¶ç‚¹ï¼›emaæŒ‡ä½¿ç”¨æŒ‡æ•°å¹³å‡è®¡ç®—Shiftä¸­é›¶ç‚¹ã€‚
- `shift_step`: Shifté‡‡æ ·æ­¥æ•°ï¼Œä¹Ÿå³æ¨¡å‹å‰å‘æ¬¡æ•°ï¼Œé»˜è®¤ä¸º32ã€‚
- `smooth`: æ˜¯å¦åœ¨PTQé‡åŒ–å‰è¿›è¡Œ[SmoothQuantç­–ç•¥](https://arxiv.org/abs/2211.10438)ï¼Œé»˜è®¤ä¸ºFalseã€‚ä½¿ç”¨Smoothç­–ç•¥éœ€è¦è®¾`do_ptq`ä¸ºTrueã€‚
- `smooth_all_linears`: æ˜¯å¦å¯¹æ¨¡å‹ä¸­æ‰€æœ‰Linearå±‚åº”ç”¨Smoothï¼Œå¦‚æœä¸ºTrueï¼Œå°†ä¼šå¯¹éLayerNorm-Linearç»„åˆçš„Linearè¿›è¡ŒSmoothï¼Œå¹¶ä¸”æ·»åŠ ä¸¤ä¸ªopï¼Œé»˜è®¤ä¸ºFalse
- `smooth_sampler`: Smoothç­–ç•¥ä½¿ç”¨çš„samplerï¼Œé»˜è®¤ä¸ºnoneï¼Œå¯é€‰noneï¼Œmulti_stepã€‚multi_stepä¼šä¿å­˜å¤šè½®å‰å‘ç»“æœè¿›è¡Œè®¡ç®—ï¼Œéœ€è¦æ›´å¤§çš„æ˜¾å­˜ã€‚
- `smooth_step`: Smoothé‡‡æ ·æ­¥æ•°ï¼Œä¹Ÿå³æ¨¡å‹å‰å‘æ¬¡æ•°ï¼Œé»˜è®¤ä¸º32ã€‚
- `smooth_piecewise_search`: Smoothæ˜¯å¦è¿›è¡Œåˆ†æ®µæœç´¢,é»˜è®¤ä¸ºFalseã€‚åˆ†æ®µæœç´¢æ ¹æ®æ•°å€¼å¤§å°å°†æ¿€æ´»åˆ†æˆKæ®µï¼Œå¯¹äºæ¯ä¸€æ®µè¿›è¡Œalhpaå’Œscaleçš„æœç´¢ã€‚
- `smooth_k_piece`: ä½¿ç”¨åˆ†æ®µæœç´¢åŠŸèƒ½æ—¶åˆ†æ®µæ•°é‡ï¼Œé»˜è®¤ä¸º3ã€‚æ ¹æ®ç»éªŒå»ºè®®10Bæ¨¡å‹è®¾ç½®ä¸º3ï¼Œ100Bæ¨¡å‹è®¾ç½®ä¸º6ã€‚
- `smooth_search_piece`: ä½¿ç”¨åˆ†æ®µæœç´¢åŠŸèƒ½æ—¶ï¼Œæ˜¯å¦æœç´¢åˆ†æ®µæ•°é‡ï¼Œé»˜è®¤ä¸ºFalseã€‚è®¾ä¸ºTrueæ—¶ï¼Œ`smooth_k_piece`å»ºè®®è®¾ä¸º6ï¼Œæœç´¢åˆ†æ®µæ•°é‡è€—æ—¶è¾ƒé•¿ï¼Œå¦‚éœ€åŠ é€ŸSmoothè¿‡ç¨‹å»ºè®®å…³é—­ã€‚
- `do_gptq`: æ˜¯å¦è¿›è¡ŒGPTQé‡åŒ–ï¼ŒGPTQå¯¹æ¨¡å‹è¿›è¡ŒWINT4é‡åŒ–ï¼Œç›¸æ¯”äºæ™®é€šPTQé‡åŒ–ç²¾åº¦æ›´é«˜ï¼Œé‡åŒ–æ—¶é—´è¾ƒé•¿ã€‚é»˜è®¤ä¸ºFalseã€‚
- `gptq_step`: GPTQé‡åŒ–æ­¥æ•°ï¼Œä¹Ÿå³æ¨¡å‹å‰å‘æ¬¡æ•°ï¼Œé»˜è®¤ä¸º8ã€‚
</div></details>


<details><summary>&emsp; å…¶ä»–å‚æ•°</summary><div>

- `per_device_train_batch_size`: é‡åŒ–å‰å‘æ‰¹å¤§å°ï¼Œé»˜è®¤ä¸º8ã€‚é‡åŒ–è¿‡ç¨‹åªæœ‰æ¨¡å‹å‰å‘ï¼Œç›¸æ¯”äºæ™®é€šè®­ç»ƒéœ€è¦æ˜¾å­˜è¾ƒå°‘ã€‚

- æ›´å¤šå‚æ•°è¯¦è§ç²¾è°ƒå‚æ•°ä»‹ç»ã€‚

</div></details>

## 7. è½¬åŒ– Pytorch æƒé‡

### 7.1 æ”¯æŒè‡ªåŠ¨è½¬åŒ–æƒé‡çš„æ¨¡å‹åˆ—è¡¨

ä»¥ä¸‹ä¸ºæ”¯æŒæƒé‡è‡ªåŠ¨è½¬åŒ–çš„ç³»åˆ—æ¨¡å‹åˆ—è¡¨ï¼š

| æ¨¡å‹       | æ˜¯å¦æ”¯æŒ |
|------------|----------|
| AlBert     | âœ…        |
| Bart       | âœ…        |
| Bert       | âœ…        |
| Bloom      | âœ…        |
| Clip       | âœ…        |
| DistilBert | âœ…        |
| Electra    | âœ…        |
| ErnieCode  | âœ…        |
| GLM        | âœ…        |
| Gpt        | âœ…        |
| Llama      | âœ…        |
| Mt5        | âœ…        |
| Opt        | âœ…        |
| Qwen       | âœ…        |
| Roberta    | âœ…        |
| Roformer   | âœ…        |
| RW         | âœ…        |
| T5         | âœ…        |

### 7.2 è½¬åŒ– Pytorch æƒé‡

PaddleNLP æä¾›äº†å¯è‡ªåŠ¨å°† Pytorch ç›¸å…³çš„æƒé‡è½¬åŒ–ä¸º Paddle æƒé‡çš„æ¥å£ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
from paddlenlp.transformers import AutoModelForCausalLM

AutoModelForCausalLM.from_pretrained("/path/to/pytorch/model", convert_from_torch=True, dtype="float16")
```

> dtype ä¸ºè½¬åŒ–æƒé‡çš„çœŸå® dtype æ•°æ®ç±»å‹ï¼Œé€šå¸¸ä¸ºï¼šfloat16, bloat16 å’Œ float32ã€‚

ä»¥ä¸Šä»£ç å¯è‡ªåŠ¨åŠ è½½ pytorch æƒé‡å¹¶è½¬åŒ–ä¸ºå¯¹åº” paddle æƒé‡ä¿å­˜åœ¨ `/path/to/pytorch/model` ç›®å½•ä¸‹ã€‚

### 7.3 åˆå¹¶ Pytorch åˆ†ç‰‡æƒé‡

å½“å‰ PaddleNLP ä»…æ”¯æŒè½¬åŒ–å•ä¸ª Pytorch æƒé‡ï¼š`pytorch_model.bin`æ–‡ä»¶ã€‚æ‰€ä»¥å½“Pytorch æƒé‡ä¸ºåˆ†ç‰‡æƒé‡æ—¶ï¼Œéœ€è¦å°†å…¶åˆå¹¶ï¼Œåˆå¹¶è„šæœ¬å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
import torch, os
state_dict = {}

files = [file for file in os.list("./path/to/pytorch/weight") if file.startswith("pytorch_model-")]

for file in files:
    state_dict.update(torch.load(file))

torch.save(state_dict, "pytorch_model.bin")
```
