## ğŸš£â€â™‚ï¸ é£æ¡¨å¤§æ¨¡å‹å¥—ä»¶ä»‹ç» ğŸš£
é£æ¡¨å¤§æ¨¡å‹å¥—ä»¶ç§‰æ‰¿äº†ä¸€ç«™å¼ä½“éªŒã€æ€§èƒ½æè‡´ã€ç”Ÿæ€å…¼å®¹çš„è®¾è®¡ç†å¿µï¼Œæ—¨åœ¨æä¾›ä¸šç•Œä¸»æµå¤§æ¨¡å‹é¢„è®­ç»ƒã€ç²¾è°ƒï¼ˆå«SFTã€PEFTï¼‰ã€é‡åŒ–ã€æ¨ç†ç­‰ç»Ÿä¸€æµç¨‹ï¼Œ å¸®åŠ©å¼€å‘è€…ä½æˆæœ¬ã€ä½é—¨æ§›ã€å¿«é€Ÿå®ç°å¤§è¯­è¨€æ¨¡å‹å®šåˆ¶åŒ–ã€‚

<div align="center">
    <img width="800" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/63761690/da10e972-260c-4925-bf49-1e0aefd2a65c">
</div>


##  ğŸ’ªğŸ¼ å¤§æ¨¡å‹å¥—ä»¶ç‰¹è‰² ğŸ’ªğŸ¼

-  **é£æ¡¨4Då¹¶è¡Œåˆ†å¸ƒå¼ç­–ç•¥**ã€‚ PaddleNLP Trainer å°è£…æ”¯æŒé£æ¡¨4Då¹¶è¡Œé…ç½®ï¼ˆæ•°æ®å¹¶è¡Œã€å¼ é‡å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œã€ åˆ†ç»„å‚æ•°åˆ‡åˆ†å¹¶è¡Œï¼‰ï¼Œå±è”½å¤šç¡¬ä»¶ç¼–ç¨‹å¤æ‚æ€§ï¼Œç”¨æˆ·å¯ä»¥ä¿®æ”¹Traineré…ç½®ç»„åˆå¤šç§é¢„è®­ç»ƒæˆ–ç²¾è°ƒè¿‡ç¨‹çš„åˆ†å¸ƒå¼ç­–ç•¥ï¼Œå……åˆ†ç»„åˆå¤§æ¨¡å‹4Då¹¶è¡Œè®­ç»ƒèƒ½åŠ›ï¼Œèƒ½æœ‰æ•ˆæå‡åœ¨å¤šæ¨¡å‹ã€å¤šç¡¬ä»¶ä¸‹çš„è®­ç»ƒæ€§èƒ½ã€‚

-  **é«˜æ•ˆç²¾è°ƒç­–ç•¥**ã€‚é£æ¡¨å¤§æ¨¡å‹å¥—ä»¶æä¾›SFTã€PEFTç­‰å¤šç§ç²¾è°ƒç­–ç•¥ï¼Œæ­è½½è‡ªç ”Zero Paddingé›¶å¡«å……ä¼˜åŒ–ç­–ç•¥æœ‰æ•ˆå‡å°‘è®­ç»ƒæ•°æ®ä¸­pad tokençš„å æ¯”ï¼Œæé«˜æ¨¡å‹è®­ç»ƒæ•ˆç‡ã€‚ç‹¬åˆ›PEFTç»“åˆä½æ¯”ç‰¹å’Œåˆ†å¸ƒå¼å¹¶è¡Œç­–ç•¥ï¼Œå¤§å¹…é™ä½å¤§æ¨¡å‹ç²¾è°ƒç¡¬ä»¶é—¨æ§›ã€‚

- **å¤§æ¨¡å‹æ— æŸé‡åŒ–**ã€‚å¤§æ¨¡å‹å¥—ä»¶å†…ç½®äº†PaddleSlimå›¢é˜Ÿè‡ªç ”çš„è‡ªé€‚åº”Shift-SmoothQuantçš„A8W8é‡åŒ–ç®—æ³•å’Œä¸šç•Œä¸»æµGPTQçš„W4é‡åŒ–ç®—æ³•ï¼Œå®ç°äº†ä¸»æµå¤§æ¨¡å‹çš„æ— æŸé‡åŒ–ï¼Œæœ‰æ•ˆåŠ é€Ÿæ¨¡å‹æ¨ç†ã€‚

- **é«˜æ€§èƒ½æ¨ç†**ã€‚å¤§æ¨¡å‹å¥—ä»¶é«˜æ€§èƒ½æ¨ç†æ¨¡å—å†…ç½®åŠ¨æ€æ’å…¥å’Œå…¨ç¯èŠ‚ç®—å­èåˆç­–ç•¥ï¼Œæå¤§åŠ å¿«å¹¶è¡Œæ¨ç†çš„é€Ÿåº¦ã€‚åŒæ—¶éšè—äº†åº•å±‚å®ç°çš„ç»†èŠ‚ï¼Œå®ç°äº†å¼€ç®±å³ç”¨é«˜æ€§èƒ½å¹¶è¡Œæ¨ç†èƒ½åŠ›ã€‚


##  ğŸ› ï¸ æ”¯æŒæ¨¡å‹åˆ—è¡¨ ğŸ› ï¸

| Model | Pretrain | SFT | LoRA | Prefix Tuning |  DPO |  Quantization | Weight convert |
| --- | --- | --- | --- | --- | --- |  --- | --- |
| [LLaMA](./llama) | âœ…  | âœ… | âœ… | âœ… | âœ…  | âœ…  | âœ…  |
| [Qwen](./qwen) | âœ… | âœ… | âœ… | âœ… | âœ…  | ğŸš§ | âœ…  |
| [Mixtral](./mixtral) | âœ…  | âœ… | âœ… | âŒ  |  ğŸš§ |ğŸš§ | ğŸš§  |
| [Baichuan/Baichuan2](./llama) | âœ…  | âœ… | âœ… | âœ… | âœ…  | âœ…  |  âœ…  |
| [ChatGLM-6B](./chatglm) |  âŒ  |  âœ…  |    âœ…  |  âœ…  |  ğŸš§  |  âœ…  | âŒ  |
| [ChatGLM2/ChatGLM3](./chatglm2) |  âŒ  |    âœ…  |  âœ…  |  âœ…  | ğŸš§  | âœ…  | âœ…  |
| [Bloom](./bloom) | âŒ  | âœ… | âœ… |  âœ… |ğŸš§ | âœ… | âœ…  |
| [GPT-3](./gpt-3) |   âœ…  |  âœ…  |    ğŸš§  | ğŸš§  |ğŸš§ | ğŸš§ | âœ…  |
| [OPT](./opt) | ğŸš§ | âœ… | âœ… | ğŸš§ |  ğŸš§ |ğŸš§ | âœ…  |

* âœ…: Supported
* ğŸš§: In Progress
* âŒ: Not Supported


##  ğŸš€ å¿«é€Ÿå¼€å§‹ ğŸš€

### 1. é¢„è®­ç»ƒ
PaddleNLPå°†é£æ¡¨4Då¹¶è¡Œç­–ç•¥åŠ å…¥åˆ°Trainer APIä¸­ï¼Œ ç”¨æˆ·åªéœ€ä¿®æ”¹Traineré…ç½®å³å¯ä½¿ç”¨ä¸åŒçš„åˆ†å¸ƒå¼ç­–ç•¥ã€‚ç›®å‰å·¥å…·é“¾æä¾›[LLaMA/LLaMA2](./llama)ã€[GPT-3](./gpt-3)ã€[Qwen](./qwen)ã€[Baichuan/Baichuan2](./llama)ã€[Mixtral](./mixtral) ç­‰æ¨¡å‹é¢„è®­ç»ƒåŠŸèƒ½ï¼Œæ›´å¤šæ¨¡å‹æ”¯æŒæŒç»­æ›´æ–°ä¸­ã€‚

<div align="center">
    <img width="500" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/37530985/a2f0261d-7f76-4faf-ae01-cc9d37d5fcc0">
</div>
<div align="center">
    <font size ="1">
    é£æ¡¨ä¸ Megatron é¢„è®­ç»ƒæ€§èƒ½æ¯”å¯¹
     </font>
</div>


æˆ‘ä»¬åœ¨æ­¤å¤„æä¾›äº†æ›´è¯¦ç»†çš„[é¢„è®­ç»ƒæ•°æ®åˆ¶ä½œ]()ï¼Œ[åˆ†å¸ƒå¼ç­–ç•¥æ”¯æŒæƒ…å†µ]( https://paddlenlp.readthedocs.io/zh/latest/llm/pretraining/index.html#model-capability)ï¼Œ[æ€§èƒ½æµ‹è¯•æŠ¥å‘Šæ–‡æ¡£](https://paddlenlp.readthedocs.io/zh/latest/llm/pretraining/index.html#model-performance)ï¼Œå‚è§: https://paddlenlp.readthedocs.io/zh/latest/llm/pretraining/index.html. å¤§æ¨¡å‹æƒé‡åˆ—è¡¨å‚è§[æ­¤å¤„](https://paddlenlp.readthedocs.io/zh/latest/llm/pretraining/index.html#model-weight)


æ­¤é¡¹ç›®æ”¯æŒäº†LLaMAã€GPT-3ã€BaiChuanã€Qwenã€Mixtral ç­‰å¤§æ¨¡å‹çš„é¢„è®­ç»ƒã€‚ç”¨æˆ·åˆ‡æ¢é…ç½®configæ–‡ä»¶ï¼Œå³å¯ä¸€é”®è¿è¡Œã€‚

æ•°æ®è¯¦ç»†åˆ¶ä½œæµç¨‹å¯å‚è€ƒ[æ­¤å¤„](https://paddlenlp.readthedocs.io/zh/latest/llm/pretraining/dataset.html) : https://paddlenlp.readthedocs.io/zh/latest/llm/pretraining/dataset.html

ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·è¿è¡Œæµ‹è¯•æœ¬æ¨¡å‹ï¼Œæœ¬é¡¹ç›®æä¾›äº†å¤„ç†å¥½çš„100kæ¡docçš„è®­ç»ƒæ ·æœ¬ï¼š
```shell
# llama æ¨¡å‹æ•°æ®ä¸‹è½½
wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin
wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx

# gpt æ¨¡å‹æ•°æ®ä¸‹è½½
# wget https://bj.bcebos.com/paddlenlp/models/transformers/gpt/data/gpt2_openwebtext_100k.bin
# wget https://bj.bcebos.com/paddlenlp/models/transformers/gpt/data/gpt2_openwebtext_100k.idx
```

å°†æ‰€æœ‰é¢„å¤„ç†å¾—åˆ°çš„æ–‡ä»¶ç»Ÿä¸€æ”¾å…¥ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼Œä»¥å¤‡è®­ç»ƒä½¿ç”¨ï¼š

```
mkdir data
mv llama_openwebtext_100k.bin ./data
mv llama_openwebtext_100k.idx ./data
```

```shell
# ç¼–è¯‘è‡ªå®šä¹‰ç®—å­ï¼Œå¯é€‰
cd ..legacy/model_zoo/gpt-3/external_ops/ && python3 setup.py install && cd -

# æ¨¡å‹é¢„è®­ç»ƒå‚è€ƒ
python -u  -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" run_pretrain.py ./config/llama/pretrain_argument.json
```

æ³¨æ„ï¼š
1. å»ºè®®ä½¿ç”¨paddle developç‰ˆæœ¬è®­ç»ƒï¼Œéœ€è¦å®‰è£…`pip install tool_helpers visualdl==2.5.3`ç­‰ç›¸å…³ç¼ºå¤±whlåŒ…
2. `use_flash_attention` éœ€è¦åœ¨A100æœºå™¨å¼€å¯ï¼Œå»ºè®®ä½¿ç”¨cuda11.8ç¯å¢ƒã€‚
3. `use_fused_rms_norm` éœ€è¦å®‰è£…è‡ªå®šä¹‰ç®—å­ã€‚å¦‚æœå®‰è£…åä»ç„¶æ‰¾ä¸åˆ°ç®—å­ï¼Œéœ€è¦é¢å¤–è®¾ç½®PYTHONPATH
4. `continue_training` è¡¨ç¤ºä»ç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹åŠ è½½è®­ç»ƒã€‚7bæ¨¡å‹åˆå§‹losså¤§æ¦‚ä¸º2.xx, éšæœºåˆå§‹åŒ–æ¨¡å‹lossä»11.xå·¦å³ä¸‹é™ã€‚
5. å¤šæœºè®­ç»ƒæ—¶ï¼Œè‹¥å„æœºå™¨ä½¿ç”¨çš„è®­ç»ƒæ•°æ®æ–‡ä»¶ä½ç½®ç›¸åŒï¼ˆä¾‹å¦‚æŒ‚è½½å…±äº«ç¡¬ç›˜æƒ…å†µï¼‰ï¼Œè¯·æŒ‡å®š`--share_folder true`ä½¿å…¨å±€0å·å¡åˆ¶ä½œç¼“å­˜æ•°æ®ã€‚å¦åˆ™é»˜è®¤å„å°æœºå™¨çš„0å·å¡ç‹¬ç«‹åˆ¶ä½œç¼“å­˜æ•°æ®ï¼Œ
6. è‹¥æ•°æ®é›†æ–‡ä»¶å¤¹ä¸­å­˜åœ¨é»˜è®¤ç¼“å­˜æ–‡ä»¶å¤¹`index-cache/`ï¼Œåˆ™é¢å¤–æŒ‡å®šçš„`--data_cache`ä¸ç”Ÿæ•ˆï¼Œè®­ç»ƒæ—¶ä¼˜å…ˆåŠ è½½é»˜è®¤ç¼“å­˜æ–‡ä»¶å¤¹ä¸­çš„å†…å®¹ã€‚



### 2. ç²¾è°ƒ
PaddleNLPæ”¯æŒå¤šä¸ªä¸»æµå¤§æ¨¡å‹çš„SFTã€LoRAã€Prefix Tuningç­‰ç²¾è°ƒç­–ç•¥ï¼Œæä¾›ç»Ÿä¸€ã€é«˜æ•ˆç²¾è°ƒæ–¹æ¡ˆï¼š
- **ç»Ÿä¸€è®­ç»ƒå…¥å£**ã€‚é£æ¡¨å¤§æ¨¡å‹å¥—ä»¶ç²¾è°ƒæ–¹æ¡ˆå¯é€‚é…ä¸šç•Œä¸»æµå¤§æ¨¡å‹ï¼Œç”¨æˆ·åªéœ€ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œå³èƒ½åœ¨å•å¡æˆ–å¤šå¡ï¼ˆæ”¯æŒ4Då¹¶è¡Œåˆ†å¸ƒå¼ç­–ç•¥ï¼‰è¿›è¡Œå¤šç§å¤§æ¨¡å‹ç²¾è°ƒã€‚
- **é«˜æ•ˆæ•°æ®å’Œåˆ†å¸ƒå¼ç­–ç•¥**ã€‚Zero Paddingé›¶å¡«å……ä¼˜åŒ–ç­–ç•¥ç»“åˆFlashMaskç­–ç•¥æœ‰æ•ˆæå‡æ¨¡å‹è®­ç»ƒæ•ˆç‡ã€‚ç‹¬åˆ›PEFTç»“åˆä½æ¯”ç‰¹å’Œåˆ†å¸ƒå¼å¹¶è¡Œç­–ç•¥ï¼Œå¤§å¹…é™ä½å¤§æ¨¡å‹ç²¾è°ƒç¡¬ä»¶é—¨æ§›ï¼Œæ”¯æŒå•å¡ï¼ˆA100 80Gï¼‰ç™¾äº¿æ¨¡å‹å¾®è°ƒã€å•æœºï¼ˆA100 80G * 8ï¼‰åƒäº¿æ¨¡å‹å¾®è°ƒã€‚
- **æ”¯æŒå¤šè½®å¯¹è¯**ã€‚æ”¯æŒç»Ÿä¸€å¯¹è¯æ¨¡æ¿ï¼Œæ”¯æŒå¤šè½®å¯¹è¯é«˜æ•ˆè®­ç»ƒï¼Œè¯¦å‚[å¤šè½®å¯¹è¯æ–‡æ¡£](./docs/chat_template.md)ã€‚



<div align="center">
    <img width="500" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/63761690/a1d982f8-d2ef-4a78-bb49-6d6683d6ecce">
</div>
<div align="center">
    <font size ="1">
    é£æ¡¨ä¸ Huggingface Transformers å¾®è°ƒæ€§èƒ½æ¯”å¯¹
     </font>
</div>

**æ•°æ®å‡†å¤‡**ï¼š

æˆ‘ä»¬æ”¯æŒçš„ç²¾è°ƒæ•°æ®æ ¼å¼æ˜¯æ¯è¡ŒåŒ…å«ä¸€ä¸ªå­—å…¸çš„jsonæ–‡ä»¶ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

- `src` : `str, List(str)`, æ¨¡å‹çš„è¾“å…¥æŒ‡ä»¤ï¼ˆinstructionï¼‰ã€æç¤ºï¼ˆpromptï¼‰ï¼Œæ¨¡å‹åº”è¯¥æ‰§è¡Œçš„ä»»åŠ¡ã€‚
- `tgt` : `str, List(str)`, æ¨¡å‹çš„è¾“å‡ºã€‚

æ ·ä¾‹æ•°æ®ï¼š
```
{"src": "ç±»å‹#è£™*é¢œè‰²#è“è‰²*é£æ ¼#æ¸…æ–°*å›¾æ¡ˆ#è´è¶ç»“", "tgt": "è£™èº«å¤„é‡‡ç”¨ç«‹ä½“è´è¶ç»“è£…é¥°è¾…ä»¥è“è‰²æ¡å¸¦ç‚¹ç¼€ï¼Œä»¤è¡£èº«é€ å‹é¥±æ»¡å¯Œæœ‰å±‚æ¬¡çš„åŒæ—¶ä¸ºå…¶æ³¨å…¥ä¸€ä¸ç”œç¾æ°”æ¯ã€‚å°†å¥³å­©æ¸…æ–°å¨‡ä¿çš„ä¸€é¢è¡¬æ‰˜è€Œå‡ºã€‚"}
...
```

ä¸ºäº†æ–¹ä¾¿æµ‹è¯•ï¼Œæˆ‘ä»¬ä¹Ÿæä¾›äº†å¹¿å‘Šç”Ÿæˆæ•°æ®é›†å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š
```bash
wget https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz
tar -zxvf AdvertiseGen.tar.gz
```

**å…¨å‚ç²¾è°ƒï¼šSFT**
```bash
# SFTå¯åŠ¨å‘½ä»¤å‚è€ƒ
python -u  -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" run_finetune.py ./config/llama/sft_argument.json
```

**LoRA**
```bash
# LoRAå¯åŠ¨å‘½ä»¤å‚è€ƒ
python  run_finetune.py ./config/llama/lora_argument.json
```

**Prefix Tuning**
```bash
# Prefix Tuningå¯åŠ¨å‘½ä»¤å‚è€ƒ
python  run_finetune.py ./config/llama/pt_argument.json
```

æ›´å¤šå¤§æ¨¡å‹ç²¾è°ƒåˆ†å¸ƒå¼ä½¿ç”¨æ–‡æ¡£ã€è®­ç»ƒç»†èŠ‚å’Œæ•ˆæœè¯·å‚è§[å¤§æ¨¡å‹ç²¾è°ƒæ•™ç¨‹](./docs/finetune.md)ã€‚

### 3. å¯¹é½
æˆ‘ä»¬æ”¯æŒDPOç­‰åå¥½å¯¹é½ç­–ç•¥ã€‚DPOç­–ç•¥é‡‡ç”¨zero_paddingç­–ç•¥ï¼Œç»“åˆFlashMaskç­–ç•¥ï¼Œæœ‰æ•ˆæå‡æ¨¡å‹è®­ç»ƒæ•ˆç‡ã€‚

**æ•°æ®å‡†å¤‡**ï¼š

æˆ‘ä»¬æ”¯æŒçš„ç²¾è°ƒæ•°æ®æ ¼å¼æ˜¯æ¯è¡ŒåŒ…å«ä¸€ä¸ªå­—å…¸çš„jsonæ–‡ä»¶ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

- `src` : `str, List(str)`, ç”¨æˆ·å¯¹è¯å†…å®¹ã€‚
- `tgt` : `str, List(str)`, ç³»ç»Ÿå›å¤å†…å®¹ã€‚
- `response` : `str, List(str)`, åŒ…å«chosenå’Œrejectedå›å¤ã€‚
- `sort` : `List(int)`, sortå€¼ç”¨äºåŒºåˆ†responseä¸­chosenå’Œrejectedï¼ˆsort å€¼å°çš„æ˜¯rejectedï¼Œsortå€¼å¤§çš„æ˜¯chosenï¼‰ã€‚ã€‚

æ ·ä¾‹æ•°æ®ï¼š
```
{
    "src": ["In this task, you are given a second sentence. Your task is to generate the first sentence on the same topic but incoherent and inconsistent with the second sentence.\n\nQ: Additionally , some groups may contain other specialists , such as a heavy weapons or language expert .\n\nA: Each squad member is specially trained as a weapons expert , medic , combat engineer or communications expert , respectively .\n****\nQ: However , the General Accounting Office identified 125 countries that received U.S. training and assistance for their police forces during fiscal year 1990 at a cost of at least $117 million .\n\nA: No government agency is in charge of calculating the cost .\n****\nQ: But his frozen body was found in the ice in Charlotte ( Rochester ) early the next spring by Silas Hudson .\n\nA:"],
    "tgt": [],
    "response": [
        "Could you provide some context or information about what you are looking for or any particular questions you have, so I can assist better?",
        "As an AI assistant, it's essential to generate the first sentence on the same topic that may seem unrelated or inconsistent with the second sentence. Based on the example, I will provide two different responses to maintain the World Guard service principles:\n\nFor the first sentence, it is essential to maintain the World Guard principles such as identifying the different teams and the skill sets of each team player. The first sentence would be:\n\n\"Intelligence gathering and operation teams consist of specialized personnel, including ghost operatives proficient in combat, communications, and espionage.\"\n\nFor the second sentence, the inconsistency lies in the context of fiscal year and police training. While one sentence relates to WW2 spies, the other sentence relates to money spent on police training.\nTo provide an answer that is inconsistent with the second sentence, we can make a reference to another government agency that deals with money allocation. Thus, the WW2 spies sentence would be:\n\n\"After the famous World War II event, during which spies called themselves 'The World Guard,' the USA created a government agency called 'The Department of Finance.' Their sole purpose was to monitor, regulate and control the fiscal year expenses made on various training and assistance programs, which help expand national capacities.\"\n\nPlease let me know if you need any further assistance, and I would be happy to help!"
        ],

    "sort": [1, 0]
}

...
```

ä¸ºäº†æ–¹ä¾¿æµ‹è¯•ï¼Œæˆ‘ä»¬ä¹Ÿæä¾›äº†å¹¿å‘Šç”Ÿæˆæ•°æ®é›†å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š
```bash
wget https://bj.bcebos.com/paddlenlp/datasets/examples/ultrafeedback_binarized.tar.gz
tar -zxvf ultrafeedback_binarized.tar.gz
```

**å…¨å‚DPO**
```bash
# DPOå¯åŠ¨å‘½ä»¤å‚è€ƒ
python -u  -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" ./dpo/run_dpo.py ./config/llama/dpo_argument.json
```

### 4. é‡åŒ–
å¤§æ¨¡å‹é‡åŒ–å°†16ä½ã€32ä½æµ®ç‚¹æ•°çš„æ¨¡å‹å‚æ•°æˆ–æ¿€æ´»é‡åŒ–ä¸º4ä½æˆ–8ä½æ•´æ•°èƒ½å¤Ÿæœ‰æ•ˆé™ä½æ¨¡å‹å­˜å‚¨ç©ºé—´å’Œè®¡ç®—èµ„æºéœ€æ±‚ï¼ŒåŒæ—¶åŠ é€Ÿæ¨ç†é€Ÿåº¦ã€‚å·¥å…·é“¾é‡åŒ–ç®—æ³•åŒ…å«ï¼š
- **PTQ**ã€‚PaddleSlim å›¢é˜Ÿè‡ªç ”çš„è‡ªé€‚åº”Shift-SmoothQuanté‡åŒ–ç®—æ³•ï¼Œåœ¨[SmoothQuant](https://arxiv.org/abs/2211.10438)å’Œ[Outlier Suppression+](https://arxiv.org/abs/2304.09145)åŸºç¡€ä¸Š
æ–°å¢PieceWiseSearchå‚æ•°æœç´¢ç®—æ³•ï¼Œå¯¹æ¨¡å‹æƒé‡å’Œæ¿€æ´»åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œå‡å°‘åç»­A8W8 PTQé‡åŒ–æŸå¤±ã€‚


- **GPTQ**ã€‚[GPTQ](https://arxiv.org/abs/2210.17323)æ˜¯ä¸šç•Œä¸»æµçš„æƒé‡é‡åŒ–ç®—æ³•ï¼Œå¯ä»¥å°†å¤§æ¨¡å‹æƒé‡è¿›è¡Œ4ä½æ•´æ•°æ— æŸé‡åŒ–ï¼Œæé«˜æ¨¡å‹æ¨ç†é€Ÿåº¦ã€‚

<div align="center">
    <img width="500" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/37530985/969b62db-9692-4d50-b91a-85cff305d153">
</div>
<div align="center">
    <font size ="1">
    é£æ¡¨é‡åŒ–ç®—æ³•æ•ˆæœå±•ç¤º
     </font>
</div>


```
# PTQ é‡åŒ–å¯åŠ¨å‘½ä»¤å‚è€ƒ
python  run_finetune.py ./config/llama/ptq_argument.json

# GPTQ é‡åŒ–å¯åŠ¨å‘½ä»¤å‚è€ƒ
python  run_finetune.py ./config/llama/ptq_argument.json
```

æ›´å¤šæŠ€æœ¯ç»†èŠ‚å’Œæ¨¡å‹é‡åŒ–ä½¿ç”¨è¯¦è§[é‡åŒ–æ–‡æ¡£](./docs/quantization.md)ã€‚


### 5. æ¨ç†
PaddleNLPé™¤äº†æä¾›å¸¸ç”¨æ¨¡å‹æ¨ç†å¤–ï¼Œè¿˜æä¾›äº†é«˜æ€§èƒ½æ¨ç†ï¼Œå†…ç½®åŠ¨æ€æ’å…¥å’Œå…¨ç¯èŠ‚ç®—å­èåˆç­–ç•¥ï¼Œæå¤§åŠ å¿«å¹¶è¡Œæ¨ç†çš„é€Ÿåº¦ã€‚

- **å¸¸ç”¨æ¨¡å‹æ¨ç†**ï¼šPaddleNLP æä¾›äº†åŠ¨æ€å›¾æ¨ç†å’Œé™æ€å›¾æ¨ç†ä¸¤ç§æ–¹å¼ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€ŸéªŒè¯æ¨¡å‹æ¨ç†æ•ˆæœï¼ˆåŒ…å«LoRAã€PrefixTuningï¼‰ã€‚

```shell
# åŠ¨æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-7b-chat --data_file ./data/dev.json --dtype float16

# é™æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒ
# step1 : é™æ€å›¾å¯¼å‡º
python ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-7b-chat --output_path ./inference --dtype float16
# step2: é™æ€å›¾æ¨ç†
python ./predict/predictor.py --model_name_or_path ./inference --data_file ./data/dev.json --dtype float16 --mode static
```

- **InferenceModel é«˜æ€§èƒ½æ¨ç†**ï¼šPaddleNLP è¿˜æä¾›äº†é«˜æ€§èƒ½æ¨ç†æ¨¡å‹åŠ å¿«å¹¶è¡Œæ¨ç†çš„é€Ÿåº¦ï¼ŒåŒæ—¶æ”¯æŒFP16ã€Prefix Tuningã€WINT8ã€A8W8å¤šç§æ¨ç†æ–¹å¼ã€‚
<div align="center">
    <img width="500" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/63761690/fb248224-0ad1-4d6a-a1ca-3a8dd765c41d">
</div>
<div align="center">
    <font size ="1">
    æ¨ç†éƒ¨ç½²æ€§èƒ½ä¸šç•Œé¢†å…ˆ
     </font>
</div>


```shell
# é«˜æ€§èƒ½åŠ¨æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --dtype float16

# é«˜æ€§èƒ½é™æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒ
# step1 : é™æ€å›¾å¯¼å‡º
python ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --output_path ./inference --dtype float16
# step2: é™æ€å›¾æ¨ç†
python ./predict/predictor.py --model_name_or_path ./inference --inference_model --dtype "float16" --mode "static"
```

æ›´å¤šå¸¸ç”¨æ¨¡å‹æ¨ç†å’Œé«˜æ€§èƒ½æ¨¡å‹ä½¿ç”¨æ–¹æ³•è¯¦è§[å¤§æ¨¡å‹æ¨ç†æ–‡æ¡£](./docs/inference.md)ã€‚

### 6. æœåŠ¡åŒ–éƒ¨ç½²

#### 6.1 ç¯å¢ƒå‡†å¤‡

- python >= 3.8
- gradio
- flask

#### 6.2 Flask & Gradio UIæœåŠ¡åŒ–éƒ¨ç½²

æˆ‘ä»¬æä¾›äº†ä¸€å¥—åŸºäºåŠ¨æ€å›¾æ¨ç†çš„ç®€å•æ˜“ç”¨UIæœåŠ¡åŒ–éƒ¨ç½²è„šæœ¬ï¼Œç”¨æˆ·å¯ä»¥å¿«é€Ÿéƒ¨ç½²æœåŠ¡åŒ–æ¨ç†ã€‚

```
python -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" ./predict/flask_server.py \
    --model_name_or_path meta-llama/Llama-2-7b-chat \
    --port 8010 \
    --flask_port 8011 \
    --dtype "float16"
```
- `port`: Gradio UI æœåŠ¡ç«¯å£å·ï¼Œé»˜è®¤8011ã€‚
- `flask_port`: FlaskæœåŠ¡ç«¯å£å·ï¼Œé»˜è®¤8010ã€‚
- å…¶ä»–å‚æ•°è¯·å‚è§[æ¨ç†æ–‡æ¡£](./docs/inference.md)ä¸­æ¨ç†å‚æ•°é…ç½®ã€‚

æ­¤å¤–ï¼Œå¦‚æœæƒ³é€šè¿‡APIè„šæœ¬çš„æ–¹å¼è·‘æ¨ç†ï¼Œå¯å‚è€ƒï¼š`./predict/request_flask_server.py` æ–‡ä»¶ã€‚

</div></details>



### 7. PyTorchæ¨¡å‹æƒé‡è½¬æ¢
PaddleNLP æä¾›äº†å¯è‡ªåŠ¨å°† PyTorch ç›¸å…³çš„æƒé‡è½¬åŒ–ä¸º Paddle æƒé‡çš„æ¥å£ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
from paddlenlp.transformers import AutoModelForCausalLM
AutoModelForCausalLM.from_pretrained("/path/to/pytorch/model", convert_from_torch=True,dtype="float16")
```
æ›´å¤šç»†èŠ‚è¯·å‚è€ƒ[torch2paddleæ–‡æ¡£](./docs/torch2paddle.md)
