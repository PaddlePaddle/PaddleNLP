# ğŸš£â€â™‚ï¸ ä½¿ç”¨PaddleNLPåœ¨æµ·å…‰DCUä¸Šè¿è¡Œllama2-13bæ¨¡å‹ ğŸš£
Paddleæ¡†æ¶ä¸PaddleNLPå¥—ä»¶åœ¨æµ·å…‰çš„DCUäº§å“ä¸Šè¿›è¡Œäº†æ·±åº¦çš„é€‚é…å’Œä¼˜åŒ–ï¼Œå®ç°äº†å¤§æ¨¡å‹åœ¨è®­ç»ƒå’Œæ¨ç†ä¸Šä¸GPUé«˜åº¦ç»Ÿä¸€ï¼Œåœ¨ç²¾åº¦å’Œæ€§èƒ½ä¸Šæ‹¥æœ‰å…ˆè¿›æ°´å¹³ã€‚

æµ·å…‰DCUäº§å“åœ¨PaddleNLPç»„åˆå¥—ä»¶ä¸Šæ‹¥æœ‰å¤šç§æŠ€æœ¯ä¼˜ç‚¹ï¼š

- **å®Œå…¨æ”¯æŒ4Dæ··åˆå¹¶è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œçµæ´»é€‚åº”å„ç§è®­ç»ƒç­–ç•¥ã€‚**
- **å„ç±»é«˜æ€§èƒ½çš„èåˆç®—å­ï¼Œæå‡è®­æ¨æ€§èƒ½ã€‚**
- **ä¼˜åŒ–çš„é€šè®¯åº“ï¼Œæ©ç›–åˆ†å¸ƒå¼è®­æ¨å»¶è¿Ÿã€‚**

##  ğŸš€ å¿«é€Ÿå¼€å§‹ ğŸš€

## ç¯å¢ƒå‡†å¤‡ï¼š

### 1.ç¡¬ä»¶å¹³å°


 | èŠ¯ç‰‡ç±»å‹ | DTKç‰ˆæœ¬ |
 | --- | --- |
 | K100_AI | 24.04.1 |

**æœ¬ç¤ºä¾‹ä½¿ç”¨8å¡æœºå™¨ï¼Œå¹¶é€šè¿‡å¾®è°ƒè®­ç»ƒ+æ¨ç†çš„æµç¨‹æ¼”ç¤ºè¿è¡Œæ–¹æ³•ï¼Œä½¿ç”¨hy-smiå‘½ä»¤æŸ¥çœ‹è¿è¡Œç¯å¢ƒä¸­çš„DCUä¿¡æ¯ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š**
```
$ hy-smi

============================ System Management Interface =============================
======================================================================================
DCU     Temp     AvgPwr     Perf     PwrCap     VRAM%      DCU%      Mode
0       49.0C    118.0W     auto     800.0W     0%         0%        Normal
1       48.0C    120.0W     auto     800.0W     0%         0%        Normal
2       53.0C    116.0W     auto     800.0W     0%         0%        Normal
3       49.0C    138.0W     auto     800.0W     0%         0%        Normal
======================================================================================
=================================== End of SMI Log ===================================
```

### 2.ç¯å¢ƒå‡†å¤‡ï¼š
æ¨èä½¿ç”¨dockeræ–¹å¼è¿è¡Œï¼Œæä¾›æ‹‰å–çš„dockeré•œåƒï¼Œå…³äºæœ¬é¡¹ç›®æ‰€éœ€æ–°ç‰ˆæœ¬ DTK ç­‰å‡å¯ä»[å…‰åˆ](https://developer.hpccube.com/tool/)å¼€å‘è€…ç¤¾åŒºä¸‹è½½å®‰è£…ï¼Œdockerä¸­é»˜è®¤ä½¿ç”¨dtk-24.04.1ã€‚

(1). æ‹‰å–é•œåƒ
```
# æ³¨æ„æ­¤é•œåƒä»…ä¸ºå¼€å‘ç¯å¢ƒï¼Œé•œåƒä¸­ä¸åŒ…å«é¢„ç¼–è¯‘çš„é£æ¡¨å®‰è£…åŒ…
docker pull registry.baidubce.com/device/paddle-dcu:dtk24.04.1-kylinv10-gcc82
```
(2). å‚è€ƒå¦‚ä¸‹å‘½ä»¤å¯åŠ¨å®¹å™¨ï¼š
```
docker run -it \
    --network=host \
    --name=paddle_llama \
    --privileged \
    --device=/dev/kfd \
    --device=/dev/dri \
    --ipc=host \
    --shm-size=128G \
    --group-add video \
    --cap-add=SYS_PTRACE \
    --security-opt seccomp=unconfined \
    -u root \
    --ulimit stack=-1:-1 \
    --ulimit memlock=-1:-1 \
    -v $(pwd):/workspace \
    -v /opt/hyhal:/opt/hyhal \
    registry.baidubce.com/device/paddle-dcu:dtk24.04.1-kylinv10-gcc82 \
    /bin/bash
```
(3). å®‰è£…paddle
```
# paddlepaddleã€é£æ¡¨ã€æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæä¾›è¿ç®—åŸºç¡€èƒ½åŠ›
python -m pip install paddlepaddle-dcu==3.0.0b2 -i https://www.paddlepaddle.org.cn/packages/stable/dcu/
```

(4). å…‹éš†PaddleNLPä»“åº“ä»£ç ï¼Œå¹¶å®‰è£…ä¾èµ–
```
# ç”¨paddlenlp developåˆ†æ”¯
git clone https://github.com/PaddlePaddle/PaddleNLP.git
cd PaddleNLP/llm # åˆ°è¾¾è¿è¡Œç›®å½•
pip install -r ../requirements.txt
```
(5). å®‰è£… paddlenlp_ops
```
# PaddleNLPä»“åº“å†…ç½®äº†rmsç›¸å…³çš„ä¸“ç”¨ç®—å­
cd legacy/model_zoo/gpt-3/external_ops
python setup.py install
```

## 3.å¾®è°ƒï¼š
- **æ³¨ï¼š** è¿›å…¥llmè·¯å¾„è¿›è¡Œä»¥ä¸‹æ“ä½œã€‚
### æ•°æ®é›†å‡†å¤‡
æˆ‘ä»¬æä¾›äº†æ•°æ®é›†demoä¾¿äºæ‚¨è°ƒè¯•ä½¿ç”¨
```
wget https://bj.bcebos.com/paddlenlp/datasets/examples/alpaca_demo.gz
tar -xvf alpaca_demo.gz
```
æˆ‘ä»¬æ”¯æŒçš„ç²¾è°ƒæ•°æ®æ ¼å¼æ˜¯æ¯è¡ŒåŒ…å«ä¸€ä¸ªå­—å…¸çš„jsonæ–‡ä»¶ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- `src`: `str, List(str)`ï¼ŒæŒ‡æ¨¡å‹çš„è¾“å…¥æŒ‡ä»¤ï¼ˆinstructionï¼‰ã€æç¤ºï¼ˆpromptï¼‰ï¼Œæ¨¡å‹åº”è¯¥æ‰§è¡Œçš„ä»»åŠ¡ã€‚
- `tgt`: `str, List(str)`ï¼ŒæŒ‡æ¨¡å‹çš„è¾“å‡ºã€‚
æ ·ä¾‹æ•°æ®ï¼š
```
{"src": "ç±»å‹#è£™*é¢œè‰²#è“è‰²*é£æ ¼#æ¸…æ–°*å›¾æ¡ˆ#è´è¶ç»“", "tgt": "è£™èº«å¤„é‡‡ç”¨ç«‹ä½“è´è¶ç»“è£…é¥°è¾…ä»¥è“è‰²æ¡å¸¦ç‚¹ç¼€ï¼Œä»¤è¡£èº«é€ å‹é¥±æ»¡å¯Œæœ‰å±‚æ¬¡çš„åŒæ—¶ä¸ºå…¶æ³¨å…¥ä¸€ä¸ç”œç¾æ°”æ¯ã€‚å°†å¥³å­©æ¸…æ–°å¨‡ä¿çš„ä¸€é¢è¡¬æ‰˜è€Œå‡ºã€‚"}
...
#æ‚¨å¯ä»¥æ ¹æ®æ­¤æ ¼å¼è‡ªè¡Œåˆ¶ä½œç²¾è°ƒæ•°æ®ã€‚
```
### Loraå¾®è°ƒ

å¯å‚è€ƒä»¥ä¸‹è„šæœ¬å¯åŠ¨Loraå¾®è°ƒè®­ç»ƒï¼š
```
PYTHONPATH=.. python run_finetune.py dcu/llama/lora_argument.json
```
### sftå¾®è°ƒ
å¯å‚è€ƒä»¥ä¸‹è¶…å‚å¯åŠ¨Lsftå¾®è°ƒè®­ç»ƒï¼š
```
PYTHONPATH=.. python run_finetune.py dcu/llama/sft_argument.json
```
## 3.é¢„è®­ç»ƒï¼š
### æ•°æ®å‡†å¤‡
æ•°æ®è¯¦ç»†åˆ¶ä½œæµç¨‹å¯å‚è€ƒ[æ­¤å¤„](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/tools/preprocess/README.md)ï¼Œä¾‹ï¼šOpenWebText2é¢„è®­ç»ƒæ•°æ®åˆ¶ä½œå‚è€ƒ[æ­¤å¤„](https://paddlenlp.readthedocs.io/zh/latest/llm/pretraining/data/OpenWebText2.html)

ä¸ºäº†æ–¹ä¾¿ç”¨æˆ·è¿è¡Œæµ‹è¯•æœ¬æ¨¡å‹ï¼Œæœ¬é¡¹ç›®æä¾›äº†å¤„ç†å¥½çš„100kæ¡docçš„è®­ç»ƒæ ·æœ¬ï¼š

```
cd PaddleNLP/llm/
mkdir data && cd data
wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin
wget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx
cd .. && tree data 
data
â”œâ”€â”€ llama_openwebtext_100k.bin
â””â”€â”€ llama_openwebtext_100k.idx
```
- **æ³¨ï¼š** ä¸å¾®è°ƒæ•°æ®é›†åŒºåˆ†è·¯å¾„
### è¿è¡Œè„šæœ¬

è¯¥è®­ç»ƒè„šæœ¬å¯ä»¥å•èŠ‚ç‚¹ä¹Ÿå¯å¤šèŠ‚ç‚¹è¿è¡Œï¼Œæ¯èŠ‚ç‚¹8å¼ DCU-K100AI-64Gã€‚

å¹¶è¡Œé…ç½®é‡‡ç”¨TP 1ï¼ŒPP 8ï¼Œä½¿ç”¨fp16ç²¾åº¦é¢„è®­ç»ƒã€‚

å¯å‚è€ƒä»¥ä¸‹è„šæœ¬å¯åŠ¨é¢„è®­ç»ƒï¼š

```
python -m paddle.distributed.launch \
    --gpus '0,1,2,3,4,5,6,7' \
    run_pretrain.py dcu/llama/pretrain_pp8.json
```

## 4.é«˜æ€§èƒ½æ¨ç†
é«˜æ€§èƒ½æ¨ç†å†…ç½®åŠ¨æ€æ’å…¥å’Œå…¨ç¯èŠ‚ç®—å­èåˆç­–ç•¥ï¼Œéšè—äº†åº•å±‚å®ç°çš„ç»†èŠ‚ï¼Œå®ç°äº†å¼€ç®±å³ç”¨é«˜æ€§èƒ½å¹¶è¡Œæ¨ç†èƒ½åŠ›ã€‚åœ¨ä¿æŒé«˜æ€§èƒ½æ¨ç†å’ŒåŠ¨æ€æ’å…¥çš„åŸºç¡€ä¸Šå¯ä»¥åŠ¨æ€åœ°ä¸ºcachekvåˆ†é…å­˜å‚¨ç©ºé—´ï¼Œæå¤§åœ°èŠ‚çœæ˜¾å­˜ï¼Œä»è€Œåœ¨åŒä¸€æ—¶åˆ»å¤„ç†æ›´å¤šçš„queryä»¥è·å¾—ååçš„æå‡ã€‚

(1). ç¯å¢ƒå‡†å¤‡

PaddleNLP é’ˆå¯¹äºTransformer ç³»åˆ—ç¼–å†™äº†é«˜æ€§èƒ½è‡ªå®šä¹‰ç®—å­ï¼Œæå‡æ¨¡å‹åœ¨æ¨ç†å’Œè§£ç è¿‡ç¨‹ä¸­çš„æ€§èƒ½ï¼Œä½¿ç”¨ä¹‹å‰éœ€è¦é¢„å…ˆå®‰è£…è‡ªå®šä¹‰ç®—å­åº“ï¼š
```
# DCUè®¾å¤‡å®‰è£…è‡ªå®šä¹‰ç®—å­
cd PaddleNLP/csrc && python3 setup_hip.py install
```
(2). é«˜æ€§èƒ½æ¨ç†

ä¸‹é¢åˆ†åˆ«ç»™å‡ºå…³é—­BlockAttentionå’Œæ‰“å¼€BlockAttentionè¿›è¡Œé«˜æ€§èƒ½æ¨ç†çš„å‘½ä»¤å‚è€ƒï¼š

a.å…³é—­BlockAttentionçš„é«˜æ€§èƒ½æ¨ç†

**åŠ¨æ€å›¾ï¼š**

```
# fp16
python3 ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-13b-chat --inference_model --dtype float16 ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
# a8w8
python3 ./predict/predictor.py --model_name_or_path checkpoints/llama_ptq_ckpts --inference_model --dtype float16 ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
```
**é™æ€å›¾ï¼š**

```
# step1: é™æ€å›¾å¯¼å‡º
# fp16
python3 ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-13b-chat --inference_model --output_path ./inference --dtype float16
# a8w8
python3 ./predict/export_model.py --model_name_or_path checkpoints/llama_ptq_ckpts --inference_model --output_path ./inference --dtype float16

# step2: é™æ€å›¾æ¨ç†
python3 ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype float16 --mode static ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
```

b. æ‰“å¼€BlockAttebtionçš„é«˜æ€§èƒ½æ¨ç†

**åŠ¨æ€å›¾ï¼š**

```
# fp16
python3 ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-13b-chat --inference_model --dtype float16 --block_attn ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
# a8w8
python3 ./predict/predictor.py --model_name_or_path checkpoints/llama_ptq_ckpts --inference_model --dtype float16 --block_attn ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
# cachekv
python3 ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-13b-chat --inference_model --dtype float16 --block_attn ---cachekv_int8 ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
```

**é™æ€å›¾ï¼š**

```
# step1: é™æ€å›¾å¯¼å‡º
# fp16
python3 ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-13b-chat --inference_model --output_path ./inference --dtype float16 --block_attn
# a8w8
python3 ./predict/export_model.py --model_name_or_path checkpoints/llama_ptq_ckpts --inference_model --output_path ./inference --dtype float16 --block_attn
# cachekv
python3 ./predict/export_model.py  --model_name_or_path meta-llama/Llama-2-13b-chat --inference_model --output_path ./inference --dtype float16 --block_attn --cachekv_int8

# step2: é™æ€å›¾æ¨ç†
# fp16
python3 ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype float16 --mode static --block_attn  ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
# a8w8
python3 ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype float16 --mode static --block_attn  ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
# cachekv
python3 ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype float16 --mode static --cachekv_int8 --block_attn  ï¼ˆæµ‹æ€§èƒ½å¯é€‰ï¼š--batch_size 1 --src_length 3072 --max_length 1024 --benchmarkï¼‰
```

## 5.åº”ç”¨åœºæ™¯

(1).ç®—æ³•ç±»åˆ«

`è‡ªç„¶è¯­è¨€å¤„ç†`

(2).çƒ­ç‚¹åº”ç”¨è¡Œä¸š

`åŒ»ç–—,æ•™è‚²,ç§‘ç ”,é‡‘è`

## 6.æºç ä»“åº“åŠé—®é¢˜åé¦ˆ

- [https://developer.hpccube.com/codes/modelzoo/llama_paddle](https://developer.hpccube.com/codes/modelzoo/llama_paddle)

## 7.å‚è€ƒ

* [https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)