# å¤§æ¨¡å‹æ¨ç†æ•™ç¨‹

PaddleNLPä»¥ä¸€ç«™å¼ä½“éªŒã€æè‡´æ€§èƒ½ä¸ºè®¾è®¡ç†å¿µï¼Œå®ç°å¤§æ¨¡å‹çš„å¿«é€Ÿæ¨ç†ï¼š

* æä¾›å¸¸ç”¨æ¨¡å‹æ¨ç†ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€ŸéªŒè¯æ¨¡å‹æ¨ç†æ•ˆæœã€‚
* æä¾›é«˜æ€§èƒ½æ¨ç†ï¼Œå†…ç½®åŠ¨æ€æ’å…¥å’Œå…¨ç¯èŠ‚ç®—å­èåˆç­–ç•¥ï¼Œæå¤§åŠ å¿«å¹¶è¡Œæ¨ç†çš„é€Ÿåº¦ã€‚
* å®ç°BlockAttentionï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½æ¨ç†å’ŒåŠ¨æ€æ’å…¥çš„åŸºç¡€ä¸Šå¯ä»¥åŠ¨æ€åœ°ä¸ºCacheKVåˆ†é…å­˜å‚¨ç©ºé—´ï¼Œæå¤§åœ°èŠ‚çœæ˜¾å­˜ã€‚


## 1. å¸¸ç”¨æ¨ç†

PaddleNLP ä¸ºå¸¸ç”¨æ¨¡å‹æä¾›äº†åŠ¨æ€å›¾æ¨ç†å’Œé™æ€å›¾æ¨ç†ä¸¤ç§æ–¹å¼ï¼ˆåŒ…å«LoRAã€PrefixTuningï¼‰ï¼Œç”¨æˆ·èƒ½å¤Ÿæ ¹æ®è‡ªå·±çš„éœ€æ±‚çµæ´»çš„é€‰æ‹©æœ€é€‚åˆçš„æ¨ç†æ–¹å¼ï¼Œä»è€Œå¿«é€ŸéªŒè¯æ¨¡å‹çš„æ¨ç†æ•ˆæœã€‚å‘½ä»¤å‚æ•°è¯¦æƒ…è¯·å‚è€ƒæ¨¡å‹é¡µé¢ä»‹ç»ã€‚

### 1.1 åŠ¨æ€å›¾æ¨ç† 

åŠ¨æ€å›¾æ¨ç†æ˜¯ä¸€ç§çµæ´»çš„æ¨ç†æ–¹å¼ï¼š

- å³æ—¶æ‰§è¡Œï¼šæ¯ä¸ªæ“ä½œéƒ½ä¼šç«‹å³æ‰§è¡Œï¼Œä¾¿äºè°ƒè¯•å’Œå¯è§†åŒ–ã€‚
- çµæ´»æ€§é«˜ï¼šæ”¯æŒåŠ¨æ€å˜åŒ–çš„ç½‘ç»œç»“æ„ã€‚

### **1.2 é™æ€å›¾æ¨ç†**

é™æ€å›¾æ¨ç†æ˜¯ä¸€ç§é«˜æ•ˆçš„æ¨ç†æ–¹å¼ï¼ˆåœ¨è¿è¡Œé™æ€å›¾ä¹‹å‰éœ€å°†åŠ¨æ€å›¾è½¬ä¸ºé™æ€å›¾ï¼‰ï¼š

- é¢„å…ˆç¼–è¯‘ï¼šæ•´ä¸ªè®¡ç®—å›¾åœ¨æ‰§è¡Œå‰è¢«å®Œæ•´ç¼–è¯‘ï¼Œæœ‰åˆ©äºå…¨å±€ä¼˜åŒ–ï¼Œæ€§èƒ½é€šå¸¸ä¼˜äºåŠ¨æ€å›¾ã€‚
- éƒ¨ç½²ä¾¿åˆ©ï¼šæ›´é€‚åˆäº§å“åŒ–éƒ¨ç½²ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯¹æ€§èƒ½è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ã€‚

## 2. é«˜æ€§èƒ½æ¨ç†

PaddleNLPæä¾›äº†å¸¸ç”¨æ¨¡å‹çš„é«˜æ€§èƒ½æ¨ç†ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€åœ°æ’å…¥æˆ–è°ƒæ•´è®¡ç®—å›¾ä¸­çš„èŠ‚ç‚¹æˆ–æ“ä½œï¼ŒåŒæ—¶åœ¨æ¨ç†è¿‡ç¨‹çš„å„ä¸ªé˜¶æ®µå®ç°äº†ç®—å­èåˆæŠ€æœ¯ï¼Œå‡å°‘å†…å­˜è®¿é—®å’Œè®¡ç®—å¼€é”€ï¼Œä»è€Œå…¨é¢æå‡æ¨ç†æ€§èƒ½ã€‚é«˜æ€§èƒ½æ¨ç†çš„å†…ç½®åŠ¨æ€æ’å…¥å’Œå…¨ç¯èŠ‚ç®—å­èåˆç­–ç•¥ï¼Œéšè—äº†åº•å±‚å®ç°çš„ç»†èŠ‚ï¼Œå®ç°äº†å¼€ç®±å³ç”¨é«˜æ€§èƒ½å¹¶è¡Œæ¨ç†èƒ½åŠ›ã€‚åŒæ—¶ä¸ºäº†è¿›ä¸€æ­¥æå‡æ¨ç†çš„ååï¼Œæˆ‘ä»¬åŸºäºPageAttentionçš„æ€æƒ³è®¾è®¡å¹¶å®ç°äº†BlockAttentionï¼Œå°† KV ç¼“å­˜åˆ’åˆ†ä¸ºå›ºå®šå¤§å°çš„å—ï¼ˆblocksï¼‰ï¼Œä»è€Œå¯ä»¥æ›´çµæ´»çš„åˆ†é…cachekvã€‚åœ¨ä¿æŒé«˜æ€§èƒ½æ¨ç†å’ŒåŠ¨æ€æ’å…¥çš„åŸºç¡€ä¸Šå¯ä»¥åŠ¨æ€åœ°ä¸ºcachekvåˆ†é…å­˜å‚¨ç©ºé—´ï¼Œæå¤§åœ°èŠ‚çœæ˜¾å­˜ï¼Œä»è€Œåœ¨åŒä¸€æ—¶åˆ»å¤„ç†æ›´å¤šçš„queryä»¥è·å¾—ååçš„æå‡ã€‚

<div align="center">
    <img width="800" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/63761690/42174b47-f765-48d6-9fef-907b69bf6706">
</div>
<div align="center">
    <font size ="1">
    é£æ¡¨é«˜æ€§èƒ½æ¨ç†ç®—å­èåˆç¤ºæ„å›¾
     </font>
</div>

<div align="center">
    <img width="800" alt="llm" src="https://github.com/PaddlePaddle/PaddleNLP/assets/63761690/616b3fc5-b9b2-4b10-a5c8-2f892a65ae6b">
</div>
<div align="center">
    <font size ="1">
    åŠ¨æ€æ’å…¥å›¾è§£ & é£æ¡¨é«˜æ€§èƒ½æ¨¡å‹æ¨ç†æ€§èƒ½å›¾
     </font>
</div>

### 2.1 æ¨¡å‹æ”¯æŒ

PaddleNLP ä¸­å·²ç»æ·»åŠ é«˜æ€§èƒ½æ¨ç†æ¨¡å‹ç›¸å…³å®ç°ï¼Œæ”¯æŒï¼š

| Model                            | FP16/BF16 | WINT8 | INT8-A8W8C16 | FP8-A8W8C16 | INT8-A8W8C8 | FP8-A8W8C8 |
|----------------------------------|-----------|-------|--------------|-------------|-------------|------------|
| [LLaMA1/2/3/3.1](../config/llama)| âœ…        | âœ…    | âœ…        | âœ…       | âœ…    | âŒ        |
| [Qwen1.5/2](../config/qwen)      | âœ…        | âœ…    | âœ…        | âœ…       | âœ…    | âŒ        |
| [Qwen-Moe]()       | âœ…        | ğŸš§    | âŒ        | âŒ       | âŒ    | âŒ        |
| [Mixtral]()        | âœ…        | ğŸš§    | âŒ        | âŒ       | âŒ    | âŒ        |
| [ChatGLM](../config/chatglm)     | âœ…        | âœ…    | âŒ        | âŒ       | âŒ    | âŒ        |
| [ChatGLM2](../config/chatglm2)   | âœ…        | âŒ    | âŒ        | âŒ       | âŒ    | âŒ        |
| [Bloom](../config/bloom)         | âœ…        | âœ…    | âŒ        | âŒ       | âŒ    | âŒ        |
| [GPT-3](../config/gpt-3)         | âœ…        | âŒ    | âŒ        | âŒ       | âŒ    | âŒ        |
| [BaiChuan-7B](../config/baichuan)   | âœ…     | âœ…     | ğŸš§       | âŒ       | âŒ    | âŒ        |
| [BaiChuan2-7B](../config/baichuan)  | âœ…     | âœ…     | ğŸš§       | âŒ       | âŒ    | âŒ        |
| [BaiChuan2-13B](../config/baichuan) | ğŸš§              | ğŸš§    | ğŸš§     | âŒ       | âŒ    | âŒ        |

* âœ…: Supported

* ğŸš§: In Progress

* âŒ: Not Supported

* WINT8:æŒ‡Weight-Only Quantization INT8ï¼Œå³å¯¹æƒé‡è¿›è¡ŒINT8é‡åŒ–çš„æ¨¡å‹ã€‚

* INT8-A8W8C16:æŒ‡ä½¿ç”¨PTQå¯¹çº¿æ€§å±‚çš„æ¿€æ´»å’Œæƒé‡éƒ½é‡åŒ–ä¸ºINT8çš„æ¨¡å‹ã€‚
* FP8-A8W8C16:æŒ‡ä½¿ç”¨PTQå¯¹çº¿æ€§å±‚çš„æ¿€æ´»å’Œæƒé‡éƒ½é‡åŒ–ä¸ºFP8çš„æ¨¡å‹ã€‚
* INT8-A8W8C8:æŒ‡ä½¿ç”¨PTQå¯¹Cache KVã€çº¿æ€§å±‚çš„æ¿€æ´»å’Œæƒé‡éƒ½é‡åŒ–ä¸ºINT8çš„æ¨¡å‹ã€‚
* FP8-A8W8C8:æŒ‡ä½¿ç”¨PTQå¯¹Cache KVã€çº¿æ€§å±‚çš„æ¿€æ´»å’Œæƒé‡éƒ½é‡åŒ–ä¸ºFP8çš„æ¨¡å‹ã€‚

### 2.2 ç¡¬ä»¶&ç²¾åº¦æ”¯æŒ

PaddleNLP æä¾›äº†å¤šç§ç¡¬ä»¶å¹³å°å’Œç²¾åº¦æ”¯æŒï¼ŒåŒ…æ‹¬ï¼š

| Precision      | Ada | Ampere | Turing | Volta | x86 CPU | XPU |
|----------------|-----|--------|--------|-------|---------|-----|
| FP32      | âœ… | âœ… | âœ… | âœ…  | âœ…  | âœ…  |
| FP16      | âœ… | âœ… | âœ… |  âœ… | âœ…  |  âœ… |
| BF16      | âœ… | âœ… | âœ… |  âŒ |  âŒ |  âŒ |
| INT8      | âœ… | âœ… | âœ… | âœ…  | âœ… |   âœ…|
| INT4      | âŒ | âŒ | âŒ | âŒ  | âŒ  | âŒ  |
| FP8       | âœ… | âŒ | âŒ | âŒ  | âŒ  |  âŒ |


### 2.4 æ€§èƒ½ä¼˜åŒ–é€‰é¡¹

#### Inference Model
`--inference_model` : å¼€å¯é«˜æ€§èƒ½æ¨ç†æ¨¡å¼

#### Block Attention
`--block_attn` : ä¸ºäº†è¿›ä¸€æ­¥æå‡æ¨ç†çš„ååï¼Œæˆ‘ä»¬åŸºäºPageAttentionçš„æ€æƒ³è®¾è®¡å¹¶å®ç°äº†BlockAttentionï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½æ¨ç†å’ŒåŠ¨æ€æ’å…¥çš„åŸºç¡€ä¸Šå¯ä»¥åŠ¨æ€åœ°ä¸ºcachekvåˆ†é…å­˜å‚¨ç©ºé—´ï¼Œæå¤§åœ°èŠ‚çœæ˜¾å­˜ï¼Œä»è€Œåœ¨åŒä¸€æ—¶åˆ»å¤„ç†æ›´å¤šçš„queryä»¥è·å¾—ååçš„æå‡ã€‚

#### Weight Only
`--quant_type weight_only_int8` : å³å¯¹æƒé‡è¿›è¡ŒINT8é‡åŒ–çš„æ¨¡å‹ã€‚


#### PTQ
`--quant_type a8w8` :


#### Cache KV Quantization
`--quant_type a8w8c8` : 

`--cachekv_int8_type` : cachekvé‡åŒ–ç±»å‹ï¼Œæ”¯æŒdynamicå’Œstaticä¸¤ç§æ¨¡å¼ã€‚


### 2.5 æ€§èƒ½åˆ†æé€‰é¡¹

#### benchmark

`--benchmark` : å¼€å¯æ€§èƒ½åˆ†ææ¨¡å¼

#### src_length & max_length

`--src_length`: æ¨¡å‹è¾“å…¥ä¸Šä¸‹æ–‡æœ€å¤§tokené•¿åº¦ï¼Œé»˜è®¤ä¸º1024ã€‚

`--max_length`:æ¨¡å‹è¾“å…¥ï¼ˆä¸Šä¸‹æ–‡+ç”Ÿæˆå†…å®¹ï¼‰çš„æœ€å¤§tokené•¿åº¦, é»˜è®¤ä¸º2048ã€‚

#### batch_size

`--batch_size` : æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤ä¸º8ã€‚è¯¥å‚æ•°è¶Šå¤§ï¼Œå ç”¨æ˜¾å­˜è¶Šé«˜ï¼›è¯¥å‚æ•°è¶Šå°ï¼Œå ç”¨æ˜¾å­˜è¶Šä½ã€‚





## 3. ç¯å¢ƒå‡†å¤‡
- [PaddlePaddle develop](https://github.com/PaddlePaddle/Paddle)
- PaddleNLP develop

git clone ä»£ç åˆ°æœ¬åœ°ï¼Œå³å¯å¼€å§‹ã€‚

```bash
git clone https://github.com/PaddlePaddle/PaddleNLP.git
# pip install ./PaddleNLP ä½¿ç”¨developç‰ˆæœ¬
cd PaddleNLP/llm
# åˆ°è¾¾è¿è¡Œç›®å½•
```

PaddleNLP é’ˆå¯¹äºTransformer ç³»åˆ—ç¼–å†™äº†é«˜æ€§èƒ½è‡ªå®šä¹‰ç®—å­ï¼Œæå‡æ¨¡å‹åœ¨æ¨ç†å’Œè§£ç è¿‡ç¨‹ä¸­çš„æ€§èƒ½ï¼Œå¦‚éœ€ä½¿ç”¨é«˜æ€§èƒ½æ¨ç†æ¨¡å¼éœ€è¦é¢„å…ˆå®‰è£…è‡ªå®šä¹‰ç®—å­åº“ï¼š

```shell
git clone https://github.com/PaddlePaddle/PaddleNLP
#GPUè®¾å¤‡å®‰è£…è‡ªå®šä¹‰ç®—å­
cd ./paddlenlp/csrc && python setup_cuda.py install
#XPUè®¾å¤‡å®‰è£…è‡ªå®šä¹‰ç®—å­
cd ./paddlenlp/csrc/xpu/src && sh cmake_build.sh
```

## 4. å¿«é€Ÿå¼€å§‹
å®‰è£…PaddleNLP

```bash
cd PaddleNLP
python setup.py install
```

åˆ°è¾¾è¿è¡Œç›®å½•
```bash
cd PaddleNLP/llm
```


### 4.1. å¸¸ç”¨æ¨ç†
#### 4.1.1 åŠ¨æ€å›¾æ¨ç†
```shell
# åŠ¨æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-7b-chat --data_file ./data/dev.json --dtype float16
```
å¯¹äºLoRAã€PrefixTuning æ¨¡å‹åªéœ€é¢å¤–ä¼ å…¥ç›¸åº”çš„lora_pathæˆ–prefix_pathå³å¯ï¼Œå¦‚ï¼š--lora_path ./checkpoints/llama_lora_ckptsæˆ–--prefix_path ./checkpoints/llama_prefix_ckptsï¼Œè¯¦è§æ¨ç†å‚æ•°ä»‹ç»ã€‚


#### 4.1.2 é™æ€å›¾æ¨ç†
```shell
# é™æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒï¼Œ LoRAéœ€è¦å…ˆåˆå¹¶å‚æ•°ï¼ŒPrefix Tuningæš‚ä¸æ”¯æŒ
# step1 : é™æ€å›¾å¯¼å‡º
python ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-7b-chat --output_path ./inference --dtype float16
# step2: é™æ€å›¾æ¨ç†
python ./predict/predictor.py --model_name_or_path ./inference --data_file ./data/dev.json --dtype float16 --mode static
```

### 4.2 é«˜æ€§èƒ½æ¨ç†
#### 4.2.1 åŠ¨æ€å›¾æ¨ç†

```shell
# åŠ¨æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --dtype float16 --block_attn

# XPUè®¾å¤‡åŠ¨æ€å›¾æ¨¡å‹æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --dtype float16 --block_attn --device xpu

# Weight Only Int8 åŠ¨æ€å›¾æ¨ç†å‚è€ƒ
python ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --dtype float16 --quant_type weight_only_int8 --block_attn

# PTQ-A8W8æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py --model_name_or_path checkpoints/llama_ptq_ckpts --inference_model --dtype float16 --block_attn

# CacheKV åŠ¨æ€é‡åŒ–æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --dtype float16 --block_attn --cachekv_int8_type dynamic
```

#### 4.2.2 é™æ€å›¾æ¨ç†
**step1ï¼šåŠ¨è½¬é™**
```shell
# åŠ¨è½¬é™å‘½ä»¤å‚è€ƒ
python ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --output_path ./inference --dtype float16 --block_attn

# XPUè®¾å¤‡åŠ¨è½¬é™å‘½ä»¤å‚è€ƒ
python ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --output_path ./inference --dtype float16 --block_attn --device xpu

# Weight Only Int8 åŠ¨è½¬é™å‘½ä»¤å‚è€ƒ
python ./predict/export_model.py --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --output_path ./inference --dtype float16 --quant_type weight_only_int8 --block_attn

# PTQ-A8W8åŠ¨è½¬é™å‘½ä»¤å‚è€ƒ
python ./predict/export_model.py --model_name_or_path checkpoints/llama_ptq_ckpts --inference_model --output_path ./inference --dtype float16 --block_attn

# CacheKV åŠ¨æ€é‡åŒ–åŠ¨è½¬é™å‘½ä»¤å‚è€ƒ
python ./predict/export_model.py  --model_name_or_path meta-llama/Llama-2-7b-chat --inference_model --output_path ./inference --dtype float16 --block_attn --cachekv_int8_type dynamic
```

**step2ï¼šé™æ€å›¾æ¨ç†**
```shell
# é™æ€å›¾æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype "float16" --mode "static" --block_attn

# XPUè®¾å¤‡é™æ€å›¾æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype "float16" --mode "static" --block_attn --device xpu

# Weight Only Int8 é™æ€å›¾æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype "float16" --mode "static" --quant_type weight_only_int8 --block_attn

# PTQ-A8W8é™æ€å›¾æ¨ç†å‘½ä»¤å‚è€ƒ
# ä»¥ä¸‹ç¯å¢ƒå˜é‡ç”¨äºå¼€å¯int8çŸ©é˜µä¹˜çš„ç®—æ³•é€‰æ‹©ä»¥è·å¾—æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œæ‰“å¼€ä¹‹åç¬¬ä¸€æ¬¡æ‰§è¡Œä¼šæ‰§è¡Œç®—æ³•é€‰æ‹©ä»è€Œå¯¼è‡´é€Ÿåº¦è¾ƒæ…¢ã€‚
export FLAGS_use_autotune=1
export FLAGS_cublaslt_exhaustive_search_times=10
export FLAGS_cache_inference_while_scope=1

python ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype "float16" --mode "static" --block_attn

# CacheKV åŠ¨æ€é‡åŒ–int8é™æ€å›¾æ¨ç†å‘½ä»¤å‚è€ƒ
python ./predict/predictor.py  --model_name_or_path ./inference --inference_model --dtype "float16" --mode "static" --cachekv_int8_type dynamic --block_attn
```
**Note**ï¼š
1. `quant_type`å¯é€‰çš„æ•°å€¼æœ‰`weight_only_int8`ï¼Œ`weight_only_int4`ï¼Œ`a8w8`, `a8w8c8`ã€‚
2. `a8w8`æ¨ç†ä¼ å…¥çš„ `model_name_or_path` ä¸ºPTQæ ¡å‡†äº§å‡ºçš„é‡åŒ–æ¨¡å‹ï¼Œéœ€è¦é¢å¤–çš„actå’Œweightçš„scaleæ ¡å‡†è¡¨ã€‚
3. `cachekv_int8_type`å¯é€‰`dynamic`å’Œ`static`ä¸¤ç§ï¼Œ`static`éœ€è¦é¢å¤–çš„cache kvçš„scaleæ ¡å‡†è¡¨ã€‚



æ›´å¤šæ¨¡å‹æ¨ç†æ•™ç¨‹ï¼Œå‚è€ƒ[examples](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples)

## 5. æ¨ç†å‚æ•°ä»‹ç»

- `model_name_or_path`: å¿…é¡»ï¼Œé¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è€…æœ¬åœ°çš„æ¨¡å‹è·¯å¾„ï¼Œç”¨äºçƒ­å¯æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `batch_size`: æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤ä¸º8ã€‚è¯¥å‚æ•°è¶Šå¤§ï¼Œå ç”¨æ˜¾å­˜è¶Šé«˜ï¼›è¯¥å‚æ•°è¶Šå°ï¼Œå ç”¨æ˜¾å­˜è¶Šä½ã€‚
- `src_length`: æ¨¡å‹è¾“å…¥ä¸Šä¸‹æ–‡æœ€å¤§tokené•¿åº¦ï¼Œé»˜è®¤ä¸º1024ã€‚
- `max_length`:æ¨¡å‹è¾“å…¥ï¼ˆä¸Šä¸‹æ–‡+ç”Ÿæˆå†…å®¹ï¼‰çš„æœ€å¤§tokené•¿åº¦, é»˜è®¤ä¸º2048ã€‚
- `lora_path`: LoRAå‚æ•°å’Œé…ç½®è·¯å¾„ï¼Œå¯¹LoRAå‚æ•°è¿›è¡Œåˆå§‹åŒ–ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `prefix_path`: Prefix Tuningå‚æ•°å’Œé…ç½®è·¯å¾„ï¼Œå¯¹Prefix Tuningå‚æ•°è¿›è¡Œåˆå§‹åŒ–ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `top_k`: â€œé‡‡æ ·â€ç­–ç•¥ä¸­ä¸º top-k è¿‡æ»¤ä¿ç•™çš„æœ€é«˜æ¦‚ç‡æ ‡è®°çš„æ•°é‡ã€‚é»˜è®¤ä¸º1ï¼Œç­‰ä»·äºè´ªå¿ƒç­–ç•¥ã€‚
- `top_p`:â€œé‡‡æ ·â€ç­–ç•¥ä¸­ top-p è¿‡æ»¤çš„ç´¯ç§¯æ¦‚ç‡ã€‚é»˜è®¤ä¸º1.0ï¼Œè¡¨ç¤ºä¸èµ·ä½œç”¨ã€‚
- `temperature`:â€œé‡‡æ ·â€ç­–ç•¥ä¸­ä¼šå¯¹è¾“å‡ºlogité™¤ä»¥temperatureã€‚é»˜è®¤ä¸º1.0ï¼Œè¡¨ç¤ºä¸èµ·ä½œç”¨ã€‚
- `data_file`:å¿…é¡»ï¼Œå¾…æ¨ç†jsonæ–‡ä»¶ï¼Œé»˜è®¤ä¸ºNoneã€‚
- `output_file`:ä¿å­˜æ¨ç†ç»“æœæ–‡ä»¶åï¼Œé»˜è®¤ä¸ºoutput.jsonã€‚
- `device`: è¿è¡Œç¯å¢ƒï¼Œé»˜è®¤ä¸ºgpuã€‚
- `dtype`: æ¨¡å‹å‚æ•°dtypeï¼Œé»˜è®¤ä¸ºNoneã€‚å¦‚æœæ²¡æœ‰ä¼ å…¥`lora_path`ã€`prefix_path`åˆ™å¿…é¡»ä¼ å…¥
- `model_type`: åˆå§‹åŒ–ä¸åŒç±»å‹æ¨¡å‹ï¼Œgpt-3: GPTForCausalLM; ernie-3.5-se: Ernie35ForCausalLM; é»˜è®¤ä¸º Noneã€‚
- `mode`: ä½¿ç”¨åŠ¨æ€å›¾æˆ–è€…é™æ€å›¾æ¨ç†ï¼Œå€¼ä¸ºï¼š[dynamic, static]ï¼Œé»˜è®¤ä¸º dynamicã€‚
- `inference_model`: æ˜¯å¦ä½¿ç”¨Inference Model æ¨ç†ï¼Œé»˜è®¤å€¼ä¸º Falseã€‚
- `block_attn`: æ˜¯å¦ä½¿ç”¨Block Attention æ¨ç†ï¼Œ é»˜è®¤å€¼ä¸ºFalseã€‚
- `block_size`: å¦‚æœä½¿ç”¨Block Attention æ¨ç†ï¼ŒæŒ‡å®šä¸€ä¸ªBlockå¯ä»¥å­˜å‚¨çš„tokenæ•°é‡ï¼Œé»˜è®¤å€¼ä¸º64ã€‚
- `cachekv_int8_type`: æ˜¯å¦ä½¿ç”¨cachekv int8é‡åŒ–ç”¨äºèŠ‚çœæ˜¾å­˜ï¼Œå¯ä»¥æ˜¯åŠ¨æ€æˆ–è€…é™æ€ï¼Œé»˜è®¤å€¼ä¸ºNoneã€‚
