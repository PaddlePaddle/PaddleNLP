{
  "model_name_or_path": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "quant_type": "a8w8",
  "use_fp8": "WA",
  "per_device_train_batch_size": 8,
  "per_device_eval_batch_size": 8,
  "eval_accumulation_steps":16,
  "src_length": 1024,
  "max_length": 2048,
  "fp16": true,
  "fp16_opt_level": "O2",
  "dataset_name_or_path": "../dataset/ceval_ptq",
  "output_dir": "../output/llama3.1/wfp8afp8_ptq_ckpts_ceval",
  "do_eval": true,
  "eval_with_do_generation": false,
  "do_ptq": true,
  "ptq_step": 16,
  "unified_checkpoint": false,
  "smooth": false,
  "weight_quant_method": "abs_max",
  "act_quant_method": "abs_max",
  "cachekv_quant_method": "abs_max"
  }