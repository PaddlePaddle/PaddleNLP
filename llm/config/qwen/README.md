# Qwen

## 1.模型介绍

[通义千问（Qwen）](https://arxiv.org/abs/2205.01068) 是阿里云研发的通义千问大模型系列的模型, 有 70 亿和 140 亿两个规模。Qwen 是基于 Transformer 的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。

**支持模型权重:**
| Model              |
|--------------------|
| qwen/qwen-7b       |
| qwen/qwen-7b-chat  |
| qwen/qwen-14b      |
| qwen/qwen-14b-chat |
| qwen/qwen-72b      |
| qwen/qwen-72b-chat |

[通义千问（Qwen1.5）](https://qwenlm.github.io/blog/qwen1.5/) 是阿里云研发的通义千问系列模型升级版。Qwen1.5包括0.5B、1.8B、4B、7B、14B、32B、72B、110B 和 MoE 共计9个不同规模的 Base 和 Chat 模型。

**支持模型权重:**
| Model (qwen-1.5)            |
|-----------------------------|
| Qwen/Qwen1.5-0.5B           |
| Qwen/Qwen1.5-0.5B-Chat      |
| Qwen/Qwen1.5-1.8B           |
| Qwen/Qwen1.5-1.8B-Chat      |
| Qwen/Qwen1.5-4B             |
| Qwen/Qwen1.5-4B-Chat        |
| Qwen/Qwen1.5-7B             |
| Qwen/Qwen1.5-7B-Chat        |
| Qwen/Qwen1.5-14B            |
| Qwen/Qwen1.5-14B-Chat       |
| Qwen/Qwen1.5-32B            |
| Qwen/Qwen1.5-32B-Chat       |
| Qwen/Qwen1.5-72B            |
| Qwen/Qwen1.5-72B-Chat       |
| Qwen/Qwen1.5-110B           |
| Qwen/Qwen1.5-110B-Chat      |
| Qwen/Qwen1.5-MoE-A2.7B      |
| Qwen/Qwen1.5-MoE-A2.7B-Chat |

[通义千问（Qwen2）](https://qwenlm.github.io/blog/qwen2/) 是阿里云研发的通义千问系列模型升级版。Qwen2包括0.5B、1.5B、7B、72B 和 MoE 共计5个不同规模的 Base 和 Chat 模型。
**支持模型权重:**
| Model (qwen2)                |
|------------------------------|
| Qwen/Qwen2-0.5B              |
| Qwen/Qwen2-0.5B-Instruct     |
| Qwen/Qwen2-1.5B              |
| Qwen/Qwen2-1.5B-Instruct     |
| Qwen/Qwen2-7B                |
| Qwen/Qwen2-7B-Instruct       |
| Qwen/Qwen2-72B               |
| Qwen/Qwen2-72B-Instruct      |
| Qwen/Qwen2-57B-A14B          |
| Qwen/Qwen2-57B-A14B-Instruct |
