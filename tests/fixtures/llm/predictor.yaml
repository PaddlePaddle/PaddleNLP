inference-predict:
  slow:
    model_name_or_path: __internal_testing__/tiny-random-llama
    mode: dynamic 
    inference_model: 1
    top_p: 0.0 
    temperature: 1.0
    max_length: 20
    batch_size: 1
    dtype: float16

inference-to-static:
  slow:
    model_name_or_path: __internal_testing__/tiny-random-llama
    inference_model: 1
    dtype: float16

inference-infer:
  slow:
    model_name_or_path: __internal_testing__/tiny-random-llama
    mode: static
    inference_model: 1
    dtype: float16
