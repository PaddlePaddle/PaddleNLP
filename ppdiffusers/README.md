<div align="center">
  <img src="https://user-images.githubusercontent.com/11793384/215372703-4385f66a-abe4-44c7-9626-96b7b65270c8.png" width="40%" height="40%" />
</div>

<p align="center">
    <a href="https://pypi.org/project/paddlenlp/"><img src="https://img.shields.io/pypi/pyversions/paddlenlp"></a>
    <a href=""><img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-yellow.svg"></a>
    <a href="https://github.com/PaddlePaddle/PaddleNLP/blob/develop/LICENSE"><img src="https://img.shields.io/github/license/paddlepaddle/paddlenlp"></a>
</p>

<h4 align="center">
  <a href=#ç‰¹æ€§> ç‰¹æ€§ </a> |
  <a href=#å®‰è£…> å®‰è£… </a> |
  <a href=#å¿«é€Ÿå¼€å§‹> å¿«é€Ÿå¼€å§‹ </a> |
  <a href=#æ¨¡å‹éƒ¨ç½²> æ¨¡å‹éƒ¨ç½²</a>
</h4>

# PPDiffusers: Diffusers toolbox implemented based on PaddlePaddle

**PPDiffusers**æ˜¯ä¸€æ¬¾æ”¯æŒå¤šç§æ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬å›¾åƒè·¨æ¨¡æ€ã€å›¾åƒã€è¯­éŸ³ï¼‰æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelï¼‰è®­ç»ƒå’Œæ¨ç†çš„å›½äº§åŒ–å·¥å…·ç®±ï¼Œä¾æ‰˜äº[**PaddlePaddle**](https://www.paddlepaddle.org.cn/)æ¡†æ¶å’Œ[**PaddleNLP**](https://github.com/PaddlePaddle/PaddleNLP)è‡ªç„¶è¯­è¨€å¤„ç†å¼€å‘åº“ã€‚

## News ğŸ“¢

* ğŸ”¥ **2023.03.29 å‘å¸ƒ 0.14.0 ç‰ˆæœ¬ï¼Œæ–°å¢[LoRA](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/dreambooth)ã€[ControlNet](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/controlnet)ï¼Œæ”¯æŒè®­ç»ƒä¸æ¨ç†ï¼›
æ¨¡å‹åŠ è½½å‡çº§ï¼Œ[å¯ç›´æ¥åŠ è½½HF Diffusersçš„æƒé‡](#åŠ è½½HF-Diffusersæƒé‡)ï¼ˆsafetensorså’Œptï¼‰æˆ– [SDç­‰åŸåº“çš„Lightningæƒé‡è¿›è¡Œæ¨ç†](#åŠ è½½åŸåº“çš„Lightningæƒé‡)ï¼Œ[æ”¯æŒåŠ è½½Civitaiç¤¾åŒºçš„LoRAæƒé‡](#åŠ è½½Civitaiç¤¾åŒºçš„LoRAæƒé‡)ï¼›
[æ”¯æŒxformers](#XFormersåŠ é€Ÿ) è®­ç»ƒä¸æ¨ç†ï¼›
æ–°å¢ç”¨äºè¶…é«˜åˆ†è¾¨ç‡ç”Ÿæˆçš„VAE tilingï¼›
æ–°å¢Instruct Pix2Pixã€Semantic guidanceã€Depth2imageç­‰æ¨¡å‹ã€‚**


* ğŸ”¥ **2023.01.18 å‘å¸ƒ 0.11.0 ç‰ˆæœ¬ï¼Œæ–°å¢Heunå’ŒSingle step DPM-Solverå™ªå£°è°ƒåº¦å™¨ï¼Œæ”¯æŒKarlo UnCLIPã€Paint-by-exampleã€Depth-Guided Stable Diffusionç­‰å›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œ æ”¯æŒAudio DiffusionéŸ³é¢‘ç”Ÿæˆæ‰©æ•£æ¨¡å‹ã€‚**


## ç‰¹æ€§
#### ğŸ“¦ SOTAæ‰©æ•£æ¨¡å‹Pipelinesé›†åˆ
æˆ‘ä»¬æä¾›**SOTAï¼ˆState-of-the-Artï¼‰** çš„æ‰©æ•£æ¨¡å‹Pipelinesé›†åˆã€‚
ç›®å‰**PPDiffusers**å·²ç»é›†æˆäº†**50+Pipelines**ï¼Œæ”¯æŒæ–‡å›¾ç”Ÿæˆï¼ˆText-to-Image Generationï¼‰ã€æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç¼–è¾‘ï¼ˆText-Guided Image Inpaintingï¼‰ã€æ–‡æœ¬å¼•å¯¼çš„å›¾åƒå˜æ¢ï¼ˆImage-to-Image Text-Guided Generationï¼‰ã€è¶…åˆ†ï¼ˆSuper Superresolutionï¼‰åœ¨å†…çš„10+ä»»åŠ¡ï¼Œè¦†ç›–æ–‡æœ¬å›¾åƒè·¨æ¨¡æ€ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€ã€‚
å¦‚æœæƒ³è¦äº†è§£å½“å‰æ”¯æŒçš„æ‰€æœ‰**Pipelines**ä»¥åŠå¯¹åº”çš„æ¥æºä¿¡æ¯ï¼Œå¯ä»¥é˜…è¯»[ğŸ”¥ PPDiffusers Pipelines](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/pipelines/README.md)æ–‡æ¡£ã€‚


#### ğŸ”Š æä¾›ä¸°å¯Œçš„Noise Scheduler
æˆ‘ä»¬æä¾›äº†ä¸°å¯Œçš„**å™ªå£°è°ƒåº¦å™¨ï¼ˆNoise Schedulerï¼‰**ï¼Œå¯ä»¥å¯¹**é€Ÿåº¦**ä¸**è´¨é‡**è¿›è¡Œæƒè¡¡ï¼Œç”¨æˆ·å¯åœ¨æ¨ç†æ—¶æ ¹æ®éœ€æ±‚å¿«é€Ÿåˆ‡æ¢ä½¿ç”¨ã€‚
å½“å‰**PPDiffusers**å·²ç»é›†æˆäº†**14+Scheduler**ï¼Œä¸ä»…æ”¯æŒ [DDPM](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_ddpm.py)ã€[DDIM](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_ddim.py) å’Œ [PNDM](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_pndm.py)ï¼Œè¿˜æ”¯æŒæœ€æ–°çš„ [ğŸ”¥ DPMSolver](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_dpmsolver_multistep.py)ï¼

#### ğŸ›ï¸ æä¾›å¤šç§æ‰©æ•£æ¨¡å‹ç»„ä»¶
æˆ‘ä»¬æä¾›äº†**å¤šç§æ‰©æ•£æ¨¡å‹**ç»„ä»¶ï¼Œå¦‚[UNet1DModel](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/unet_1d.py)ã€[UNet2DModel](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/unet_2d.py)ã€[UNet2DConditionModel](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/unet_2d_condition.py)ã€[VQModel](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/vae.py)ã€[AutoencoderKL](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/vae.py)ç­‰ã€‚

#### ğŸ“– æä¾›ä¸°å¯Œçš„è®­ç»ƒå’Œæ¨ç†æ•™ç¨‹
æˆ‘ä»¬æä¾›äº†ä¸°å¯Œçš„è®­ç»ƒæ•™ç¨‹ï¼Œä¸ä»…æ”¯æŒæ‰©æ•£æ¨¡å‹çš„äºŒæ¬¡å¼€å‘å¾®è°ƒï¼Œå¦‚åŸºäº[Textual Inversion](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/textual_inversion)å’Œ[DreamBooth](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/dreambooth)ä½¿ç”¨3-5å¼ å›¾å®šåˆ¶åŒ–è®­ç»ƒç”Ÿæˆå›¾åƒçš„é£æ ¼æˆ–ç‰©ä½“ï¼Œè¿˜æ”¯æŒä½¿ç”¨[Laion400M](https://laion.ai/blog/laion-400-open-dataset)æ•°æ®é›†[ğŸ”¥ ä»é›¶è®­ç»ƒLatent Diffusion Model](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/text_to_image_laion400m) æ¨¡å‹ï¼
æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸°å¯Œçš„[ğŸ”¥ Pipelinesæ¨ç†è„šæœ¬](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/inference)ã€‚

#### ğŸš€ æ”¯æŒFastDeployé«˜æ€§èƒ½éƒ¨ç½²
æˆ‘ä»¬æä¾›åŸºäº[FastDeploy](https://github.com/PaddlePaddle/FastDeploy)çš„[ğŸ”¥ é«˜æ€§èƒ½Stable Diffusion Pipeline](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/pipelines/stable_diffusion/pipeline_fastdeploy_stable_diffusion.py)ï¼Œæ›´å¤šæœ‰å…³FastDeployè¿›è¡Œå¤šæ¨ç†å¼•æ“åç«¯é«˜æ€§èƒ½éƒ¨ç½²çš„ä¿¡æ¯è¯·å‚è€ƒ[ğŸ”¥ é«˜æ€§èƒ½FastDeployæ¨ç†æ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/deploy)ã€‚
```python
from ppdiffusers import StableDiffusionPipeline, FastDeployStableDiffusionPipeline

orig_pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
fd_pipe = FastDeployStableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5@fastdeploy")
```

## å®‰è£…

### ç¯å¢ƒä¾èµ–
```
pip install -r requirements.txt
```
å…³äºPaddlePaddleå®‰è£…çš„è¯¦ç»†æ•™ç¨‹è¯·æŸ¥çœ‹[Installation](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/develop/install/pip/linux-pip.html)ã€‚

### pipå®‰è£…

```shell
pip install --upgrade ppdiffusers -f https://www.paddlepaddle.org.cn/whl/paddlenlp.html
```

### æ‰‹åŠ¨å®‰è£…
```shell
git clone https://github.com/PaddlePaddle/PaddleNLP
# æ³¨æ„ï¼šå¦‚æœcloneä»“åº“éå¸¸æ…¢çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨é•œåƒç‰ˆæœ¬
# git clone https://gitee.com/paddlepaddle/PaddleNLP
cd PaddleNLP/ppdiffusers
python setup.py install
```

## å¿«é€Ÿå¼€å§‹
æˆ‘ä»¬å°†ä»¥æ‰©æ•£æ¨¡å‹çš„å…¸å‹ä»£è¡¨**Stable Diffusion**ä¸ºä¾‹ï¼Œå¸¦ä½ å¿«é€Ÿäº†è§£PPDiffusersã€‚

**Stable Diffusion**åŸºäº**æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Modelsï¼‰**ï¼Œä¸“é—¨ç”¨äº**æ–‡å›¾ç”Ÿæˆï¼ˆText-to-Image Generationï¼‰ä»»åŠ¡**ã€‚è¯¥æ¨¡å‹æ˜¯ç”±æ¥è‡ª [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/), [LAION](https://laion.ai/)ä»¥åŠ[RunwayML](https://runwayml.com/)çš„å·¥ç¨‹å¸ˆå…±åŒå¼€å‘å®Œæˆï¼Œç›®å‰å‘å¸ƒäº†v1å’Œv2ä¸¤ä¸ªç‰ˆæœ¬ã€‚v1ç‰ˆæœ¬é‡‡ç”¨äº†LAION-5Bæ•°æ®é›†å­é›†ï¼ˆåˆ†è¾¨ç‡ä¸º 512x512ï¼‰è¿›è¡Œè®­ç»ƒï¼Œå¹¶å…·æœ‰ä»¥ä¸‹æ¶æ„è®¾ç½®ï¼šè‡ªåŠ¨ç¼–ç å™¨ä¸‹é‡‡æ ·å› å­ä¸º8ï¼ŒUNetå¤§å°ä¸º860Mï¼Œæ–‡æœ¬ç¼–ç å™¨ä¸ºCLIP ViT-L/14ã€‚v2ç‰ˆæœ¬ç›¸è¾ƒäºv1ç‰ˆæœ¬åœ¨ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œåˆ†è¾¨ç‡ç­‰è¿›è¡Œäº†æ”¹å–„ã€‚

### Stable Diffusioné‡ç‚¹æ¨¡å‹æƒé‡

<details><summary>&emsp; Stable Diffusion æ¨¡å‹æ”¯æŒçš„æƒé‡ï¼ˆè‹±æ–‡ï¼‰ </summary>

**æˆ‘ä»¬åªéœ€è¦å°†ä¸‹é¢çš„"xxxx"ï¼Œæ›¿æ¢æˆæ‰€éœ€çš„æƒé‡åï¼Œå³å¯å¿«é€Ÿä½¿ç”¨ï¼**
```python
from ppdiffusers import *

pipe_text2img = StableDiffusionPipeline.from_pretrained("xxxx")
pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained("xxxx")
pipe_inpaint_legacy = StableDiffusionInpaintPipelineLegacy.from_pretrained("xxxx")
pipe_mega = StableDiffusionMegaPipeline.from_pretrained("xxxx")

# pipe_mega.text2img() ç­‰äº pipe_text2img()
# pipe_mega.img2img() ç­‰äº pipe_img2img()
# pipe_mega.inpaint_legacy() ç­‰äº pipe_inpaint_legacy()
```

| PPDiffusersæ”¯æŒçš„æ¨¡å‹åç§°                     | æ”¯æŒåŠ è½½çš„Pipeline                                    | å¤‡æ³¨ | huggingface.coåœ°å€ |
| :-------------------------------------------: | :--------------------------------------------------------------------: | --- | :-----------------------------------------: |
| CompVis/stable-diffusion-v1-4           | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | Stable-Diffusion-v1-4 ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚éšååœ¨"laion-aesthetics v2 5+"æ•°æ®é›†ä¸Šä»¥ **512x512** åˆ†è¾¨ç‡å¾®è°ƒäº† **225k** æ­¥æ•°ï¼Œå¯¹æ–‡æœ¬ä½¿ç”¨äº† **10%** çš„dropoutï¼ˆå³ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ–‡å›¾å¯¹ä¸­çš„æ–‡æœ¬æœ‰ 10% çš„æ¦‚ç‡ä¼šå˜æˆç©ºæ–‡æœ¬ï¼‰ã€‚æ¨¡å‹ä½¿ç”¨äº†[CLIP ViT-L/14](https://huggingface.co/openai/clip-vit-large-patch14)ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ã€‚| [åœ°å€](https://huggingface.co/CompVis/stable-diffusion-v1-4) |
| CompVis/ldm-text2im-large-256               | LDMTextToImagePipeline | [LDMè®ºæ–‡](https://arxiv.org/pdf/2112.10752.pdf) LDM-KL-8-G* æƒé‡ã€‚| [åœ°å€](https://huggingface.co/CompVis/ldm-text2im-large-256) |
| CompVis/ldm-super-resolution-4x-openimages  | LDMSuperResolutionPipeline | [LDMè®ºæ–‡](https://arxiv.org/pdf/2112.10752.pdf) LDM-VQ-4 æƒé‡ï¼Œ[åŸå§‹æƒé‡é“¾æ¥](https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip)ã€‚| [åœ°å€](https://huggingface.co/CompVis/ldm-super-resolution-4x-openimages) |
| runwayml/stable-diffusion-v1-5              | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | Stable-Diffusion-v1-5 ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚éšååœ¨"laion-aesthetics v2 5+"æ•°æ®é›†ä¸Šä»¥ **512x512** åˆ†è¾¨ç‡å¾®è°ƒäº† **595k** æ­¥æ•°ï¼Œå¯¹æ–‡æœ¬ä½¿ç”¨äº† **10%** çš„dropoutï¼ˆå³ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ–‡å›¾å¯¹ä¸­çš„æ–‡æœ¬æœ‰ 10% çš„æ¦‚ç‡ä¼šå˜æˆç©ºæ–‡æœ¬ï¼‰ã€‚æ¨¡å‹åŒæ ·ä¹Ÿä½¿ç”¨äº†[CLIP ViT-L/14](https://huggingface.co/openai/clip-vit-large-patch14)ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ã€‚| [åœ°å€](https://huggingface.co/runwayml/stable-diffusion-v1-5) |
| runwayml/stable-diffusion-inpainting        | StableDiffusionInpaintPipeline | Stable-Diffusion-Inpainting ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚é¦–å…ˆè¿›è¡Œäº† **595k** æ­¥çš„å¸¸è§„è®­ç»ƒï¼ˆå®é™…ä¹Ÿå°±æ˜¯ Stable-Diffusion-v1-5 çš„æƒé‡ï¼‰ï¼Œç„¶åè¿›è¡Œäº† **440k** æ­¥çš„ inpainting ä¿®å¤è®­ç»ƒã€‚å¯¹äº inpainting ä¿®å¤è®­ç»ƒï¼Œç»™ UNet é¢å¤–å¢åŠ äº† **5** è¾“å…¥é€šé“ï¼ˆå…¶ä¸­ **4** ä¸ªç”¨äºè¢« Mask é®ç›–ä½çš„å›¾ç‰‡ï¼Œ**1** ä¸ªç”¨äº Mask æœ¬èº«ï¼‰ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œä¼šéšæœºç”Ÿæˆ Maskï¼Œå¹¶æœ‰ **25%** æ¦‚ç‡ä¼šå°†åŸå§‹å›¾ç‰‡å…¨éƒ¨ Mask æ‰ã€‚| [åœ°å€](https://huggingface.co/runwayml/stable-diffusion-inpainting) |
| stabilityai/stable-diffusion-2-base         | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | è¯¥æ¨¡å‹é¦–å…ˆåœ¨ [LAION-5B 256x256 å­é›†ä¸Š](https://laion.ai/blog/laion-5b/) ï¼ˆè¿‡æ»¤æ¡ä»¶ï¼š[punsafe = 0.1 çš„ LAION-NSFW åˆ†ç±»å™¨](https://github.com/LAION-AI/CLIP-based-NSFW-Detector) å’Œ å®¡ç¾åˆ†æ•°å¤§äºç­‰äº 4.5 ï¼‰ä»å¤´å¼€å§‹è®­ç»ƒ **550k** æ­¥ï¼Œç„¶ååˆåœ¨åˆ†è¾¨ç‡ **>= 512x512** çš„åŒä¸€æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒ **850k** æ­¥ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2-base) |
| stabilityai/stable-diffusion-2              | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | stable-diffusion-2 ä½¿ç”¨ stable-diffusion-2-base æƒé‡è¿›è¡Œåˆå§‹åŒ–ï¼Œé¦–å…ˆåœ¨åŒä¸€æ•°æ®é›†ä¸Šï¼ˆ**512x512** åˆ†è¾¨ç‡ï¼‰ä½¿ç”¨ [v-objective](https://arxiv.org/abs/2202.00512) è®­ç»ƒäº† **150k** æ­¥ã€‚ç„¶ååˆåœ¨ **768x768** åˆ†è¾¨ç‡ä¸Šä½¿ç”¨ [v-objective](https://arxiv.org/abs/2202.00512) ç»§ç»­è®­ç»ƒäº† **140k** æ­¥ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2) |
| stabilityai/stable-diffusion-2-inpainting   | StableDiffusionInpaintPipeline |stable-diffusion-2-inpainting ä½¿ç”¨ stable-diffusion-2-base æƒé‡åˆå§‹åŒ–ï¼Œå¹¶ä¸”é¢å¤–è®­ç»ƒäº† **200k** æ­¥ã€‚è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨äº† [LAMA](https://github.com/saic-mdal/lama) ä¸­æå‡ºçš„ Mask ç”Ÿæˆç­–ç•¥ï¼Œå¹¶ä¸”ä½¿ç”¨ Mask å›¾ç‰‡çš„ Latent è¡¨ç¤ºï¼ˆç»è¿‡ VAE ç¼–ç ï¼‰ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting) |
| stabilityai/stable-diffusion-x4-upscaler    | StableDiffusionUpscalePipeline | è¯¥æ¨¡å‹åœ¨**LAION 10M** å­é›†ä¸Šï¼ˆ>2048x2048ï¼‰è®­ç»ƒäº† 1.25M æ­¥ã€‚è¯¥æ¨¡å‹è¿˜åœ¨åˆ†è¾¨ç‡ä¸º **512x512** çš„å›¾åƒä¸Šä½¿ç”¨ [Text-guided Latent Upscaling Diffusion Model](https://arxiv.org/abs/2112.10752) è¿›è¡Œäº†è®­ç»ƒã€‚é™¤äº†**æ–‡æœ¬è¾“å…¥**ä¹‹å¤–ï¼Œå®ƒè¿˜æ¥æ”¶ **noise_level** ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [é¢„å®šä¹‰çš„ Scheduler](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/blob/main/low_res_scheduler/scheduler_config.json) å‘ä½åˆ†è¾¨ç‡çš„è¾“å…¥å›¾ç‰‡æ·»åŠ å™ªå£°ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler) |
| hakurei/waifu-diffusion    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | waifu-diffusion-v1-2 ä½¿ç”¨ stable-diffusion-v1-4 æƒé‡åˆå§‹åŒ–ï¼Œå¹¶ä¸”åœ¨**é«˜è´¨é‡åŠ¨æ¼«**å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒåå¾—åˆ°çš„æ¨¡å‹ã€‚ç”¨äºå¾®è°ƒçš„æ•°æ®æ˜¯ **680k** æ–‡æœ¬å›¾åƒæ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬æ˜¯é€šè¿‡ **booru ç½‘ç«™** ä¸‹è½½çš„ã€‚| [åœ°å€](https://huggingface.co/hakurei/waifu-diffusion) |
| hakurei/waifu-diffusion-v1-3    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | waifu-diffusion-v1-3 æ˜¯ waifu-diffusion-v1-2 åŸºç¡€ä¸Šè¿›ä¸€æ­¥è®­ç»ƒå¾—åˆ°çš„ã€‚ä»–ä»¬å¯¹æ•°æ®é›†è¿›è¡Œäº†é¢å¤–æ“ä½œï¼šï¼ˆ1ï¼‰åˆ é™¤ä¸‹åˆ’çº¿ï¼›ï¼ˆ2ï¼‰åˆ é™¤æ‹¬å·ï¼›ï¼ˆ3ï¼‰ç”¨é€—å·åˆ†éš”æ¯ä¸ªbooru æ ‡ç­¾ï¼›ï¼ˆ4ï¼‰éšæœºåŒ–æ ‡ç­¾é¡ºåºã€‚| [åœ°å€](https://huggingface.co/hakurei/waifu-diffusion) |
| naclbit/trinart_stable_diffusion_v2_60k    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | trinart_stable_diffusion ä½¿ç”¨ stable-diffusion-v1-4 æƒé‡åˆå§‹åŒ–ï¼Œåœ¨ 40k **é«˜åˆ†è¾¨ç‡æ¼«ç”»/åŠ¨æ¼«é£æ ¼**çš„å›¾ç‰‡æ•°æ®é›†ä¸Šå¾®è°ƒäº† 8 ä¸ª epochã€‚V2 ç‰ˆæ¨¡å‹ä½¿ç”¨ **dropouts**ã€**10k+ å›¾åƒ**å’Œ**æ–°çš„æ ‡è®°ç­–ç•¥**è®­ç»ƒäº†**æ›´é•¿æ—¶é—´**ã€‚| [åœ°å€](https://huggingface.co/naclbit/trinart_stable_diffusion_v2) |
| naclbit/trinart_stable_diffusion_v2_95k    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | **95k** æ­¥æ•°çš„çš„ç»“æœï¼Œå…¶ä»–åŒä¸Šã€‚| [åœ°å€](https://huggingface.co/naclbit/trinart_stable_diffusion_v2) |
| naclbit/trinart_stable_diffusion_v2_115k    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | **115k** æ­¥æ•°çš„çš„ç»“æœï¼Œå…¶ä»–åŒä¸Šã€‚| [åœ°å€](https://huggingface.co/naclbit/trinart_stable_diffusion_v2) |
| Deltaadams/Hentai-Diffusion    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | None| [åœ°å€](https://huggingface.co/Deltaadams/Hentai-Diffusion) |
| ringhyacinth/nail-set-diffuser    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ç¾ç”²é¢†åŸŸçš„æ‰©æ•£æ¨¡å‹ï¼Œè®­ç»ƒæ•°æ®ä½¿ç”¨äº† [Weekend](https://weibo.com/u/5982308498)| [åœ°å€](https://huggingface.co/ringhyacinth/nail-set-diffuser) |
| Linaqruf/anything-v3.0    | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | è¯¥æ¨¡å‹å¯é€šè¿‡è¾“å…¥å‡ ä¸ªæ–‡æœ¬æç¤ºè¯å°±èƒ½ç”Ÿæˆ**é«˜è´¨é‡ã€é«˜åº¦è¯¦ç»†çš„åŠ¨æ¼«é£æ ¼å›¾ç‰‡**ï¼Œè¯¥æ¨¡å‹æ”¯æŒä½¿ç”¨ **danbooru æ ‡ç­¾æ–‡æœ¬** ç”Ÿæˆå›¾åƒã€‚| [åœ°å€](https://huggingface.co/Linaqruf/anything-v3.0) |

</details>
<details><summary>&emsp; Stable Diffusion æ¨¡å‹æ”¯æŒçš„æƒé‡ï¼ˆä¸­æ–‡å’Œå¤šè¯­è¨€ï¼‰ </summary>


| PPDiffusersæ”¯æŒçš„æ¨¡å‹åç§°                     | æ”¯æŒåŠ è½½çš„Pipeline                                    | å¤‡æ³¨ | huggingface.coåœ°å€ |
| :-------------------------------------------: | :--------------------------------------------------------------------: | --- | :-----------------------------------------: |
| BAAI/AltDiffusion                           | AltDiffusionPipelineã€AltDiffusionImg2ImgPipeline | è¯¥æ¨¡å‹ä½¿ç”¨ [AltCLIP](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP/README.md) ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œåœ¨ Stable Diffusion åŸºç¡€ä¸Šè®­ç»ƒäº†**åŒè¯­Diffusionæ¨¡å‹**ï¼Œå…¶ä¸­è®­ç»ƒæ•°æ®æ¥è‡ª [WuDaoæ•°æ®é›†](https://data.baai.ac.cn/details/WuDaoCorporaText) å’Œ [LAION](https://huggingface.co/datasets/ChristophSchuhmann/improved_aesthetics_6plus) ã€‚| [åœ°å€](https://huggingface.co/BAAI/AltDiffusion) |
| BAAI/AltDiffusion-m9                        | AltDiffusionPipelineã€AltDiffusionImg2ImgPipeline |è¯¥æ¨¡å‹ä½¿ç”¨9ç§è¯­è¨€çš„ [AltCLIP-m9](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP/README.md) ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œå…¶ä»–åŒä¸Šã€‚| [åœ°å€](https://huggingface.co/BAAI/AltDiffusion-m9) |
| IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ä»–ä»¬å°† [Noah-Wukong](https://wukong-dataset.github.io/wukong-dataset/) æ•°æ®é›† (100M) å’Œ [Zero](https://zero.so.com/) æ•°æ®é›† (23M) ç”¨ä½œé¢„è®­ç»ƒçš„æ•°æ®é›†ï¼Œå…ˆç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) å¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†çš„å›¾æ–‡å¯¹ç›¸ä¼¼æ€§è¿›è¡Œæ‰“åˆ†ï¼Œå– CLIP Score å¤§äº 0.2 çš„å›¾æ–‡å¯¹ä½œä¸ºè®­ç»ƒé›†ã€‚ ä»–ä»¬ä½¿ç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) ä½œä¸ºåˆå§‹åŒ–çš„text encoderï¼Œå†»ä½ [stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) ([è®ºæ–‡](https://arxiv.org/abs/2112.10752)) æ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ï¼Œåªè®­ç»ƒ text encoderï¼Œä»¥ä¾¿ä¿ç•™åŸå§‹æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ä¸”å®ç°ä¸­æ–‡æ¦‚å¿µçš„å¯¹é½ã€‚è¯¥æ¨¡å‹ç›®å‰åœ¨0.2äº¿å›¾æ–‡å¯¹ä¸Šè®­ç»ƒäº†ä¸€ä¸ª epochã€‚ åœ¨ 32 x A100 ä¸Šè®­ç»ƒäº†å¤§çº¦100å°æ—¶ï¼Œè¯¥ç‰ˆæœ¬åªæ˜¯ä¸€ä¸ªåˆæ­¥çš„ç‰ˆæœ¬ã€‚| [åœ°å€](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1) |
| IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ä»–ä»¬å°† [Noah-Wukong](https://wukong-dataset.github.io/wukong-dataset/) æ•°æ®é›† (100M) å’Œ [Zero](https://zero.so.com/) æ•°æ®é›† (23M) ç”¨ä½œé¢„è®­ç»ƒçš„æ•°æ®é›†ï¼Œå…ˆç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) å¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†çš„å›¾æ–‡å¯¹ç›¸ä¼¼æ€§è¿›è¡Œæ‰“åˆ†ï¼Œå– CLIP Score å¤§äº 0.2 çš„å›¾æ–‡å¯¹ä½œä¸ºè®­ç»ƒé›†ã€‚ ä»–ä»¬ä½¿ç”¨ [stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) ([è®ºæ–‡](https://arxiv.org/abs/2112.10752)) æ¨¡å‹è¿›è¡Œç»§ç»­è®­ç»ƒï¼Œå…¶ä¸­è®­ç»ƒåˆ†ä¸º**ä¸¤ä¸ªstage**ã€‚**ç¬¬ä¸€ä¸ªstage** ä¸­å†»ä½æ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ï¼Œåªè®­ç»ƒ text encoder ï¼Œä»¥ä¾¿ä¿ç•™åŸå§‹æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ä¸”å®ç°ä¸­æ–‡æ¦‚å¿µçš„å¯¹é½ã€‚**ç¬¬äºŒä¸ªstage** ä¸­å°†å…¨éƒ¨æ¨¡å‹è§£å†»ï¼Œä¸€èµ·è®­ç»ƒ text encoder å’Œ diffusion model ï¼Œä»¥ä¾¿ diffusion model æ›´å¥½çš„é€‚é…ä¸­æ–‡å¼•å¯¼ã€‚ç¬¬ä¸€ä¸ª stage ä»–ä»¬è®­ç»ƒäº† 80 å°æ—¶ï¼Œç¬¬äºŒä¸ª stage è®­ç»ƒäº† 100 å°æ—¶ï¼Œä¸¤ä¸ªstageéƒ½æ˜¯ç”¨äº†8 x A100ï¼Œè¯¥ç‰ˆæœ¬æ˜¯ä¸€ä¸ªåˆæ­¥çš„ç‰ˆæœ¬ã€‚| [åœ°å€](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1) |
</details>


### åŠ è½½HF Diffusersæƒé‡
```python
from ppdiffusers import StableDiffusionPipeline
# è®¾ç½®from_hf_hubä¸ºTrueï¼Œè¡¨ç¤ºä»huggingface hubä¸‹è½½ï¼Œfrom_diffusersä¸ºTrueè¡¨ç¤ºåŠ è½½çš„æ˜¯diffusersç‰ˆPytorchæƒé‡
pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2", from_hf_hub=True, from_diffusers=True)
```

### åŠ è½½åŸåº“çš„Lightningæƒé‡
```python
from ppdiffusers import StableDiffusionPipeline
# å¯è¾“å…¥ç½‘å€ æˆ– æœ¬åœ°ckptã€safetensorsæ–‡ä»¶
pipe = StableDiffusionPipeline.from_pretrained_original_ckpt("https://paddlenlp.bj.bcebos.com/models/community/junnyu/develop/ppdiffusers/chilloutmix_NiPrunedFp32Fix.safetensors")
```

### åŠ è½½Civitaiç¤¾åŒºçš„LoRAæƒé‡
```python
from ppdiffusers import StableDiffusionPipeline
pipe = StableDiffusionPipeline.from_pretrained("TASUKU2023/Chilloutmix")
# åŠ è½½loraæƒé‡
pipe.apply_lora("https://paddlenlp.bj.bcebos.com/models/community/junnyu/develop/ppdiffusers/Moxin_10.safetensors")
```

### XFormersåŠ é€Ÿ
ä¸ºäº†ä½¿ç”¨**XFormersåŠ é€Ÿ**ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…`develop`ç‰ˆæœ¬çš„`paddle`ï¼ŒLinuxç³»ç»Ÿçš„å®‰è£…å‘½ä»¤å¦‚ä¸‹ï¼š
```sh
python -m pip install paddlepaddle-gpu==0.0.0.post117 -f https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html
```

```python
import paddle
from ppdiffusers import StableDiffusionPipeline
pipe = StableDiffusionPipeline.from_pretrained("TASUKU2023/Chilloutmix", paddle_dtype=paddle.float16)
# å¼€å¯xformersåŠ é€Ÿ é»˜è®¤é€‰æ‹©"cutlass"åŠ é€Ÿ
pipe.enable_xformers_memory_efficient_attention()
# flash éœ€è¦ä½¿ç”¨ A100ã€A10ã€3060ã€3070ã€3080ã€3090 ç­‰ä»¥ä¸Šæ˜¾å¡ã€‚
# pipe.enable_xformers_memory_efficient_attention("flash")
```
### æ–‡å›¾ç”Ÿæˆ ï¼ˆText-to-Image Generationï¼‰

```python
import paddle
from ppdiffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2")

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(5232132133)
prompt = "a portrait of shiba inu with a red cap growing on its head. intricate. lifelike. soft light. sony a 7 r iv 5 5 mm. cinematic post - processing "
image = pipe(prompt, guidance_scale=7.5, height=768, width=768).images[0]

image.save("shiba_dog_with_a_red_cap.png")
```
<div align="center">
<img width="500" alt="image" src="https://user-images.githubusercontent.com/50394665/204796701-d7911f76-8670-47d5-8d1b-8368b046c5e4.png">
</div>

### æ–‡æœ¬å¼•å¯¼çš„å›¾åƒå˜æ¢ï¼ˆImage-to-Image Text-Guided Generationï¼‰

<details><summary>&emsp;Image-to-Image Text-Guided Generation Demo </summary>

```python
import paddle
from ppdiffusers import StableDiffusionImg2ImgPipeline
from ppdiffusers.utils import load_image

pipe = StableDiffusionImg2ImgPipeline.from_pretrained("Linaqruf/anything-v3.0", safety_checker=None)

url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/image_Kurisu.png"
image = load_image(url).resize((512, 768))

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(42)
prompt = "Kurisu Makise, looking at viewer, long hair, standing, 1girl, hair ornament, hair flower, cute, jacket, white flower, white dress"
negative_prompt = "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"

image = pipe(prompt=prompt, negative_prompt=negative_prompt, image=image, strength=0.75, guidance_scale=7.5).images[0]
image.save("image_Kurisu_img2img.png")
```
<div align="center">
<img width="500" alt="image" src="https://user-images.githubusercontent.com/50394665/204799529-cd89dcdb-eb1d-4247-91ac-b0f7bad777f8.png">
</div>
</details>

### æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç¼–è¾‘ï¼ˆText-Guided Image Inpaintingï¼‰

æ³¨æ„ï¼å½“å‰æœ‰ä¸¤ç§ç‰ˆæœ¬çš„å›¾åƒç¼–è¾‘ä»£ç ï¼Œä¸€ä¸ªæ˜¯Legacyç‰ˆæœ¬ï¼Œä¸€ä¸ªæ˜¯æ­£å¼ç‰ˆæœ¬ï¼Œä¸‹é¢å°†åˆ†åˆ«ä»‹ç»ä¸¤ç§ä»£ç å¦‚ä½•ä½¿ç”¨ï¼

<details><summary>&emsp;Legacyç‰ˆæœ¬ä»£ç </summary>

```python
import paddle
from ppdiffusers import StableDiffusionInpaintPipelineLegacy
from ppdiffusers.utils import load_image

# å¯é€‰æ¨¡å‹æƒé‡
# CompVis/stable-diffusion-v1-4
# runwayml/stable-diffusion-v1-5
# stabilityai/stable-diffusion-2-base ï¼ˆåŸå§‹ç­–ç•¥ 512x512ï¼‰
# stabilityai/stable-diffusion-2 ï¼ˆv-objective 768x768ï¼‰
# Linaqruf/anything-v3.0
# ......
img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"

image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipelineLegacy.from_pretrained("stabilityai/stable-diffusion-2-base", safety_checker=None)

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(10245)
prompt = "a red cat sitting on a bench"
image = pipe(prompt=prompt, image=image, mask_image=mask_image, strength=0.75).images[0]

image.save("a_red_cat_legacy.png")
```
<div align="center">
<img width="900" alt="image" src="https://user-images.githubusercontent.com/50394665/204802186-5a6d302b-83aa-4247-a5bb-ebabfcc3abc4.png">
</div>

</details>

<details><summary>&emsp;æ­£å¼ç‰ˆæœ¬ä»£ç </summary>

Tips: ä¸‹é¢çš„ä½¿ç”¨æ–¹æ³•æ˜¯æ–°ç‰ˆæœ¬çš„ä»£ç ï¼Œä¹Ÿæ˜¯å®˜æ–¹æ¨èçš„ä»£ç ï¼Œæ³¨æ„å¿…é¡»é…åˆ **runwayml/stable-diffusion-inpainting** å’Œ **stabilityai/stable-diffusion-2-inpainting** æ‰å¯æ­£å¸¸ä½¿ç”¨ã€‚
```python
import paddle
from ppdiffusers import StableDiffusionInpaintPipeline
from ppdiffusers.utils import load_image

# å¯é€‰æ¨¡å‹æƒé‡
# runwayml/stable-diffusion-inpainting
# stabilityai/stable-diffusion-2-inpainting
img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"

image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipeline.from_pretrained("stabilityai/stable-diffusion-2-inpainting")

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(1024)
prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
image = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]

image.save("a_yellow_cat.png")
```
<div align="center">
<img width="900" alt="image" src="https://user-images.githubusercontent.com/50394665/204801946-6cd043bc-f3db-42cf-82cd-6a6171484523.png">
</div>
</details>

### æ–‡æœ¬å¼•å¯¼çš„å›¾åƒæ”¾å¤§ & è¶…åˆ†ï¼ˆText-Guided Image Upscaling & Super-Resolutionï¼‰

<details><summary>&emsp;Text-Guided Image Upscaling Demo</summary>

```python
import paddle
from ppdiffusers import StableDiffusionUpscalePipeline
from ppdiffusers.utils import load_image

pipe = StableDiffusionUpscalePipeline.from_pretrained("stabilityai/stable-diffusion-x4-upscaler")

url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/low_res_cat.png"
# æˆ‘ä»¬äººå·¥å°†åŸå§‹å›¾ç‰‡ç¼©å°æˆ 128x128 åˆ†è¾¨ç‡ï¼Œæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡ä¼šæ”¾å¤§4å€ï¼
low_res_img = load_image(url).resize((128, 128))

prompt = "a white cat"
image = pipe(prompt=prompt, image=low_res_img).images[0]

image.save("upscaled_white_cat.png")
```
<div align="center">
<img width="200" alt="image" src="https://user-images.githubusercontent.com/50394665/204806180-b7f1b9cf-8a62-4577-b5c4-91adda08a13b.png">
<img width="400" alt="image" src="https://user-images.githubusercontent.com/50394665/204806202-8c110be3-5f48-4946-95ea-21ad5a9a2340.png">
</div>
</details>

<details><summary>&emsp;Super-Resolution Demo</summary>

```python
import paddle
from ppdiffusers import LDMSuperResolutionPipeline
from ppdiffusers.utils import load_image

pipe = LDMSuperResolutionPipeline.from_pretrained("CompVis/ldm-super-resolution-4x-openimages")

url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"

# æˆ‘ä»¬äººå·¥å°†åŸå§‹å›¾ç‰‡ç¼©å°æˆ 128x128 åˆ†è¾¨ç‡ï¼Œæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡ä¼šæ”¾å¤§4å€ï¼
low_res_img = load_image(url).resize((128, 128))

image = pipe(image=low_res_img, num_inference_steps=100).images[0]

image.save("ldm-super-resolution-image.png")
```
<div align="center">
<img width="200" alt="image" src="https://user-images.githubusercontent.com/50394665/204804426-5e28b571-aa41-4f56-ba26-68cca75fdaae.png">
<img width="400" alt="image" src="https://user-images.githubusercontent.com/50394665/204804148-fe7c293b-6cd7-4942-ae9c-446369fe8410.png">
</div>

</details>

## æ¨¡å‹æ¨ç†éƒ¨ç½²
é™¤äº†**PaddleåŠ¨æ€å›¾**è¿è¡Œä¹‹å¤–ï¼Œå¾ˆå¤šæ¨¡å‹è¿˜æ”¯æŒå°†æ¨¡å‹å¯¼å‡ºå¹¶ä½¿ç”¨æ¨ç†å¼•æ“è¿è¡Œã€‚æˆ‘ä»¬æä¾›åŸºäº[FastDeploy](https://github.com/PaddlePaddle/FastDeploy)ä¸Šçš„**StableDiffusion**æ¨¡å‹éƒ¨ç½²ç¤ºä¾‹ï¼Œæ¶µç›–æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å›¾åƒç¼–è¾‘ç­‰ä»»åŠ¡ï¼Œç”¨æˆ·å¯ä»¥æŒ‰ç…§æˆ‘ä»¬æä¾›[StableDiffusionæ¨¡å‹å¯¼å‡ºæ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/deploy/export.md)å°†æ¨¡å‹å¯¼å‡ºï¼Œç„¶åä½¿ç”¨`FastDeployStableDiffusionMegaPipeline`è¿›è¡Œé«˜æ€§èƒ½æ¨ç†éƒ¨ç½²ï¼

<details><summary>&emsp; å·²é¢„å…ˆå¯¼å‡ºçš„FastDeployç‰ˆStable Diffusionæƒé‡ </summary>

**æ³¨æ„ï¼šå½“å‰å¯¼å‡ºçš„vae encoderå¸¦æœ‰éšæœºå› ç´ ï¼**

- CompVis/stable-diffusion-v1-4@fastdeploy
- runwayml/stable-diffusion-v1-5@fastdeploy
- runwayml/stable-diffusion-inpainting@fastdeploy
- stabilityai/stable-diffusion-2-base@fastdeploy
- stabilityai/stable-diffusion-2@fastdeploy
- stabilityai/stable-diffusion-2-inpainting@fastdeploy
- Linaqruf/anything-v3.0@fastdeploy
- hakurei/waifu-diffusion-v1-3@fastdeploy

</details>

<details><summary>&emsp; FastDeploy Demo </summary>

```python
import paddle
import fastdeploy as fd
from ppdiffusers import FastDeployStableDiffusionMegaPipeline
from ppdiffusers.utils import load_image

def create_runtime_option(device_id=0, backend="paddle", use_cuda_stream=True):
    option = fd.RuntimeOption()
    if backend == "paddle":
        option.use_paddle_backend()
    else:
        option.use_ort_backend()
    if device_id == -1:
        option.use_cpu()
    else:
        option.use_gpu(device_id)
        if use_cuda_stream:
            paddle_stream = paddle.device.cuda.current_stream(device_id).cuda_stream
            option.set_external_raw_stream(paddle_stream)
    return option

runtime_options = {
    "text_encoder": create_runtime_option(0, "paddle"),  # use gpu:0
    "vae_encoder": create_runtime_option(0, "paddle"),  # use gpu:0
    "vae_decoder": create_runtime_option(0, "paddle"),  # use gpu:0
    "unet": create_runtime_option(0, "paddle"),  # use gpu:0
}

fd_pipe = FastDeployStableDiffusionMegaPipeline.from_pretrained(
    "Linaqruf/anything-v3.0@fastdeploy", runtime_options=runtime_options
)

# text2img
prompt = "a portrait of shiba inu with a red cap growing on its head. intricate. lifelike. soft light. sony a 7 r iv 5 5 mm. cinematic post - processing "
image_text2img = fd_pipe.text2img(prompt=prompt, num_inference_steps=50).images[0]
image_text2img.save("image_text2img.png")

# img2img
url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/image_Kurisu.png"
image = load_image(url).resize((512, 512))
prompt = "Kurisu Makise, looking at viewer, long hair, standing, 1girl, hair ornament, hair flower, cute, jacket, white flower, white dress"
negative_prompt = "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"

image_img2img = fd_pipe.img2img(
    prompt=prompt, negative_prompt=negative_prompt, image=image, strength=0.75, guidance_scale=7.5
).images[0]
image_img2img.save("image_img2img.png")

# inpaint_legacy
img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"
image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))
prompt = "a red cat sitting on a bench"

image_inpaint_legacy = fd_pipe.inpaint_legacy(
    prompt=prompt, image=image, mask_image=mask_image, strength=0.75, num_inference_steps=50
).images[0]
image_inpaint_legacy.save("image_inpaint_legacy.png")
```
</details>
<div align="center">
<img width="900" alt="image" src="https://user-images.githubusercontent.com/50394665/205297240-46b80992-34af-40cd-91a6-ae76589d0e21.png">
</div>



## License
PPDiffusers éµå¾ª [Apache-2.0å¼€æºåè®®](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/LICENSE)ã€‚

Stable Diffusion éµå¾ª [The CreativeML OpenRAIL M å¼€æºåè®®](https://huggingface.co/spaces/CompVis/stable-diffusion-license)ã€‚
> The CreativeML OpenRAIL M is an [Open RAIL M license](https://www.licenses.ai/blog/2022/8/18/naming-convention-of-responsible-ai-licenses), adapted from the work that [BigScience](https://bigscience.huggingface.co/) and [the RAIL Initiative](https://www.licenses.ai/) are jointly carrying in the area of responsible AI licensing. See also [the article about the BLOOM Open RAIL license](https://bigscience.huggingface.co/blog/the-bigscience-rail-license) on which this license is based.

## Acknowledge
æˆ‘ä»¬å€Ÿé‰´äº†ğŸ¤— Hugging Faceçš„[Diffusers](https://github.com/huggingface/diffusers)å…³äºé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä½¿ç”¨çš„ä¼˜ç§€è®¾è®¡ï¼Œåœ¨æ­¤å¯¹Hugging Faceä½œè€…åŠå…¶å¼€æºç¤¾åŒºè¡¨ç¤ºæ„Ÿè°¢ã€‚


## Credits
This library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We'd like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:
- @huggingface' diffusers library, available [here](https://github.com/huggingface/diffusers)
- @CompVis' latent diffusion models library, available [here](https://github.com/CompVis/latent-diffusion)
- @hojonathanho original DDPM implementation, available [here](https://github.com/hojonathanho/diffusion) as well as the extremely useful translation into PyTorch by @pesser, available [here](https://github.com/pesser/pytorch_diffusion)
- @ermongroup's DDIM implementation, available [here](https://github.com/ermongroup/ddim).
- @yang-song's Score-VE and Score-VP implementations, available [here](https://github.com/yang-song/score_sde_pytorch)

We also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available [here](https://github.com/heejkoo/Awesome-Diffusion-Models) as well as @crowsonkb and @rromb for useful discussions and insights.

## Citation

```bibtex
@misc{von-platen-etal-2022-diffusers,
  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Thomas Wolf},
  title = {Diffusers: State-of-the-art diffusion models},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/diffusers}}
}
```
