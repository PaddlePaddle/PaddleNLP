# PPDiffusers: Diffusers toolbox implemented based on PaddlePaddle


**PPDiffusers**æ˜¯ä¸€æ¬¾æ”¯æŒ**è·¨æ¨¡æ€**ï¼ˆå¦‚å›¾åƒä¸è¯­éŸ³ï¼‰è®­ç»ƒå’Œæ¨ç†çš„**æ‰©æ•£æ¨¡å‹**ï¼ˆDiffusion Modelï¼‰å·¥å…·ç®±ï¼Œæˆ‘ä»¬å€Ÿé‰´äº†ğŸ¤— Huggingfaceå›¢é˜Ÿçš„[**Diffusers**](https://github.com/huggingface/diffusers)çš„ä¼˜ç§€è®¾è®¡ï¼Œå¹¶ä¸”ä¾æ‰˜[**PaddlePaddle**](https://www.paddlepaddle.org.cn/)æ¡†æ¶å’Œ[**PaddleNLP**](https://github.com/PaddlePaddle/PaddleNLP)è‡ªç„¶è¯­è¨€å¤„ç†åº“ï¼Œæ‰“é€ äº†ä¸€æ¬¾å›½äº§åŒ–çš„å·¥å…·ç®±ã€‚

## 1. News ğŸ“¢

* ğŸ”¥ **2022.11.04 æ”¯æŒ IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 å’Œ IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 ä¸­æ–‡æƒé‡**
* ğŸ”¥ **2022.10.27 å‘å¸ƒ PPDiffusersä»“åº“**


## 2. å®‰è£…
**ä½¿ç”¨ `pip` å®‰è£…**

```bash
pip install --upgrade ppdiffusers
```

**æ‰‹åŠ¨å®‰è£…**
```bash
# å…‹éš†paddlenlpä»“åº“
git clone https://github.com/PaddlePaddle/PaddleNLP
# æ³¨æ„ï¼šå¦‚æœcloneä»“åº“éå¸¸æ…¢çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨é•œåƒç‰ˆæœ¬
# git clone https://gitee.com/paddlepaddle/PaddleNLP
# åˆ‡æ¢ç›®å½•ï¼Œè¿›å…¥ppdiffusersæ–‡ä»¶å¤¹
cd PaddleNLP/ppdiffusers
# å®‰è£…ppdiffusers
python setup.py install
```

## 3. å¿«é€Ÿå¼€å§‹

ä¸ºäº†å¿«é€Ÿä¸Šæ‰‹ä½¿ç”¨è¯¥é¡¹ç›®, æˆ‘ä»¬å¯ä»¥å…ˆé˜…è¯»ğŸ¤— Huggingfaceå›¢é˜Ÿæä¾›çš„**ä¸¤ä¸ªnotebooks** (æ³¨æ„å›½å†…å¯èƒ½æ— æ³•æ­£å¸¸æ‰“å¼€):

- The [Getting started with Diffusers](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb) notebook, which showcases an end-to-end example of usage for diffusion models, schedulers and pipelines.
  Take a look at this notebook to learn how to use the pipeline abstraction, which takes care of everything (model, scheduler, noise handling) for you, and also to understand each independent building block in the library.
- The [Training a diffusers model](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb) notebook summarizes diffusion models training methods. This notebook takes a step-by-step approach to training your
  diffusion models on an image dataset, with explanatory graphics.


## 4. ä½¿ç”¨PPDiffuserså¿«é€Ÿä½“éªŒStable Diffusionæ¨¡å‹!

Stable Diffusion æ˜¯ä¸€ä¸ª**æ–‡æœ¬åˆ°å›¾åƒ(text-to-image)**çš„**æ½œåœ¨æ‰©æ•£æ¨¡å‹(latent diffusion model, ldm)**, è¯¥æ¨¡å‹æ˜¯ç”±æ¥è‡ª[CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/), [LAION](https://laion.ai/) çš„å·¥ç¨‹å¸ˆä»¥åŠ [RunwayML](https://runwayml.com/)ä¸€èµ·å¼€å‘è€Œå®Œæˆçš„ã€‚è¯¥æ¨¡å‹ä½¿ç”¨äº†å¤§å°ä¸º**512x512**çš„[LAION-5B](https://laion.ai/blog/laion-5b/)æ•°æ®é›†å­é›†è¿›è¡Œè®­ç»ƒã€‚è¯¥æ¨¡å‹ä½¿ç”¨äº†Openaiå¼€æºçš„**CLIP ViT-L/14** æ–‡æœ¬ç¼–ç å™¨(text_encoder)æ¥ç¼–ç æç¤º(prompt)æ–‡æœ¬ï¼Œä»è€Œä½œä¸ºå¼•å¯¼æ¡ä»¶ï¼ˆæ³¨æ„è¯¥éƒ¨åˆ†æƒé‡ä¸è¿›è¡Œè®­ç»ƒï¼‰ã€‚è¯¥æ¨¡å‹ä½¿ç”¨äº†Unetæ¨¡å‹ï¼ˆ860Må‚æ•°ï¼‰å’Œtext encoderï¼ˆ123Må‚æ•°ï¼‰ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å…·æœ‰4GBæ˜¾å­˜çš„GPUä¸Šè¿›è¡Œæ¨ç†é¢„æµ‹ã€‚

___æ³¨æ„___:
___ä¸ºäº†æ–¹ä¾¿å›½å†…ç”¨æˆ·ä¸‹è½½ä½¿ç”¨åŠå¿«é€Ÿä½“éªŒStable Diffusionæ¨¡å‹ï¼Œæˆ‘ä»¬åœ¨ç™¾åº¦äº‘(BOS)ä¸Šæä¾›äº†paddleç‰ˆæœ¬çš„é•œåƒæƒé‡ã€‚æ³¨æ„ï¼šä¸ºäº†ä½¿ç”¨è¯¥æ¨¡å‹ä¸æƒé‡ï¼Œä½ å¿…é¡»æ¥å—è¯¥æ¨¡å‹æ‰€è¦æ±‚çš„**License**ï¼Œè¯·è®¿é—®huggingfaceçš„[model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), ä»”ç»†é˜…è¯»é‡Œé¢çš„**License**ï¼Œç„¶åç­¾ç½²è¯¥åè®®ã€‚___

___Tips___:
___Stable Diffusionæ˜¯åŸºäºä»¥ä¸‹çš„License:
The CreativeML OpenRAIL M license is an Open RAIL M license, adapted from the work that BigScience and the RAIL Initiative are jointly carrying in the area of responsible AI licensing. See also the article about the BLOOM Open RAIL license on which this license is based.___


### 4.1 ä½¿ç”¨Stable Diffusionè¿›è¡Œæ–‡æœ¬-å›¾åƒçš„ç”Ÿæˆ
```python
import paddle
from ppdiffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]

image.save("astronaut_rides_horse.png")
```
<img width="600" alt="image" src="https://user-images.githubusercontent.com/50394665/197779466-04543823-8b83-41d6-94e8-146a7dac00d7.png">

### 4.2 ä½¿ç”¨Stable Diffusionè¿›è¡Œç”±æ–‡æœ¬å¼•å¯¼çš„å›¾ç‰‡-å›¾ç‰‡çš„ç”Ÿæˆ

```python
import requests
import paddle
from PIL import Image
from io import BytesIO

from ppdiffusers import StableDiffusionImg2ImgPipeline

# åŠ è½½pipeline
pipe = StableDiffusionImg2ImgPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

# ä¸‹è½½åˆå§‹å›¾ç‰‡
url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/sketch-mountains-input.png"

response = requests.get(url)
init_image = Image.open(BytesIO(response.content)).convert("RGB")
init_image = init_image.resize((768, 512))

prompt = "A fantasy landscape, trending on artstation"
# ä½¿ç”¨fp16åŠ å¿«ç”Ÿæˆé€Ÿåº¦
with paddle.amp.auto_cast(True):
    image = pipe(prompt=prompt, init_image=init_image, strength=0.75, guidance_scale=7.5).images[0]

image.save("fantasy_landscape.png")
```

<img width="600" alt="image" src="https://user-images.githubusercontent.com/50394665/197780044-34e6f8ca-6864-4c3d-bb99-28e0aadf867b.png">


### 4.3 ä½¿ç”¨Stable Diffusionæ ¹æ®æ–‡æœ¬è¡¥å…¨å›¾ç‰‡

Tips: ä¸‹é¢çš„ä½¿ç”¨æ–¹æ³•æ˜¯æ—§ç‰ˆæœ¬çš„ä»£ç ã€‚
```python
import paddle
from io import BytesIO

import requests
import PIL

from ppdiffusers import StableDiffusionInpaintPipeline

def download_image(url):
    response = requests.get(url)
    return PIL.Image.open(BytesIO(response.content)).convert("RGB")

img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"

init_image = download_image(img_url).resize((512, 512))
mask_image = download_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

prompt = "a cat sitting on a bench"
with paddle.amp.auto_cast(True):
    image = pipe(prompt=prompt, init_image=init_image, mask_image=mask_image, strength=0.75).images[0]

image.save("cat_on_bench.png")
```
<img width="600" alt="image" src="https://user-images.githubusercontent.com/50394665/197783711-ab3caf2e-5a4d-4099-8d01-d6ca80ca8e78.png">

Tips: ä¸‹é¢çš„ä½¿ç”¨æ–¹æ³•æ˜¯æ–°ç‰ˆæœ¬çš„ä»£ç ï¼Œä¹Ÿæ˜¯å®˜æ–¹æ¨èçš„ä»£ç ï¼Œæ³¨æ„å¿…é¡»é…åˆ**runwayml/stable-diffusion-inpainting**æ‰å¯æ­£å¸¸ä½¿ç”¨ã€‚
```python
import PIL
import requests
from io import BytesIO

from ppdiffusers import StableDiffusionInpaintPipeline, EulerAncestralDiscreteScheduler

def download_image(url):
    response = requests.get(url)
    return PIL.Image.open(BytesIO(response.content)).convert("RGB")


img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"

init_image = download_image(img_url).resize((512, 512))
mask_image = download_image(mask_url).resize((512, 512))
scheduler = EulerAncestralDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule="scaled_linear")
pipe = StableDiffusionInpaintPipeline.from_pretrained("runwayml/stable-diffusion-inpainting", scheduler=scheduler)

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[0]

image.save("cat_on_bench_new.png")
```
<img width="600" alt="image" src="https://user-images.githubusercontent.com/50394665/198016801-87cec13b-0d89-41c3-aedb-c89a43d76153.png">

## 5. Credits

This library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We'd like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:
- @huggingface' diffusers library, available [here](https://github.com/huggingface/diffusers)
- @CompVis' latent diffusion models library, available [here](https://github.com/CompVis/latent-diffusion)
- @hojonathanho original DDPM implementation, available [here](https://github.com/hojonathanho/diffusion) as well as the extremely useful translation into PyTorch by @pesser, available [here](https://github.com/pesser/pytorch_diffusion)
- @ermongroup's DDIM implementation, available [here](https://github.com/ermongroup/ddim).
- @yang-song's Score-VE and Score-VP implementations, available [here](https://github.com/yang-song/score_sde_pytorch)

We also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available [here](https://github.com/heejkoo/Awesome-Diffusion-Models) as well as @crowsonkb and @rromb for useful discussions and insights.

## 6. Citation

```bibtex
@misc{von-platen-etal-2022-diffusers,
  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Thomas Wolf},
  title = {Diffusers: State-of-the-art diffusion models},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/diffusers}}
}
```

## 7. License

PPDiffuserséµå¾ª[Apache-2.0å¼€æºåè®®](./LICENSE)ã€‚
