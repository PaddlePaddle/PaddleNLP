# PPDiffusers: Diffusers toolbox implemented based on PaddlePaddle

**PPDiffusers**æ˜¯ä¸€æ¬¾æ”¯æŒ**è·¨æ¨¡æ€**ï¼ˆå¦‚å›¾åƒä¸è¯­éŸ³ï¼‰è®­ç»ƒå’Œæ¨ç†çš„**æ‰©æ•£æ¨¡å‹**ï¼ˆDiffusion Modelï¼‰å·¥å…·ç®±ï¼Œæˆ‘ä»¬å€Ÿé‰´äº†ğŸ¤— Huggingfaceå›¢é˜Ÿçš„ [**Diffusers**](https://github.com/huggingface/diffusers) çš„ä¼˜ç§€è®¾è®¡ï¼Œå¹¶ä¸”ä¾æ‰˜ [**PaddlePaddle**](https://www.paddlepaddle.org.cn/) æ¡†æ¶å’Œ [**PaddleNLP**](https://github.com/PaddlePaddle/PaddleNLP) è‡ªç„¶è¯­è¨€å¤„ç†åº“ï¼Œæ‰“é€ äº†ä¸€æ¬¾å›½äº§åŒ–çš„å·¥å…·ç®±ã€‚

## News ğŸ“¢

* ğŸ”¥ **2022.12.06 å‘å¸ƒ 0.9.0 ç‰ˆæœ¬ï¼Œæ”¯æŒ [StableDiffusion2.0](https://github.com/Stability-AI/stablediffusion) çš„æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å›¾åƒç¼–è¾‘åŠå›¾åƒè¶…åˆ†ç­‰åŠŸèƒ½ï¼›**

* ğŸ”¥ **2022.11.11 å‘å¸ƒ 0.6.2 ç‰ˆæœ¬ï¼Œæ”¯æŒä½¿ç”¨FastDeployå¯¹ [StableDiffusionè¿›è¡Œé«˜æ€§èƒ½éƒ¨ç½²](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/deploy/README.md)ã€æ”¯æŒ [Diffusersæˆ–åŸç‰ˆæ¨¡å‹->PPDiffusersæƒé‡è½¬æ¢](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/scripts/convert_diffusers_model/README.md)ï¼›**

* ğŸ”¥ **2022.11.04 æ”¯æŒ IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 å’Œ IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 ä¸­æ–‡æƒé‡ï¼›**

* ğŸ”¥ **2022.10.27 å‘å¸ƒ PPDiffusersä»“åº“**ã€‚


<h4 align="center">
  <a href=#ç‰¹æ€§> ç‰¹æ€§ </a> |
  <a href=#å®‰è£…> å®‰è£… </a> |
  <a href=#å¿«é€Ÿå¼€å§‹> å¿«é€Ÿå¼€å§‹ </a> |
  <a href=#æ¨¡å‹éƒ¨ç½²> æ¨¡å‹éƒ¨ç½²</a>
</h4>

## ç‰¹æ€§


#### <a href=#sotaæ‰©æ•£æ¨¡å‹pipelinesé›†åˆ> ğŸ“¦ SOTAæ‰©æ•£æ¨¡å‹Pipelinesé›†åˆ </a>

#### <a href=#æä¾›ä¸°å¯Œçš„noise-scheduler> ğŸ¤— æä¾›ä¸°å¯Œçš„Noise Scheduler </a>

#### <a href=#æä¾›å¤šç§diffusionæ¨¡å‹ç»„ä»¶> ğŸ›ï¸ æä¾›å¤šç§Diffusionæ¨¡å‹ç»„ä»¶ </a>

#### <a href=#æä¾›ä¸°å¯Œçš„è®­ç»ƒå’Œæ¨ç†æ•™ç¨‹> ğŸš€ æä¾›ä¸°å¯Œçš„è®­ç»ƒå’Œæ¨ç†æ•™ç¨‹ </a>


### SOTAæ‰©æ•£æ¨¡å‹Pipelinesé›†åˆ
**æœ€å…ˆè¿›ï¼ˆState-of-the-artï¼‰** çš„ æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelï¼‰ç®¡é“ï¼ˆPipelinesï¼‰é›†åˆã€‚
å½“å‰**PPDiffusers**å·²ç»é›†æˆäº†**33+Pipelines**ï¼Œä¸ä»…æ”¯æŒ Stable Diffusion [æ–‡ç”Ÿå›¾Pipeline](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py)ï¼Œè¿˜æ”¯æŒåŸºäº[FastDeploy](https://github.com/PaddlePaddle/FastDeploy)çš„[ğŸ”¥é«˜æ€§èƒ½æ–‡ç”Ÿå›¾Pipeline](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/pipelines/stable_diffusion/pipeline_fastdeploy_stable_diffusion.py)ã€‚
å¦‚æœæƒ³è¦äº†è§£å½“å‰æ‰€æ”¯æŒçš„æ‰€æœ‰ **Pipelines** ä»¥åŠå¯¹åº”çš„è®ºæ–‡ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥é˜…è¯»[ğŸ”¥è¿™é‡Œ](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/pipelines/README.md)çš„æ–‡æ¡£ã€‚
```python
from ppdiffusers import StableDiffusionPipeline, FastDeployStableDiffusionPipeline

orig_pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
fd_pipe = FastDeployStableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5@fastdeploy")
```

### æä¾›ä¸°å¯Œçš„Noise Scheduler
æˆ‘ä»¬æä¾›äº†ä¸°å¯Œçš„**å™ªå£°è°ƒåº¦å™¨ï¼ˆNoise Schedulerï¼‰**ï¼Œæˆ‘ä»¬å¯ä»¥æƒè¡¡**é€Ÿåº¦**ä¸**è´¨é‡**ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­æ ¹æ®éœ€æ±‚å¿«é€Ÿåˆ‡æ¢ä½¿ç”¨ã€‚
å½“å‰**PPDiffusers**å·²ç»é›†æˆäº†**14+Scheduler**ï¼Œä¸ä»…æ”¯æŒ [DDPM](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_ddpm.py)ã€[DDIM](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_ddim.py) å’Œ [PNDM](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_pndm.py)ï¼Œè¿˜æ”¯æŒæœ€æ–°çš„ [ğŸ”¥DPMSolver](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/schedulers/scheduling_dpmsolver_multistep.py)ï¼

```python
from ppdiffusers import DDIMScheduler, DDPMScheduler, DPMSolverMultistepScheduler

ddpm_scheduler = DDPMScheduler(
    beta_start=0.00085,
    beta_end=0.012,
    beta_schedule="scaled_linear",
    num_train_timesteps=1000,
    steps_offset=1,
)
ddim_scheduler = DDIMScheduler(
    beta_start=0.00085,
    beta_end=0.012,
    beta_schedule="scaled_linear",
    num_train_timesteps=1000,
    clip_sample=False,
    set_alpha_to_one=False,
    steps_offset=1,
)
dpmsolver_scheduler = DPMSolverMultistepScheduler(
    beta_start=0.00085,
    beta_end=0.012,
    beta_schedule="scaled_linear",
    num_train_timesteps=1000,
    thresholding=False,
    algorithm_type="dpmsolver++",
    solver_type="midpoint",
    lower_order_final=True,
)
```

### æä¾›å¤šç§Diffusionæ¨¡å‹ç»„ä»¶
æˆ‘ä»¬æä¾›äº†**å¤šç§ Diffusion æ¨¡å‹**ç»„ä»¶ï¼Œå¦‚[UNet1d](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/unet_1d.py)ã€[UNet2d](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/unet_2d.py)ã€[UNet2d Conditional](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/ppdiffusers/models/unet_2d_conditional.py)ã€‚


### æä¾›ä¸°å¯Œçš„è®­ç»ƒå’Œæ¨ç†æ•™ç¨‹
æˆ‘ä»¬æä¾›äº†ä¸°å¯Œçš„è®­ç»ƒæ•™ç¨‹ï¼Œä¸ä»…æ”¯æŒæ‰©æ•£æ¨¡å‹çš„äºŒæ¬¡å¼€å‘ï¼Œå¦‚ [Textual Inversion](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/textual_inversion) å’Œ [DreamBooth](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/dreamBooth)  ä½¿ç”¨ 3-5 å¼ å›¾å®šåˆ¶åŒ–è®­ç»ƒè‡ªå·±çš„é£æ ¼æˆ–ç‰©ä½“ã€‚è¿˜æ”¯æŒä½¿ç”¨ [Laion400M](https://laion.ai/blog/laion-400-open-dataset) æ•°æ®é›† [ğŸ”¥ä»é›¶è®­ç»ƒLatent Diffusion Model](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/text_to_image_laion400m) æ¨¡å‹ï¼
æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº† [ä½¿ç”¨PaddleåŠ¨æ€å›¾æ¨ç†çš„æ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/examples/inference) ä»¥åŠ [ğŸ”¥é«˜æ€§èƒ½FastDeployæ¨ç†æ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/deploy)ã€‚


## å®‰è£…

### ç¯å¢ƒä¾èµ–
- paddlepaddle-gpu>=2.4.0
- paddlenlp>=2.4.4
- ftfy
- regex
- Pillow

### pipå®‰è£…

```shell
pip install --upgrade ppdiffusers
```

æ›´å¤šå…³äºPaddlePaddleå®‰è£…çš„è¯¦ç»†æ•™ç¨‹è¯·æŸ¥çœ‹[Installation](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/develop/install/pip/linux-pip.html)ã€‚

### æ‰‹åŠ¨å®‰è£…
```shell
git clone https://github.com/PaddlePaddle/PaddleNLP
# æ³¨æ„ï¼šå¦‚æœcloneä»“åº“éå¸¸æ…¢çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨é•œåƒç‰ˆæœ¬
# git clone https://gitee.com/paddlepaddle/PaddleNLP
cd PaddleNLP/ppdiffusers
python setup.py install
```

## å¿«é€Ÿå¼€å§‹

ä¸ºäº†å¿«é€Ÿä¸Šæ‰‹ä½¿ç”¨è¯¥é¡¹ç›®, æˆ‘ä»¬å¯ä»¥å…ˆé˜…è¯»ğŸ¤— Huggingfaceå›¢é˜Ÿæä¾›çš„ä¸¤ä¸ªNotebookæ•™ç¨‹ [Getting started with Diffusers](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb) å’Œ [Training a diffusers model](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb)ã€‚ï¼ˆTipsï¼šå›½å†…ç”¨æˆ·å¯èƒ½æ— æ³•æ­£å¸¸æ‰“å¼€ï¼‰

**Stable Diffusion 1.x** æ˜¯ä¸€ä¸ª**æ–‡æœ¬åˆ°å›¾åƒï¼ˆtext-to-imageï¼‰**çš„**æ½œåœ¨æ‰©æ•£æ¨¡å‹(Latent Diffusion Model, LDM)**, è¯¥æ¨¡å‹æ˜¯ç”±æ¥è‡ª [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai/), [LAION](https://laion.ai/) çš„å·¥ç¨‹å¸ˆä»¥åŠ [RunwayML](https://runwayml.com/)ä¸€èµ·å¼€å‘è€Œå®Œæˆçš„ã€‚è¯¥æ¨¡å‹ä½¿ç”¨äº†å¤§å°ä¸º **512x512** åˆ†è¾¨ç‡çš„ [LAION-5B](https://laion.ai/blog/laion-5b/) æ•°æ®é›†å­é›†è¿›è¡Œè®­ç»ƒã€‚è¯¥æ¨¡å‹ä½¿ç”¨äº† **Openai** å¼€æºçš„ **CLIP ViT-L/14** æ–‡æœ¬ç¼–ç å™¨ï¼ˆçº¦**123M**å‚æ•°ï¼‰æ¥ç¼–ç æç¤ºï¼ˆpromptï¼‰æ–‡æœ¬ï¼ˆæ³¨æ„è¯¥éƒ¨åˆ†æƒé‡ä¸è¿›è¡Œè®­ç»ƒï¼‰ã€‚è¯¥æ¨¡å‹è¿˜ä½¿ç”¨äº†**UNet2d Conditional**æ¨¡å‹ï¼ˆçº¦**860M**å‚æ•°ï¼‰æ¥å»ºæ¨¡æ‰©æ•£è¿‡ç¨‹ã€‚

**Stable Diffusion 2.0** ç”± [LAION](https://laion.ai/) åœ¨ [Stability AI](https://stability.ai/) çš„æ”¯æŒä¸‹å¼€å‘å®Œæˆçš„ï¼Œå®ƒä¸æ—©æœŸçš„ **V1** ç‰ˆæœ¬ç›¸æ¯”ï¼Œå¤§å¤§æ”¹å–„äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚è¯¥ç‰ˆæœ¬ä¸­çš„æ–‡ç”Ÿå›¾æ¨¡å‹ä¸ä»…å¯ä»¥ç”Ÿæˆé»˜è®¤åˆ†è¾¨ç‡ä¸º **512x512** åƒç´ è¿˜å¯ä»¥ç”Ÿæˆ **768x768** åˆ†è¾¨ç‡çš„å›¾åƒã€‚è¯¥æ¨¡å‹ä½œä¸º **Stable Diffusion 1.x** çš„å‡çº§ç‰ˆ, ä½¿ç”¨äº†å…¨æ–°çš„ [OpenCLIP-ViT/H](laion/CLIP-ViT-H-14-laion2B-s32B-b79K) ä¸­çš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆæ³¨æ„ï¼šè¯¥æ–‡æœ¬ç¼–ç å™¨ä¸€å…±**24å±‚**ï¼Œå®é™…åªä½¿ç”¨**23å±‚**ï¼‰ã€‚LAION å›¢é˜Ÿé¦–å…ˆä½¿ç”¨ **V1 ç‰ˆçš„ç­–ç•¥**åœ¨ **512x512** åƒç´ çš„å›¾ç‰‡ä¸Šè¿›è¡Œè®­ç»ƒå¾—åˆ°äº†ä¸€ä¸ªåŸºç¡€ç‰ˆæ¨¡å‹ [stabilityai/stable-diffusion-2-base](https://huggingface.co/stabilityai/stable-diffusion-2-base)ï¼Œç„¶åä»–ä»¬è¿˜ä½¿ç”¨äº† [v-objective](https://arxiv.org/abs/2202.00512) ç­–ç•¥ï¼Œåœ¨åŸºç¡€æ¨¡å‹ä¹‹ä¸Šè¿›ä¸€æ­¥ä½¿ç”¨ **768x768** åˆ†è¾¨ç‡çš„å›¾ç‰‡è¿›è¡Œè®­ç»ƒï¼Œå¾—åˆ°äº†ä¸€ä¸ªæœ€ç»ˆç‰ˆçš„æ¨¡å‹ [stabilityai/stable-diffusion-2](https://huggingface.co/stabilityai/stable-diffusion-2)ã€‚

___Tips___:
___ä¸ºäº†æ–¹ä¾¿å›½å†…ç”¨æˆ·ä¸‹è½½ä½¿ç”¨åŠå¿«é€Ÿä½“éªŒStable Diffusionæ¨¡å‹ï¼Œæˆ‘ä»¬åœ¨ç™¾åº¦äº‘(BOS)ä¸Šæä¾›äº†paddleç‰ˆæœ¬çš„é•œåƒæƒé‡ã€‚æ³¨æ„ï¼šä¸ºäº†ä½¿ç”¨è¯¥æ¨¡å‹ä¸æƒé‡ï¼Œä½ å¿…é¡»æ¥å—è¯¥æ¨¡å‹æ‰€è¦æ±‚çš„**License**ï¼Œè¯·è®¿é—®huggingfaceçš„[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) å’Œ [stabilityai/stable-diffusion-2](https://huggingface.co/stabilityai/stable-diffusion-2), ä»”ç»†é˜…è¯»é‡Œé¢çš„**License**ï¼Œç„¶åç­¾ç½²è¯¥åè®®ã€‚___
___Stable Diffusionæ˜¯åŸºäºä»¥ä¸‹çš„License:
The CreativeML OpenRAIL M license is an Open RAIL M license, adapted from the work that BigScience and the RAIL Initiative are jointly carrying in the area of responsible AI licensing. See also the article about the BLOOM Open RAIL license on which this license is based.___

ä¸‹é¢å°†ä»¥æœ€è¿‘è¾ƒä¸ºç«çƒ­çš„ **ğŸ”¥Stable Diffusion** æ¨¡å‹ä¸ºä¾‹ï¼Œæ¥è¯´æ˜å¦‚ä½•å¿«é€Ÿä½¿ç”¨ **ppdiffusers**ï¼Œåœ¨å¼€å§‹ä¹‹å‰æˆ‘ä»¬å¯ä»¥ç‚¹å¼€ä¸‹é¢çš„æŠ˜å æŒ‰é’®ï¼ŒæŸ¥çœ‹å½“å‰ Stable Diffusion æ¨¡å‹æ‰€æ”¯æŒçš„æƒé‡ï¼

### PPDiffusersæ¨¡å‹æ”¯æŒçš„æƒé‡

<details><summary>&emsp; Stable Diffusion æ¨¡å‹æ”¯æŒçš„æƒé‡ï¼ˆè‹±æ–‡ï¼‰ </summary>

**æˆ‘ä»¬åªéœ€è¦å°†ä¸‹é¢çš„"xxxx"ï¼Œæ›¿æ¢æˆæ‰€éœ€çš„æƒé‡åï¼Œå³å¯å¿«é€Ÿä½¿ç”¨ï¼**
```python
from ppdiffusers import *

pipe_text2img = StableDiffusionPipeline.from_pretrained("xxxx")
pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained("xxxx")
pipe_inpaint_legacy = StableDiffusionInpaintPipelineLegacy.from_pretrained("xxxx")
pipe_mega = StableDiffusionMegaPipeline.from_pretrained("xxxx")

# pipe_mega.text2img() ç­‰äº pipe_text2img()
# pipe_mega.img2img() ç­‰äº pipe_img2img()
# pipe_mega.inpaint_legacy() ç­‰äº pipe_inpaint_legacy()
```

| ppdiffusersæ”¯æŒçš„æ¨¡å‹åç§°                     | æ”¯æŒåŠ è½½çš„Pipeline                                    | å¤‡æ³¨ | huggingface.coåœ°å€ |
| :-------------------------------------------: | :--------------------------------------------------------------------: | --- | :-----------------------------------------: |
| CompVis/stable-diffusion-v1-4           | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | Stable-Diffusion-v1-4 ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚éšååœ¨"laion-aesthetics v2 5+"æ•°æ®é›†ä¸Šä»¥ **512x512** åˆ†è¾¨ç‡å¾®è°ƒäº† **225k** æ­¥æ•°ï¼Œå¯¹æ–‡æœ¬ä½¿ç”¨äº† **10%** çš„dropoutï¼ˆå³ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ–‡å›¾å¯¹ä¸­çš„æ–‡æœ¬æœ‰ 10% çš„æ¦‚ç‡ä¼šå˜æˆç©ºæ–‡æœ¬ï¼‰ã€‚æ¨¡å‹ä½¿ç”¨äº†[CLIP ViT-L/14](https://huggingface.co/openai/clip-vit-large-patch14)ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ã€‚| [åœ°å€](https://huggingface.co/CompVis/stable-diffusion-v1-4) |
| CompVis/ldm-text2im-large-256               | LDMTextToImagePipeline | [LDMè®ºæ–‡](https://arxiv.org/pdf/2112.10752.pdf) LDM-KL-8-G* æƒé‡ã€‚| [åœ°å€](https://huggingface.co/CompVis/ldm-text2im-large-256) |
| CompVis/ldm-super-resolution-4x-openimages  | LDMSuperResolutionPipeline | [LDMè®ºæ–‡](https://arxiv.org/pdf/2112.10752.pdf) LDM-VQ-4 æƒé‡ï¼Œ[åŸå§‹æƒé‡é“¾æ¥](https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip)ã€‚| [åœ°å€](https://huggingface.co/CompVis/ldm-super-resolution-4x-openimages) |
| runwayml/stable-diffusion-v1-5              | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | Stable-Diffusion-v1-5 ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚éšååœ¨"laion-aesthetics v2 5+"æ•°æ®é›†ä¸Šä»¥ **512x512** åˆ†è¾¨ç‡å¾®è°ƒäº† **595k** æ­¥æ•°ï¼Œå¯¹æ–‡æœ¬ä½¿ç”¨äº† **10%** çš„dropoutï¼ˆå³ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æ–‡å›¾å¯¹ä¸­çš„æ–‡æœ¬æœ‰ 10% çš„æ¦‚ç‡ä¼šå˜æˆç©ºæ–‡æœ¬ï¼‰ã€‚æ¨¡å‹åŒæ ·ä¹Ÿä½¿ç”¨äº†[CLIP ViT-L/14](https://huggingface.co/openai/clip-vit-large-patch14)ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ã€‚| [åœ°å€](https://huggingface.co/runwayml/stable-diffusion-v1-5) |
| runwayml/stable-diffusion-inpainting        | StableDiffusionInpaintPipeline | Stable-Diffusion-Inpainting ä½¿ç”¨ Stable-Diffusion-v1-2 çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ã€‚é¦–å…ˆè¿›è¡Œäº† **595k** æ­¥çš„å¸¸è§„è®­ç»ƒï¼ˆå®é™…ä¹Ÿå°±æ˜¯ Stable-Diffusion-v1-5 çš„æƒé‡ï¼‰ï¼Œç„¶åè¿›è¡Œäº† **440k** æ­¥çš„ inpainting ä¿®å¤è®­ç»ƒã€‚å¯¹äº inpainting ä¿®å¤è®­ç»ƒï¼Œç»™ UNet é¢å¤–å¢åŠ äº† **5** è¾“å…¥é€šé“ï¼ˆå…¶ä¸­ **4** ä¸ªç”¨äºè¢« Mask é®ç›–ä½çš„å›¾ç‰‡ï¼Œ**1** ä¸ªç”¨äº Mask æœ¬èº«ï¼‰ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œä¼šéšæœºç”Ÿæˆ Maskï¼Œå¹¶æœ‰ **25%** æ¦‚ç‡ä¼šå°†åŸå§‹å›¾ç‰‡å…¨éƒ¨ Mask æ‰ã€‚| [åœ°å€](https://huggingface.co/runwayml/stable-diffusion-inpainting) |
| stabilityai/stable-diffusion-2-base         | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | è¯¥æ¨¡å‹é¦–å…ˆåœ¨ [LAION-5B 256x256 å­é›†ä¸Š](https://laion.ai/blog/laion-5b/) ï¼ˆè¿‡æ»¤æ¡ä»¶ï¼š[punsafe = 0.1 çš„ LAION-NSFW åˆ†ç±»å™¨](https://github.com/LAION-AI/CLIP-based-NSFW-Detector) å’Œ å®¡ç¾åˆ†æ•°å¤§äºç­‰äº 4.5 ï¼‰ä»å¤´å¼€å§‹è®­ç»ƒ **550k** æ­¥ï¼Œç„¶ååˆåœ¨åˆ†è¾¨ç‡ **>= 512x512** çš„åŒä¸€æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒ **850k** æ­¥ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2-base) |
| stabilityai/stable-diffusion-2              | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | stable-diffusion-2 ä½¿ç”¨ stable-diffusion-2-base æƒé‡è¿›è¡Œåˆå§‹åŒ–ï¼Œé¦–å…ˆåœ¨åŒä¸€æ•°æ®é›†ä¸Šï¼ˆ**512x512** åˆ†è¾¨ç‡ï¼‰ä½¿ç”¨ [v-objective](https://arxiv.org/abs/2202.00512) è®­ç»ƒäº† **150k** æ­¥ã€‚ç„¶ååˆåœ¨ **768x768** åˆ†è¾¨ç‡ä¸Šä½¿ç”¨ [v-objective](https://arxiv.org/abs/2202.00512) ç»§ç»­è®­ç»ƒäº† **140k** æ­¥ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2) |
| stabilityai/stable-diffusion-2-inpainting   | StableDiffusionInpaintPipeline |stable-diffusion-2-inpainting ä½¿ç”¨ stable-diffusion-2-base æƒé‡åˆå§‹åŒ–ï¼Œå¹¶ä¸”é¢å¤–è®­ç»ƒäº† **200k** æ­¥ã€‚è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨äº† [LAMA](https://github.com/saic-mdal/lama) ä¸­æå‡ºçš„ Mask ç”Ÿæˆç­–ç•¥ï¼Œå¹¶ä¸”ä½¿ç”¨ Mask å›¾ç‰‡çš„ Latent è¡¨ç¤ºï¼ˆç»è¿‡ VAE ç¼–ç ï¼‰ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting) |
| stabilityai/stable-diffusion-x4-upscaler    | StableDiffusionUpscalePipeline | è¯¥æ¨¡å‹åœ¨**LAION 10M** å­é›†ä¸Šï¼ˆ>2048x2048ï¼‰è®­ç»ƒäº† 1.25M æ­¥ã€‚è¯¥æ¨¡å‹è¿˜åœ¨åˆ†è¾¨ç‡ä¸º **512x512** çš„å›¾åƒä¸Šä½¿ç”¨ [Text-guided Latent Upscaling Diffusion Model](https://arxiv.org/abs/2112.10752) è¿›è¡Œäº†è®­ç»ƒã€‚é™¤äº†**æ–‡æœ¬è¾“å…¥**ä¹‹å¤–ï¼Œå®ƒè¿˜æ¥æ”¶ **noise_level** ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [é¢„å®šä¹‰çš„ Scheduler](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/blob/main/configs/stable-diffusion/x4-upscaling.yaml) å‘ä½åˆ†è¾¨ç‡çš„è¾“å…¥å›¾ç‰‡æ·»åŠ å™ªå£°ã€‚| [åœ°å€](https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler) |
</details>
<details><summary>&emsp; Stable Diffusion æ¨¡å‹æ”¯æŒçš„æƒé‡ï¼ˆä¸­æ–‡å’Œå¤šè¯­è¨€ï¼‰ </summary>


| ppdiffusersæ”¯æŒçš„æ¨¡å‹åç§°                     | æ”¯æŒåŠ è½½çš„Pipeline                                    | å¤‡æ³¨ | huggingface.coåœ°å€ |
| :-------------------------------------------: | :--------------------------------------------------------------------: | --- | :-----------------------------------------: |
| BAAI/AltDiffusion                           | AltDiffusionPipelineã€AltDiffusionImg2ImgPipeline | è¯¥æ¨¡å‹ä½¿ç”¨ [AltCLIP](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP/README.md) ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œåœ¨ Stable Diffusion åŸºç¡€ä¸Šè®­ç»ƒäº†**åŒè¯­Diffusionæ¨¡å‹**ï¼Œå…¶ä¸­è®­ç»ƒæ•°æ®æ¥è‡ª [WuDaoæ•°æ®é›†](https://data.baai.ac.cn/details/WuDaoCorporaText) å’Œ [LAION](https://huggingface.co/datasets/ChristophSchuhmann/improved_aesthetics_6plus) ã€‚| [åœ°å€](https://huggingface.co/BAAI/AltDiffusion) |
| BAAI/AltDiffusion-m9                        | AltDiffusionPipelineã€AltDiffusionImg2ImgPipeline |è¯¥æ¨¡å‹ä½¿ç”¨9ç§è¯­è¨€çš„ [AltCLIP-m9](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP/README.md) ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œå…¶ä»–åŒä¸Šã€‚| [åœ°å€](https://huggingface.co/BAAI/AltDiffusion-m9) |
| IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1 | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ä»–ä»¬å°† [Noah-Wukong](https://wukong-dataset.github.io/wukong-dataset/) æ•°æ®é›† (100M) å’Œ [Zero](https://zero.so.com/) æ•°æ®é›† (23M) ç”¨ä½œé¢„è®­ç»ƒçš„æ•°æ®é›†ï¼Œå…ˆç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) å¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†çš„å›¾æ–‡å¯¹ç›¸ä¼¼æ€§è¿›è¡Œæ‰“åˆ†ï¼Œå– CLIP Score å¤§äº 0.2 çš„å›¾æ–‡å¯¹ä½œä¸ºè®­ç»ƒé›†ã€‚ ä»–ä»¬ä½¿ç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) ä½œä¸ºåˆå§‹åŒ–çš„text encoderï¼Œå†»ä½ [stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) ([è®ºæ–‡](https://arxiv.org/abs/2112.10752)) æ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ï¼Œåªè®­ç»ƒ text encoderï¼Œä»¥ä¾¿ä¿ç•™åŸå§‹æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ä¸”å®ç°ä¸­æ–‡æ¦‚å¿µçš„å¯¹é½ã€‚è¯¥æ¨¡å‹ç›®å‰åœ¨0.2äº¿å›¾æ–‡å¯¹ä¸Šè®­ç»ƒäº†ä¸€ä¸ª epochã€‚ åœ¨ 32 x A100 ä¸Šè®­ç»ƒäº†å¤§çº¦100å°æ—¶ï¼Œè¯¥ç‰ˆæœ¬åªæ˜¯ä¸€ä¸ªåˆæ­¥çš„ç‰ˆæœ¬ã€‚| [åœ°å€](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1) |
| IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 | StableDiffusionPipelineã€StableDiffusionImg2ImgPipelineã€StableDiffusionInpaintPipelineLegacyã€StableDiffusionMegaPipelineã€StableDiffusionPipelineAllinOne | ä»–ä»¬å°† [Noah-Wukong](https://wukong-dataset.github.io/wukong-dataset/) æ•°æ®é›† (100M) å’Œ [Zero](https://zero.so.com/) æ•°æ®é›† (23M) ç”¨ä½œé¢„è®­ç»ƒçš„æ•°æ®é›†ï¼Œå…ˆç”¨ [IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese) å¯¹è¿™ä¸¤ä¸ªæ•°æ®é›†çš„å›¾æ–‡å¯¹ç›¸ä¼¼æ€§è¿›è¡Œæ‰“åˆ†ï¼Œå– CLIP Score å¤§äº 0.2 çš„å›¾æ–‡å¯¹ä½œä¸ºè®­ç»ƒé›†ã€‚ ä»–ä»¬ä½¿ç”¨ [stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) ([è®ºæ–‡](https://arxiv.org/abs/2112.10752)) æ¨¡å‹è¿›è¡Œç»§ç»­è®­ç»ƒï¼Œå…¶ä¸­è®­ç»ƒåˆ†ä¸º**ä¸¤ä¸ªstage**ã€‚**ç¬¬ä¸€ä¸ªstage** ä¸­å†»ä½æ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ï¼Œåªè®­ç»ƒ text encoder ï¼Œä»¥ä¾¿ä¿ç•™åŸå§‹æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ä¸”å®ç°ä¸­æ–‡æ¦‚å¿µçš„å¯¹é½ã€‚**ç¬¬äºŒä¸ªstage** ä¸­å°†å…¨éƒ¨æ¨¡å‹è§£å†»ï¼Œä¸€èµ·è®­ç»ƒ text encoder å’Œ diffusion model ï¼Œä»¥ä¾¿ diffusion model æ›´å¥½çš„é€‚é…ä¸­æ–‡å¼•å¯¼ã€‚ç¬¬ä¸€ä¸ª stage ä»–ä»¬è®­ç»ƒäº† 80 å°æ—¶ï¼Œç¬¬äºŒä¸ª stage è®­ç»ƒäº† 100 å°æ—¶ï¼Œä¸¤ä¸ªstageéƒ½æ˜¯ç”¨äº†8 x A100ï¼Œè¯¥ç‰ˆæœ¬æ˜¯ä¸€ä¸ªåˆæ­¥çš„ç‰ˆæœ¬ã€‚| [åœ°å€](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1) |
</details>


### æ–‡ç”Ÿå›¾ ï¼ˆText-to-Image Generationï¼‰

```python
import paddle
from ppdiffusers import StableDiffusionPipeline

# å¯é€‰æ¨¡å‹æƒé‡
# CompVis/stable-diffusion-v1-4
# runwayml/stable-diffusion-v1-5
# stabilityai/stable-diffusion-2-base ï¼ˆåŸå§‹ç­–ç•¥ 512x512ï¼‰
# stabilityai/stable-diffusion-2 ï¼ˆv-objective 768x768ï¼‰
# Linaqruf/anything-v3.0
# ......
pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2")

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(5232132133)
prompt = "a portrait of shiba inu with a red cap growing on its head. intricate. lifelike. soft light. sony a 7 r iv 5 5 mm. cinematic post - processing "
image = pipe(prompt, guidance_scale=7.5, height=768, width=768).images[0]

image.save("shiba_dog_with_a_red_cap.png")
```
<div align="center">
<img width="500" alt="image" src="https://user-images.githubusercontent.com/50394665/204796701-d7911f76-8670-47d5-8d1b-8368b046c5e4.png">
</div>

### åŸºäºæ–‡æœ¬å¼•å¯¼çš„å›¾ç”Ÿå›¾ï¼ˆImage-to-Image Text-Guided Generationï¼‰

<details><summary>&emsp;Image-to-Image Text-Guided Generation Demo </summary>

```python
import paddle
from ppdiffusers import StableDiffusionImg2ImgPipeline
from ppdiffusers.utils import load_image

# å¯é€‰æ¨¡å‹æƒé‡
# CompVis/stable-diffusion-v1-4
# runwayml/stable-diffusion-v1-5
# stabilityai/stable-diffusion-2-base ï¼ˆåŸå§‹ç­–ç•¥ 512x512ï¼‰
# stabilityai/stable-diffusion-2 ï¼ˆv-objective 768x768ï¼‰
# Linaqruf/anything-v3.0
# ......
pipe = StableDiffusionImg2ImgPipeline.from_pretrained("Linaqruf/anything-v3.0", safety_checker=None)

url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/image_Kurisu.png"
image = load_image(url).resize((512, 768))

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(42)
prompt = "Kurisu Makise, looking at viewer, long hair, standing, 1girl, hair ornament, hair flower, cute, jacket, white flower, white dress"
negative_prompt = "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"

image = pipe(prompt=prompt, negative_prompt=negative_prompt, image=image, strength=0.75, guidance_scale=7.5).images[0]
image.save("image_Kurisu_img2img.png")
```
<div align="center">
<img width="500" alt="image" src="https://user-images.githubusercontent.com/50394665/204799529-cd89dcdb-eb1d-4247-91ac-b0f7bad777f8.png">
</div>
</details>

### åŸºäºæ–‡æœ¬å¼•å¯¼çš„å›¾åƒç¼–è¾‘ï¼ˆText-Guided Image Inpaintingï¼‰

æ³¨æ„ï¼å½“å‰æœ‰ä¸¤ç§ç‰ˆæœ¬çš„å›¾åƒç¼–è¾‘ä»£ç ï¼Œä¸€ä¸ªæ˜¯Legacyç‰ˆæœ¬ï¼Œä¸€ä¸ªæ˜¯æ­£å¼ç‰ˆæœ¬ï¼Œä¸‹é¢å°†åˆ†åˆ«ä»‹ç»ä¸¤ç§ä»£ç å¦‚ä½•ä½¿ç”¨ï¼

<details><summary>&emsp;Legacyç‰ˆæœ¬ä»£ç </summary>

```python
import paddle
from ppdiffusers import StableDiffusionInpaintPipelineLegacy
from ppdiffusers.utils import load_image

# å¯é€‰æ¨¡å‹æƒé‡
# CompVis/stable-diffusion-v1-4
# runwayml/stable-diffusion-v1-5
# stabilityai/stable-diffusion-2-base ï¼ˆåŸå§‹ç­–ç•¥ 512x512ï¼‰
# stabilityai/stable-diffusion-2 ï¼ˆv-objective 768x768ï¼‰
# Linaqruf/anything-v3.0
# ......
img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"

image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipelineLegacy.from_pretrained("stabilityai/stable-diffusion-2-base", safety_checker=None)

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(10245)
prompt = "a red cat sitting on a bench"
image = pipe(prompt=prompt, image=image, mask_image=mask_image, strength=0.75).images[0]

image.save("a_red_cat_legacy.png")
```
<div align="center">
<img width="900" alt="image" src="https://user-images.githubusercontent.com/50394665/204802186-5a6d302b-83aa-4247-a5bb-ebabfcc3abc4.png">
</div>

</details>

<details><summary>&emsp;æ­£å¼ç‰ˆæœ¬ä»£ç </summary>

Tips: ä¸‹é¢çš„ä½¿ç”¨æ–¹æ³•æ˜¯æ–°ç‰ˆæœ¬çš„ä»£ç ï¼Œä¹Ÿæ˜¯å®˜æ–¹æ¨èçš„ä»£ç ï¼Œæ³¨æ„å¿…é¡»é…åˆ **runwayml/stable-diffusion-inpainting** å’Œ **stabilityai/stable-diffusion-2-inpainting** æ‰å¯æ­£å¸¸ä½¿ç”¨ã€‚
```python
import paddle
from ppdiffusers import StableDiffusionInpaintPipeline
from ppdiffusers.utils import load_image

# å¯é€‰æ¨¡å‹æƒé‡
# runwayml/stable-diffusion-inpainting
# stabilityai/stable-diffusion-2-inpainting
img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"

image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipeline.from_pretrained("stabilityai/stable-diffusion-2-inpainting")

# è®¾ç½®éšæœºç§å­ï¼Œæˆ‘ä»¬å¯ä»¥å¤ç°ä¸‹é¢çš„ç»“æœï¼
paddle.seed(1024)
prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
image = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]

image.save("a_yellow_cat.png")
```
<div align="center">
<img width="900" alt="image" src="https://user-images.githubusercontent.com/50394665/204801946-6cd043bc-f3db-42cf-82cd-6a6171484523.png">
</div>
</details>

### åŸºäºæ–‡æœ¬å¼•å¯¼çš„å›¾åƒæ”¾å¤§ & å›¾åƒè¶…åˆ†ï¼ˆText-Guided Image Upscaling & Super Superresolutionï¼‰

<details><summary>&emsp;Text-Guided Image Upscaling Demo</summary>

```python
import paddle
from ppdiffusers import StableDiffusionUpscalePipeline
from ppdiffusers.utils import load_image

pipe = StableDiffusionUpscalePipeline.from_pretrained("stabilityai/stable-diffusion-x4-upscaler")

url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/low_res_cat.png"
# æˆ‘ä»¬äººå·¥å°†åŸå§‹å›¾ç‰‡ç¼©å°æˆ 128x128 åˆ†è¾¨ç‡ï¼Œæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡ä¼šæ”¾å¤§4å€ï¼
low_res_img = load_image(url).resize((128, 128))

prompt = "a white cat"
image = pipe(prompt=prompt, image=low_res_img).images[0]

image.save("upscaled_white_cat.png")
```
<div align="center">
<img width="200" alt="image" src="https://user-images.githubusercontent.com/50394665/204806180-b7f1b9cf-8a62-4577-b5c4-91adda08a13b.png">
<img width="400" alt="image" src="https://user-images.githubusercontent.com/50394665/204806202-8c110be3-5f48-4946-95ea-21ad5a9a2340.png">
</div>
</details>

<details><summary>&emsp;Super Superresolution Demo</summary>

```python
import paddle
from ppdiffusers import LDMSuperResolutionPipeline
from ppdiffusers.utils import load_image

pipe = LDMSuperResolutionPipeline.from_pretrained("CompVis/ldm-super-resolution-4x-openimages")

url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"

# æˆ‘ä»¬äººå·¥å°†åŸå§‹å›¾ç‰‡ç¼©å°æˆ 128x128 åˆ†è¾¨ç‡ï¼Œæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡ä¼šæ”¾å¤§4å€ï¼
low_res_img = load_image(url).resize((128, 128))

image = pipe(image=low_res_img, num_inference_steps=100).images[0]

image.save("ldm-super-resolution-image.png")
```
<div align="center">
<img width="200" alt="image" src="https://user-images.githubusercontent.com/50394665/204804426-5e28b571-aa41-4f56-ba26-68cca75fdaae.png">
<img width="400" alt="image" src="https://user-images.githubusercontent.com/50394665/204804148-fe7c293b-6cd7-4942-ae9c-446369fe8410.png">
</div">
</details>

## æ¨¡å‹éƒ¨ç½²
StableDiffusionæ¨¡å‹é™¤äº†**æ”¯æŒPaddleåŠ¨æ€å›¾**è¿è¡Œï¼Œè¿˜æ”¯æŒå°†æ¨¡å‹å¯¼å‡ºå¹¶ä½¿ç”¨æ¨ç†å¼•æ“è¿è¡Œã€‚æˆ‘ä»¬æä¾›åœ¨ [FastDeploy](https://github.com/PaddlePaddle/FastDeploy) ä¸Šçš„ **StableDiffusion** æ¨¡å‹æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ã€å›¾åƒç¼–è¾‘ç­‰ä»»åŠ¡çš„éƒ¨ç½²ç¤ºä¾‹ï¼Œç”¨æˆ·å¯ä»¥æŒ‰ç…§æˆ‘ä»¬æä¾› [StableDiffusionæ¨¡å‹å¯¼å‡ºæ•™ç¨‹](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/deploy/export.md) å°†æ¨¡å‹å¯¼å‡º æˆ–è€…ä½¿ç”¨ [ä¸€é”®å¯¼å‡ºè„šæœ¬](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/ppdiffusers/scripts/convert_diffusers_model/convert_ppdiffusers_stable_diffusion_to_fastdeploy.py) å¯¼å‡ºæ¨¡å‹ï¼Œç„¶åä½¿ç”¨æˆ‘ä»¬æä¾›çš„`FastDeployStableDiffusionMegaPipeline`è¿›è¡Œé«˜æ€§èƒ½æ¨ç†éƒ¨ç½²ï¼

<details><summary>&emsp; å·²é¢„å…ˆå¯¼å‡ºçš„FastDeployç‰ˆStable Diffusionæƒé‡ </summary>

**æ³¨æ„ï¼šå½“å‰å¯¼å‡ºçš„vae encoderå¸¦æœ‰éšæœºå› ç´ ï¼[éšæœºå› ç´ ä»£ç åœ°å€](https://github.com/PaddlePaddle/PaddleNLP/blob/649b18a1834163007358e3a9dffd6462c0f9c7cf/ppdiffusers/ppdiffusers/models/vae.py#L365-L370)**

- CompVis/stable-diffusion-v1-4@fastdeploy
- runwayml/stable-diffusion-v1-5@fastdeploy
- runwayml/stable-diffusion-inpainting@fastdeploy
- stabilityai/stable-diffusion-2-base@fastdeploy
- stabilityai/stable-diffusion-2@fastdeploy
- stabilityai/stable-diffusion-2-inpainting@fastdeploy
- Linaqruf/anything-v3.0@fastdeploy
- hakurei/waifu-diffusion-v1-3@fastdeploy

</details>

```python
import fastdeploy as fd
from ppdiffusers import FastDeployStableDiffusionMegaPipeline
from ppdiffusers.utils import load_image

def create_runtime_option(device_id=-1, backend="paddle"):
    option = fd.RuntimeOption()
    if backend == "paddle":
        option.use_paddle_backend()
    else:
        option.use_ort_backend()
    if device_id == -1:
        option.use_cpu()
    else:
        option.use_gpu(device_id)
    return option

runtime_options = {
    "text_encoder": create_runtime_option(-1, "onnx"),  # use cpu
    "vae_encoder": create_runtime_option(-1, "paddle"),  # use cpu
    "vae_decoder": create_runtime_option(-1, "paddle"),  # use cpu
    "unet": create_runtime_option(0, "paddle"),  # use gpu
}

fd_pipe = FastDeployStableDiffusionMegaPipeline.from_pretrained(
    "Linaqruf/anything-v3.0@fastdeploy", runtime_options=runtime_options
)

# text2img
prompt = "a portrait of shiba inu with a red cap growing on its head. intricate. lifelike. soft light. sony a 7 r iv 5 5 mm. cinematic post - processing "
image_text2img = fd_pipe.text2img(prompt=prompt, num_inference_steps=50).images[0]
image_text2img.save("image_text2img.png")

# img2img
url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/data/image_Kurisu.png"
image = load_image(url).resize((512, 512))
prompt = "Kurisu Makise, looking at viewer, long hair, standing, 1girl, hair ornament, hair flower, cute, jacket, white flower, white dress"
negative_prompt = "lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"

image_img2img = fd_pipe.img2img(
    prompt=prompt, negative_prompt=negative_prompt, image=image, strength=0.75, guidance_scale=7.5
).images[0]
image_img2img.save("image_img2img.png")

# inpaint_legacy
img_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations.png"
mask_url = "https://paddlenlp.bj.bcebos.com/models/community/CompVis/stable-diffusion-v1-4/overture-creations-mask.png"
image = load_image(img_url).resize((512, 512))
mask_image = load_image(mask_url).resize((512, 512))
prompt = "a red cat sitting on a bench"

image_inpaint_legacy = fd_pipe.inpaint_legacy(
    prompt=prompt, image=image, mask_image=mask_image, strength=0.75, num_inference_steps=50
).images[0]
image_inpaint_legacy.save("image_inpaint_legacy.png")
```
<div align="center">
<img width="900" alt="image" src="https://user-images.githubusercontent.com/50394665/205297240-46b80992-34af-40cd-91a6-ae76589d0e21.png">
</div>

## Credits

This library concretizes previous work by many different authors and would not have been possible without their great research and implementations. We'd like to thank, in particular, the following implementations which have helped us in our development and without which the API could not have been as polished today:
- @huggingface' diffusers library, available [here](https://github.com/huggingface/diffusers)
- @CompVis' latent diffusion models library, available [here](https://github.com/CompVis/latent-diffusion)
- @hojonathanho original DDPM implementation, available [here](https://github.com/hojonathanho/diffusion) as well as the extremely useful translation into PyTorch by @pesser, available [here](https://github.com/pesser/pytorch_diffusion)
- @ermongroup's DDIM implementation, available [here](https://github.com/ermongroup/ddim).
- @yang-song's Score-VE and Score-VP implementations, available [here](https://github.com/yang-song/score_sde_pytorch)

We also want to thank @heejkoo for the very helpful overview of papers, code and resources on diffusion models, available [here](https://github.com/heejkoo/Awesome-Diffusion-Models) as well as @crowsonkb and @rromb for useful discussions and insights.

## Citation

```bibtex
@misc{von-platen-etal-2022-diffusers,
  author = {Patrick von Platen and Suraj Patil and Anton Lozhkov and Pedro Cuenca and Nathan Lambert and Kashif Rasul and Mishig Davaadorj and Thomas Wolf},
  title = {Diffusers: State-of-the-art diffusion models},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/diffusers}}
}
```

## License

PPDiffuserséµå¾ª[Apache-2.0å¼€æºåè®®](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/ppdiffusers/LICENSE)ã€‚
