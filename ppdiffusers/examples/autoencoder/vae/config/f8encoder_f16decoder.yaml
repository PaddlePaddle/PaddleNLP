model:
  base_learning_rate: 1.0e-4
  target: autoencoder.models.autoencoder.AutoencoderKL
  params:
    ckpt_path: './pretrained_autoencoder/kl-f8.ckpt'
    load_decoder_ckpt: False
    input_size: [256, 256]
    monitor: "val/rec_loss"
    embed_dim: 4
    lossconfig:
      target: autoencoder.modules.losses.LPIPSWithDiscriminator
      params:
        disc_start: 50001
        kl_weight: 0.000001
        disc_weight: 0.5
    freeze_encoder: true
    ddconfig:
      encoder:
        double_z: true
        z_channels: 4
        resolution: 256
        in_channels: 3
        out_ch: 3
        ch: 128
        ch_mult:
        - 1
        - 2
        - 4
        - 4
        num_res_blocks: 2
        attn_resolutions: []
        dropout: 0.0
      decoder:
        double_z: true
        z_channels: 4
        resolution: 256
        in_channels: 3
        out_ch: 3
        ch: 128
        ch_mult:
        - 1
        - 2
        - 2
        - 2
        - 4
        num_res_blocks: 2
        attn_resolutions: []
        dropout: 0.0
data:
  target: train.DataModuleFromConfig
  params:
    batch_size: 4
    num_workers: 8
    train:
      target: autoencoder.data.text_image_pair.TextImagePair
      params:
        file_list: data/filelist/train.filelist.list
        size: 512
        num_records: 62500
        buffer_size: 100

lightning:
  callbacks:
    image_logger:
      target: train.ImageLogger
      params:
        batch_frequency: 500
        max_images: 8
        increase_log_steps: True
        save_every_steps: 2000

  trainer:
    benchmark: True
    accumulate_grad_batches: 1