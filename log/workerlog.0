/ssd1/zhangbin41/miniconda3/envs/paddle_env/bin/python: can't open file 'test.py': [Errno 2] No such file or directory
/ssd1/zhangbin41/miniconda3/envs/paddle_env/bin/python: can't open file 'modelzoo/ernie-health/test.py': [Errno 2] No such file or directory
/ssd1/zhangbin41/miniconda3/envs/paddle_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[32m[2023-01-04 14:41:40,551] [    INFO][0m - loading configuration file<./configs/test.yaml>[0m
<function init_argv at 0x7f40701d4550>
[32m[2023-01-04 14:41:40,560] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-01-04 14:41:40,560] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:41:40,560] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-01-04 14:41:40,560] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - model_name_or_path            :ernie-health-chinese[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - model_type                    :ernie-health[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - [0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - input_dir                     :./data[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - masked_lm_prob                :0.15[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-01-04 14:41:40,561] [    INFO][0m - [0m
I0104 14:41:40.562435 10634 tcp_utils.cc:181] The server starts to listen on IP_ANY:36777
I0104 14:41:40.562624 10634 tcp_utils.cc:130] Successfully connected to 10.255.129.12:36777
W0104 14:41:42.953619 10634 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2
W0104 14:41:42.957989 10634 gpu_resources.cc:91] device: 1, cuDNN Version: 7.6.
/ssd1/zhangbin41/miniconda3/envs/paddle_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[32m[2023-01-04 14:42:16,688] [    INFO][0m - loading configuration file<./configs/test.yaml>[0m
<function init_argv at 0x7ff4feb98550>
[32m[2023-01-04 14:42:16,696] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-01-04 14:42:16,696] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:42:16,696] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-01-04 14:42:16,696] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:42:16,696] [    INFO][0m - model_name_or_path            :ernie-health-chinese[0m
[32m[2023-01-04 14:42:16,696] [    INFO][0m - model_type                    :ernie-health[0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m - [0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m - input_dir                     :./data[0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m - masked_lm_prob                :0.15[0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-01-04 14:42:16,697] [    INFO][0m - [0m
I0104 14:42:16.698088 17109 tcp_utils.cc:181] The server starts to listen on IP_ANY:39813
I0104 14:42:16.698256 17109 tcp_utils.cc:130] Successfully connected to 10.255.129.12:39813
W0104 14:42:19.079283 17109 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2
W0104 14:42:19.083113 17109 gpu_resources.cc:91] device: 5, cuDNN Version: 7.6.
[33m[2023-01-04 14:42:19,586] [ WARNING][0m - Process rank: 0, device: gpu, world_size: 3, distributed training: True, 16-bits training: True[0m
[32m[2023-01-04 14:42:19,587] [    INFO][0m - Already cached /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/vocab.txt[0m
[32m[2023-01-04 14:42:19,621] [    INFO][0m - tokenizer config file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/tokenizer_config.json[0m
[32m[2023-01-04 14:42:19,622] [    INFO][0m - Special tokens file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/special_tokens_map.json[0m
[32m[2023-01-04 14:42:19,625] [    INFO][0m - Model config ElectraConfig {
  "attention_probs_dropout_prob": 0.1,
  "embedding_size": 768,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 512,
  "model_type": "electra",
  "num_attention_heads": 12,
  "num_choices": 2,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "type_vocab_size": 2,
  "vocab_size": 22608
}
[0m
[33m[2023-01-04 14:42:20,079] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:42:20,145] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:42:20,738] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:42:20,858] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:42:21,171] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[32m[2023-01-04 14:42:27,240] [    INFO][0m - Downloading ernie-health-chinese.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie-health-chinese/ernie-health-chinese.pdparams[0m
  0%|          | 0.00/392M [00:00<?, ?B/s]  1%|          | 3.66M/392M [00:00<00:10, 38.3MB/s]  2%|â–         | 9.26M/392M [00:00<00:07, 50.4MB/s]  4%|â–         | 16.4M/392M [00:00<00:06, 61.7MB/s]  6%|â–Œ         | 22.3M/392M [00:00<00:06, 56.8MB/s]  7%|â–‹         | 27.8M/392M [00:00<00:06, 55.2MB/s]  9%|â–‰         | 34.5M/392M [00:00<00:06, 54.2MB/s] 11%|â–ˆ         | 42.3M/392M [00:00<00:05, 62.3MB/s] 13%|â–ˆâ–Ž        | 50.4M/392M [00:00<00:05, 68.8MB/s] 15%|â–ˆâ–        | 58.5M/392M [00:00<00:04, 73.6MB/s] 17%|â–ˆâ–‹        | 66.5M/392M [00:01<00:04, 76.7MB/s] 19%|â–ˆâ–‰        | 74.5M/392M [00:01<00:04, 78.8MB/s] 21%|â–ˆâ–ˆ        | 82.5M/392M [00:01<00:04, 80.4MB/s] 23%|â–ˆâ–ˆâ–Ž       | 90.5M/392M [00:01<00:03, 81.5MB/s] 25%|â–ˆâ–ˆâ–Œ       | 98.4M/392M [00:01<00:03, 81.9MB/s] 27%|â–ˆâ–ˆâ–‹       | 106M/392M [00:01<00:03, 82.3MB/s]  29%|â–ˆâ–ˆâ–‰       | 114M/392M [00:01<00:03, 82.8MB/s] 31%|â–ˆâ–ˆâ–ˆ       | 122M/392M [00:01<00:03, 83.1MB/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 130M/392M [00:01<00:03, 83.1MB/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 138M/392M [00:01<00:03, 83.3MB/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 146M/392M [00:02<00:03, 83.6MB/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 154M/392M [00:02<00:02, 83.8MB/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 162M/392M [00:02<00:02, 83.9MB/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 170M/392M [00:02<00:02, 84.1MB/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 178M/392M [00:02<00:02, 84.2MB/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 187M/392M [00:02<00:02, 84.1MB/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 195M/392M [00:02<00:02, 84.1MB/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 203M/392M [00:02<00:02, 84.0MB/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 211M/392M [00:02<00:02, 84.1MB/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 219M/392M [00:02<00:02, 80.7MB/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 226M/392M [00:03<00:02, 66.9MB/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 233M/392M [00:03<00:02, 68.3MB/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 241M/392M [00:03<00:02, 71.2MB/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 248M/392M [00:03<00:02, 73.5MB/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 256M/392M [00:03<00:01, 75.2MB/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 263M/392M [00:03<00:01, 76.3MB/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 271M/392M [00:03<00:01, 77.0MB/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 279M/392M [00:03<00:01, 77.5MB/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 286M/392M [00:03<00:01, 77.7MB/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 293M/392M [00:04<00:01, 77.9MB/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 301M/392M [00:04<00:01, 74.5MB/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 308M/392M [00:04<00:01, 75.5MB/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 316M/392M [00:04<00:01, 76.4MB/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 323M/392M [00:04<00:00, 77.3MB/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 331M/392M [00:04<00:00, 78.0MB/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 339M/392M [00:04<00:00, 78.5MB/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 346M/392M [00:04<00:00, 78.7MB/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 354M/392M [00:04<00:00, 78.9MB/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 361M/392M [00:04<00:00, 78.9MB/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 369M/392M [00:05<00:00, 79.0MB/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 376M/392M [00:05<00:00, 79.0MB/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 384M/392M [00:05<00:00, 79.0MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 391M/392M [00:05<00:00, 71.2MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392M/392M [00:05<00:00, 75.8MB/s]
[33m[2023-01-04 14:42:33,546] [ WARNING][0m - Some weights of the model checkpoint at ernie-health-chinese were not used when initializing ErnieHealthForTotalPretraining: ['electra.encoder.layers.7.norm1.weight', 'electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.encoder.layers.9.norm1.bias', 'electra.encoder.layers.7.norm2.weight', 'electra.encoder.layers.3.linear2.weight', 'electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.encoder.layers.11.norm2.bias', 'electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.encoder.layers.4.linear2.bias', 'electra.encoder.layers.3.norm1.bias', 'electra.encoder.layers.7.linear1.weight', 'electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.encoder.layers.9.linear1.weight', 'electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.encoder.layers.6.norm1.weight', 'electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.encoder.layers.0.norm1.weight', 'electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.encoder.layers.9.linear1.bias', 'electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.encoder.layers.10.linear2.weight', 'electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.encoder.layers.1.linear1.weight', 'electra.encoder.layers.4.linear1.weight', 'electra.encoder.layers.11.norm1.bias', 'electra.encoder.layers.11.linear2.weight', 'electra.encoder.layers.9.norm2.weight', 'electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.encoder.layers.8.norm2.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.encoder.layers.11.linear1.weight', 'electra.encoder.layers.3.linear2.bias', 'electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.encoder.layers.4.norm2.weight', 'electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.encoder.layers.5.norm1.weight', 'electra.encoder.layers.2.norm2.weight', 'electra.encoder.layers.6.norm1.bias', 'electra.encoder.layers.8.linear2.weight', 'electra.encoder.layers.4.linear2.weight', 'electra.encoder.layers.10.norm2.weight', 'electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.encoder.layers.0.norm2.bias', 'electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.encoder.layers.6.norm2.bias', 'electra.encoder.layers.8.linear1.bias', 'electra.encoder.layers.7.norm2.bias', 'electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.encoder.layers.2.linear2.bias', 'electra.encoder.layers.0.linear2.weight', 'electra.encoder.layers.5.norm2.bias', 'electra.encoder.layers.6.linear1.bias', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.encoder.layers.2.linear1.bias', 'electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.encoder.layers.10.norm1.bias', 'electra.encoder.layers.0.linear1.weight', 'electra.encoder.layers.0.norm2.weight', 'electra.encoder.layers.8.norm2.weight', 'electra.encoder.layers.1.norm1.weight', 'electra.encoder.layers.2.linear1.weight', 'electra.encoder.layers.10.norm2.bias', 'electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.embeddings.layer_norm.weight', 'electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.encoder.layers.1.linear2.bias', 'electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.encoder.layers.7.linear1.bias', 'electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.encoder.layers.1.norm2.bias', 'electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.encoder.layers.10.linear1.bias', 'electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.encoder.layers.0.linear2.bias', 'electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.encoder.layers.5.linear1.bias', 'electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.embeddings.layer_norm.bias', 'electra.encoder.layers.4.norm1.bias', 'electra.encoder.layers.9.linear2.weight', 'electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.encoder.layers.11.linear2.bias', 'electra.encoder.layers.3.linear1.bias', 'electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.encoder.layers.3.norm1.weight', 'electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layers.3.norm2.bias', 'electra.encoder.layers.5.linear2.bias', 'electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.encoder.layers.8.norm1.bias', 'electra.encoder.layers.9.norm2.bias', 'electra.encoder.layers.4.norm2.bias', 'electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.encoder.layers.2.norm1.bias', 'electra.encoder.layers.1.norm1.bias', 'electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.encoder.layers.2.norm1.weight', 'electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.encoder.layers.1.norm2.weight', 'electra.encoder.layers.4.linear1.bias', 'electra.encoder.layers.5.linear1.weight', 'electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.encoder.layers.9.norm1.weight', 'electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.encoder.layers.5.norm1.bias', 'electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.encoder.layers.9.linear2.bias', 'electra.encoder.layers.2.norm2.bias', 'electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.encoder.layers.1.linear1.bias', 'electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.encoder.layers.6.linear2.weight', 'electra.encoder.layers.7.linear2.bias', 'electra.encoder.layers.8.norm1.weight', 'electra.encoder.layers.2.linear2.weight', 'electra.encoder.layers.11.norm2.weight', 'electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.encoder.layers.11.norm1.weight', 'electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.encoder.layers.10.linear2.bias', 'electra.encoder.layers.1.linear2.weight', 'electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.encoder.layers.6.linear2.bias', 'electra.encoder.layers.7.norm1.bias', 'electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.encoder.layers.3.norm2.weight', 'electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.encoder.layers.3.linear1.weight', 'electra.encoder.layers.0.linear1.bias', 'electra.encoder.layers.0.norm1.bias', 'electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.encoder.layers.5.linear2.weight', 'electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.encoder.layers.4.norm1.weight', 'electra.encoder.layers.8.linear1.weight', 'electra.encoder.layers.8.linear2.bias', 'electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.encoder.layers.6.linear1.weight', 'electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.encoder.layers.5.norm2.weight', 'electra.encoder.layers.10.norm1.weight', 'electra.encoder.layers.7.linear2.weight', 'electra.encoder.layers.11.linear1.bias', 'electra.encoder.layers.10.linear1.weight', 'electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.encoder.layers.6.norm2.weight']
- This IS expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).[0m
[33m[2023-01-04 14:42:33,546] [ WARNING][0m - Some weights of ErnieHealthForTotalPretraining were not initialized from the model checkpoint at ernie-health-chinese and are newly initialized: ['electra.generator.electra.embeddings.layer_norm.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.norm1.weight', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.1.norm2.weight', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.bias', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.11.norm2.weight', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.7.norm2.bias', 'electra.generator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.7.norm2.weight', 'electra.discriminator.electra.encoder.layers.10.norm1.bias', 'electra.generator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.5.norm1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.3.linear2.weight', 'electra.generator.electra.encoder.layers.8.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.linear1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.10.norm2.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.4.norm1.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.electra.encoder.layers.8.norm1.bias', 'electra.discriminator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.0.linear2.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.bias', 'electra.generator.electra.encoder.layers.8.linear1.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear2.bias', 'electra.discriminator.electra.encoder.layers.11.norm1.bias', 'electra.generator.electra.encoder.layers.0.norm2.weight', 'electra.generator.electra.encoder.layers.7.linear2.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.norm2.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.bias', 'electra.discriminator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.1.linear1.bias', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.linear2.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.linear2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.4.linear2.weight', 'electra.generator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.9.norm2.weight', 'electra.generator.electra.encoder.layers.0.norm1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.discriminator.bias_mts.weight', 'electra.generator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.3.norm2.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.7.linear2.weight', 'electra.generator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.5.norm1.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.weight', 'electra.generator.electra.encoder.layers.11.norm2.weight', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.4.norm1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.discriminator.discriminator_csp.out_proj.weight', 'electra.discriminator.electra.encoder.layers.0.linear1.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.generator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.1.linear2.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.weight', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.discriminator.discriminator_csp.dense.weight', 'electra.generator.electra.encoder.layers.6.linear2.bias', 'electra.generator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.discriminator.discriminator_rtd.dense.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.8.norm2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.9.norm1.bias', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.7.norm1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.weight', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.4.norm2.weight', 'electra.discriminator.electra.encoder.layers.4.norm1.weight', 'electra.generator.electra.encoder.layers.1.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.0.linear1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.3.linear2.bias', 'electra.discriminator.electra.encoder.layers.3.norm2.weight', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.discriminator.electra.embeddings.word_embeddings.weight', 'electra.generator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.norm1.bias', 'electra.generator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.discriminator.discriminator_csp.out_proj.bias', 'electra.discriminator.electra.encoder.layers.5.norm2.weight', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.linear1.bias', 'electra.generator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.discriminator.electra.embeddings.position_embeddings.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.linear1.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.electra.encoder.layers.2.linear1.weight', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.generator.electra.embeddings.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.10.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.linear2.bias', 'electra.generator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.10.linear1.bias', 'electra.generator.electra.encoder.layers.5.norm2.weight', 'electra.generator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.1.norm1.bias', 'electra.generator.electra.encoder.layers.4.norm2.bias', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.linear2.weight', 'electra.generator.electra.encoder.layers.5.norm2.bias', 'electra.generator.electra.encoder.layers.9.linear1.weight', 'electra.generator.electra.encoder.layers.3.linear2.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.11.linear1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.3.norm2.weight', 'electra.generator.electra.encoder.layers.3.norm1.weight', 'electra.generator.electra.encoder.layers.10.linear1.weight', 'electra.discriminator.discriminator_csp.dense.bias', 'electra.discriminator.electra.encoder.layers.2.norm2.weight', 'electra.discriminator.electra.encoder.layers.8.linear2.bias', 'electra.generator.generator_predictions.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.generator.electra.embeddings.word_embeddings.weight', 'electra.generator.generator_predictions.dense.bias', 'electra.generator.electra.encoder.layers.5.linear2.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.2.norm2.weight', 'electra.generator.electra.encoder.layers.10.norm1.bias', 'electra.discriminator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.1.linear2.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.6.linear2.weight', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.1.linear1.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.3.linear2.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.discriminator.discriminator_rtd.dense.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.bias', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.8.norm2.bias', 'electra.generator.electra.encoder.layers.5.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.6.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.6.linear1.bias', 'electra.discriminator.electra.encoder.layers.11.norm1.weight', 'electra.generator.electra.encoder.layers.7.norm2.weight', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.10.norm1.weight', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.weight', 'electra.generator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.7.linear2.bias', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.discriminator.electra.embeddings.token_type_embeddings.weight', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.norm1.bias', 'electra.generator.electra.encoder.layers.2.norm1.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.generator.generator_predictions.dense.weight', 'electra.discriminator.electra.encoder.layers.3.linear1.bias', 'electra.discriminator.electra.encoder.layers.9.linear1.bias', 'electra.generator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.discriminator.discriminator_mts.weight', 'electra.discriminator.electra.encoder.layers.7.norm2.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.7.norm1.weight', 'electra.generator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.discriminator_rtd.dense_prediction.bias', 'electra.discriminator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.0.linear2.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.electra.encoder.layers.2.norm1.weight', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.4.linear2.bias', 'electra.generator.generator_lm_head_bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear2.weight', 'electra.discriminator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.linear2.bias', 'electra.generator.electra.encoder.layers.9.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.8.linear2.bias', 'electra.discriminator.electra.encoder.layers.8.linear1.bias', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.11.norm2.bias', 'electra.generator.electra.encoder.layers.6.norm2.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.norm2.weight', 'electra.generator.generator_predictions.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.norm2.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.4.linear1.bias', 'electra.discriminator.electra.encoder.layers.9.norm2.bias', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.11.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.11.norm1.weight', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.discriminator.electra.embeddings.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.9.norm1.bias', 'electra.generator.electra.encoder.layers.9.linear2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.discriminator_rtd.dense_prediction.weight', 'electra.generator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.generator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm1.bias', 'electra.generator.electra.encoder.layers.3.norm1.bias', 'electra.discriminator.electra.embeddings.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.2.linear1.weight', 'electra.discriminator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.0.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.discriminator.discriminator_mts.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.5.linear2.bias', 'electra.generator.electra.encoder.layers.7.linear1.weight', 'electra.generator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.4.linear1.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[0m
[32m[2023-01-04 14:42:33,547] [    INFO][0m - start load data : 2023-01-04 14:42:33[0m
[32m[2023-01-04 14:42:33,800] [    INFO][0m - load data done, total : 0.25368738174438477 s[0m
[32m[2023-01-04 14:42:33,929] [    INFO][0m - max_steps is given, it will override any value given in num_train_epochs[0m
[32m[2023-01-04 14:42:33,930] [    INFO][0m - Using half precision[0m
[32m[2023-01-04 14:42:33,936] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:42:33,936] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2023-01-04 14:42:33,936] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:42:33,937] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2023-01-04 14:42:33,937] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2023-01-04 14:42:33,937] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2023-01-04 14:42:33,937] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2023-01-04 14:42:33,938] [    INFO][0m - bf16                          :False[0m
[32m[2023-01-04 14:42:33,938] [    INFO][0m - bf16_full_eval                :False[0m
[32m[2023-01-04 14:42:33,938] [    INFO][0m - current_device                :gpu:5[0m
[32m[2023-01-04 14:42:33,938] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2023-01-04 14:42:33,938] [    INFO][0m - dataloader_num_workers        :2[0m
[32m[2023-01-04 14:42:33,939] [    INFO][0m - device                        :gpu[0m
[32m[2023-01-04 14:42:33,939] [    INFO][0m - disable_tqdm                  :False[0m
[32m[2023-01-04 14:42:33,939] [    INFO][0m - do_eval                       :False[0m
[32m[2023-01-04 14:42:33,939] [    INFO][0m - do_export                     :False[0m
[32m[2023-01-04 14:42:33,939] [    INFO][0m - do_predict                    :False[0m
[32m[2023-01-04 14:42:33,940] [    INFO][0m - do_train                      :True[0m
[32m[2023-01-04 14:42:33,940] [    INFO][0m - eval_batch_size               :8[0m
[32m[2023-01-04 14:42:33,940] [    INFO][0m - eval_iters                    :10[0m
[32m[2023-01-04 14:42:33,940] [    INFO][0m - eval_steps                    :None[0m
[32m[2023-01-04 14:42:33,940] [    INFO][0m - evaluation_strategy           :IntervalStrategy.NO[0m
[32m[2023-01-04 14:42:33,940] [    INFO][0m - fp16                          :True[0m
[32m[2023-01-04 14:42:33,941] [    INFO][0m - fp16_full_eval                :False[0m
[32m[2023-01-04 14:42:33,941] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2023-01-04 14:42:33,941] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2023-01-04 14:42:33,941] [    INFO][0m - greater_is_better             :None[0m
[32m[2023-01-04 14:42:33,941] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2023-01-04 14:42:33,942] [    INFO][0m - label_names                   :None[0m
[32m[2023-01-04 14:42:33,942] [    INFO][0m - learning_rate                 :0.001[0m
[32m[2023-01-04 14:42:33,942] [    INFO][0m - load_best_model_at_end        :False[0m
[32m[2023-01-04 14:42:33,942] [    INFO][0m - local_process_index           :0[0m
[32m[2023-01-04 14:42:33,942] [    INFO][0m - local_rank                    :0[0m
[32m[2023-01-04 14:42:33,943] [    INFO][0m - log_level                     :-1[0m
[32m[2023-01-04 14:42:33,943] [    INFO][0m - log_level_replica             :-1[0m
[32m[2023-01-04 14:42:33,943] [    INFO][0m - log_on_each_node              :True[0m
[32m[2023-01-04 14:42:33,943] [    INFO][0m - logging_dir                   :output/eheath-pretraining/runs/Jan04_14-42-16_yq01-qianmo-com-255-129-12.yq01[0m
[32m[2023-01-04 14:42:33,943] [    INFO][0m - logging_first_step            :False[0m
[32m[2023-01-04 14:42:33,943] [    INFO][0m - logging_steps                 :20[0m
[32m[2023-01-04 14:42:33,944] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:42:33,944] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2023-01-04 14:42:33,944] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2023-01-04 14:42:33,944] [    INFO][0m - max_steps                     :100[0m
[32m[2023-01-04 14:42:33,944] [    INFO][0m - metric_for_best_model         :None[0m
[32m[2023-01-04 14:42:33,945] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2023-01-04 14:42:33,945] [    INFO][0m - no_cuda                       :False[0m
[32m[2023-01-04 14:42:33,945] [    INFO][0m - num_train_epochs              :3.0[0m
[32m[2023-01-04 14:42:33,945] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2023-01-04 14:42:33,945] [    INFO][0m - output_dir                    :output/eheath-pretraining[0m
[32m[2023-01-04 14:42:33,946] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2023-01-04 14:42:33,946] [    INFO][0m - past_index                    :-1[0m
[32m[2023-01-04 14:42:33,946] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2023-01-04 14:42:33,946] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2023-01-04 14:42:33,946] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2023-01-04 14:42:33,947] [    INFO][0m - process_index                 :0[0m
[32m[2023-01-04 14:42:33,947] [    INFO][0m - recompute                     :True[0m
[32m[2023-01-04 14:42:33,947] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2023-01-04 14:42:33,947] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2023-01-04 14:42:33,947] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2023-01-04 14:42:33,947] [    INFO][0m - run_name                      :output/eheath-pretraining[0m
[32m[2023-01-04 14:42:33,948] [    INFO][0m - save_on_each_node             :False[0m
[32m[2023-01-04 14:42:33,948] [    INFO][0m - save_steps                    :5[0m
[32m[2023-01-04 14:42:33,948] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:42:33,948] [    INFO][0m - save_total_limit              :10[0m
[32m[2023-01-04 14:42:33,948] [    INFO][0m - scale_loss                    :32768[0m
[32m[2023-01-04 14:42:33,949] [    INFO][0m - seed                          :42[0m
[32m[2023-01-04 14:42:33,949] [    INFO][0m - sharding                      :[][0m
[32m[2023-01-04 14:42:33,949] [    INFO][0m - sharding_degree               :-1[0m
[32m[2023-01-04 14:42:33,949] [    INFO][0m - should_log                    :True[0m
[32m[2023-01-04 14:42:33,949] [    INFO][0m - should_save                   :True[0m
[32m[2023-01-04 14:42:33,950] [    INFO][0m - skip_memory_metrics           :True[0m
[32m[2023-01-04 14:42:33,950] [    INFO][0m - test_iters                    :100[0m
[32m[2023-01-04 14:42:33,950] [    INFO][0m - train_batch_size              :8[0m
[32m[2023-01-04 14:42:33,950] [    INFO][0m - warmup_ratio                  :0.01[0m
[32m[2023-01-04 14:42:33,950] [    INFO][0m - warmup_steps                  :0[0m
[32m[2023-01-04 14:42:33,950] [    INFO][0m - weight_decay                  :0.01[0m
[32m[2023-01-04 14:42:33,951] [    INFO][0m - world_size                    :3[0m
[32m[2023-01-04 14:42:33,951] [    INFO][0m - [0m
[32m[2023-01-04 14:42:34,063] [    INFO][0m - ***** Running training *****[0m
[32m[2023-01-04 14:42:34,064] [    INFO][0m -   Num examples = 200061[0m
[32m[2023-01-04 14:42:34,064] [    INFO][0m -   Num Epochs = 1[0m
[32m[2023-01-04 14:42:34,064] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2023-01-04 14:42:34,064] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 24[0m
[32m[2023-01-04 14:42:34,064] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2023-01-04 14:42:34,064] [    INFO][0m -   Total optimization steps = 100[0m
[32m[2023-01-04 14:42:34,064] [    INFO][0m -   Total num train samples = 2400[0m
/ssd1/zhangbin41/miniconda3/envs/paddle_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[32m[2023-01-04 14:44:21,711] [    INFO][0m - loading configuration file<./configs/test.yaml>[0m
<function init_argv at 0x7f6f803ed550>
[32m[2023-01-04 14:44:21,729] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-01-04 14:44:21,729] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:44:21,730] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-01-04 14:44:21,730] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:44:21,730] [    INFO][0m - model_name_or_path            :ernie-health-chinese[0m
[32m[2023-01-04 14:44:21,730] [    INFO][0m - model_type                    :ernie-health[0m
[32m[2023-01-04 14:44:21,731] [    INFO][0m - [0m
[32m[2023-01-04 14:44:21,731] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:44:21,731] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-01-04 14:44:21,731] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:44:21,731] [    INFO][0m - input_dir                     :./data[0m
[32m[2023-01-04 14:44:21,732] [    INFO][0m - masked_lm_prob                :0.15[0m
[32m[2023-01-04 14:44:21,732] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-01-04 14:44:21,732] [    INFO][0m - [0m
I0104 14:44:21.733343 37279 tcp_utils.cc:181] The server starts to listen on IP_ANY:40353
I0104 14:44:21.733708 37279 tcp_utils.cc:130] Successfully connected to 10.255.129.12:40353
W0104 14:44:24.539471 37279 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2
W0104 14:44:24.543303 37279 gpu_resources.cc:91] device: 5, cuDNN Version: 7.6.
[33m[2023-01-04 14:44:25,331] [ WARNING][0m - Process rank: 0, device: gpu, world_size: 3, distributed training: True, 16-bits training: True[0m
[32m[2023-01-04 14:44:25,332] [    INFO][0m - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie-health-chinese/vocab.txt and saved to /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese[0m
[32m[2023-01-04 14:44:25,413] [    INFO][0m - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie-health-chinese/vocab.txt[0m
  0%|          | 0.00/109k [00:00<?, ?B/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109k/109k [00:00<00:00, 8.72MB/s]
[32m[2023-01-04 14:44:25,623] [    INFO][0m - tokenizer config file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/tokenizer_config.json[0m
[32m[2023-01-04 14:44:25,623] [    INFO][0m - Special tokens file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/special_tokens_map.json[0m
[32m[2023-01-04 14:44:25,626] [    INFO][0m - Model config ElectraConfig {
  "attention_probs_dropout_prob": 0.1,
  "embedding_size": 768,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 512,
  "model_type": "electra",
  "num_attention_heads": 12,
  "num_choices": 2,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "type_vocab_size": 2,
  "vocab_size": 22608
}
[0m
[32m[2023-01-04 14:44:25,628] [    INFO][0m - Configuration saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/config.json[0m
[33m[2023-01-04 14:44:26,050] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:44:26,125] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:44:26,674] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:44:26,747] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:44:27,016] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[32m[2023-01-04 14:44:32,974] [    INFO][0m - Downloading ernie-health-chinese.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie-health-chinese/ernie-health-chinese.pdparams[0m
  0%|          | 0.00/392M [00:00<?, ?B/s]  1%|          | 3.17M/392M [00:00<00:12, 33.2MB/s]  2%|â–         | 8.53M/392M [00:00<00:08, 46.7MB/s]  4%|â–         | 15.8M/392M [00:00<00:06, 60.1MB/s]  6%|â–Œ         | 23.5M/392M [00:00<00:05, 68.3MB/s]  8%|â–Š         | 31.2M/392M [00:00<00:05, 72.8MB/s] 10%|â–‰         | 38.9M/392M [00:00<00:04, 75.5MB/s] 12%|â–ˆâ–        | 46.6M/392M [00:00<00:04, 77.3MB/s] 14%|â–ˆâ–        | 54.5M/392M [00:00<00:04, 78.9MB/s] 16%|â–ˆâ–Œ        | 62.0M/392M [00:00<00:04, 75.1MB/s] 18%|â–ˆâ–Š        | 69.2M/392M [00:01<00:05, 67.4MB/s] 20%|â–ˆâ–‰        | 76.7M/392M [00:01<00:04, 70.3MB/s] 22%|â–ˆâ–ˆâ–       | 84.6M/392M [00:01<00:04, 74.0MB/s] 24%|â–ˆâ–ˆâ–Ž       | 92.6M/392M [00:01<00:04, 76.9MB/s] 26%|â–ˆâ–ˆâ–Œ       | 101M/392M [00:01<00:03, 79.1MB/s]  28%|â–ˆâ–ˆâ–Š       | 109M/392M [00:01<00:03, 80.7MB/s] 30%|â–ˆâ–ˆâ–‰       | 117M/392M [00:01<00:03, 81.8MB/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 125M/392M [00:01<00:03, 82.4MB/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 133M/392M [00:01<00:03, 83.1MB/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 141M/392M [00:01<00:03, 83.5MB/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 149M/392M [00:02<00:03, 83.6MB/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 157M/392M [00:02<00:02, 83.9MB/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 165M/392M [00:02<00:02, 83.7MB/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 173M/392M [00:02<00:02, 84.0MB/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 181M/392M [00:02<00:02, 84.1MB/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 189M/392M [00:02<00:02, 84.2MB/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 197M/392M [00:02<00:02, 84.2MB/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 205M/392M [00:02<00:02, 84.1MB/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 213M/392M [00:02<00:02, 84.2MB/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 221M/392M [00:02<00:02, 84.0MB/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 229M/392M [00:03<00:02, 84.1MB/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 237M/392M [00:03<00:01, 84.2MB/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 245M/392M [00:03<00:01, 84.1MB/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 253M/392M [00:03<00:01, 84.1MB/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 261M/392M [00:03<00:01, 84.1MB/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 269M/392M [00:03<00:01, 83.9MB/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 278M/392M [00:03<00:01, 83.8MB/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 286M/392M [00:03<00:01, 83.9MB/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 294M/392M [00:03<00:01, 83.9MB/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 302M/392M [00:03<00:01, 84.0MB/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 310M/392M [00:04<00:01, 84.2MB/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 318M/392M [00:04<00:00, 84.5MB/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 326M/392M [00:04<00:00, 84.3MB/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 334M/392M [00:04<00:00, 84.3MB/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 342M/392M [00:04<00:00, 84.2MB/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 350M/392M [00:04<00:00, 84.1MB/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 358M/392M [00:04<00:00, 84.2MB/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 366M/392M [00:04<00:00, 84.2MB/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 374M/392M [00:04<00:00, 84.2MB/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 382M/392M [00:04<00:00, 84.0MB/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 390M/392M [00:05<00:00, 84.2MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392M/392M [00:05<00:00, 80.8MB/s]
[33m[2023-01-04 14:44:38,896] [ WARNING][0m - Some weights of the model checkpoint at ernie-health-chinese were not used when initializing ErnieHealthForTotalPretraining: ['electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.encoder.layers.3.linear2.bias', 'electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.encoder.layers.6.linear2.weight', 'electra.encoder.layers.9.linear2.bias', 'electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.encoder.layers.3.linear1.bias', 'electra.encoder.layers.10.norm2.bias', 'electra.encoder.layers.2.linear2.weight', 'electra.encoder.layers.5.norm2.weight', 'electra.encoder.layers.1.linear2.weight', 'electra.encoder.layers.9.norm2.weight', 'electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.encoder.layers.7.linear1.bias', 'electra.encoder.layers.3.linear2.weight', 'electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.encoder.layers.11.norm1.bias', 'electra.encoder.layers.4.linear2.bias', 'electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.encoder.layers.2.linear1.bias', 'electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.encoder.layers.10.linear2.weight', 'electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.encoder.layers.10.norm2.weight', 'electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.encoder.layers.10.linear1.bias', 'electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.encoder.layers.3.norm1.weight', 'electra.encoder.layers.0.linear2.bias', 'electra.encoder.layers.10.linear1.weight', 'electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.encoder.layers.5.linear1.bias', 'electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.encoder.layers.9.norm1.bias', 'electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.encoder.layers.11.norm2.weight', 'electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.encoder.layers.7.norm1.bias', 'electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.encoder.layers.11.linear2.weight', 'electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.encoder.layers.0.linear1.weight', 'electra.encoder.layers.0.linear1.bias', 'electra.encoder.layers.8.norm1.weight', 'electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.encoder.layers.6.norm2.weight', 'electra.encoder.layers.3.norm1.bias', 'electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.encoder.layers.2.norm1.weight', 'electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.encoder.layers.3.norm2.bias', 'electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.encoder.layers.6.norm1.bias', 'electra.encoder.layers.1.norm2.bias', 'electra.encoder.layers.3.linear1.weight', 'electra.encoder.layers.8.norm2.weight', 'electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.encoder.layers.6.linear1.bias', 'electra.encoder.layers.4.linear2.weight', 'electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.encoder.layers.0.norm1.bias', 'electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.encoder.layers.1.norm2.weight', 'electra.encoder.layers.6.linear2.bias', 'electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.encoder.layers.7.linear1.weight', 'electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.encoder.layers.8.norm1.bias', 'electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.encoder.layers.4.linear1.bias', 'electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.encoder.layers.7.norm1.weight', 'electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.encoder.layers.1.norm1.bias', 'electra.encoder.layers.5.norm1.bias', 'electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.encoder.layers.10.norm1.weight', 'electra.embeddings.layer_norm.bias', 'electra.encoder.layers.7.norm2.bias', 'electra.encoder.layers.7.norm2.weight', 'electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.encoder.layers.7.linear2.bias', 'electra.encoder.layers.0.norm2.bias', 'electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.encoder.layers.2.linear1.weight', 'electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.encoder.layers.0.linear2.weight', 'electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.encoder.layers.4.norm1.weight', 'electra.encoder.layers.1.norm1.weight', 'electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.encoder.layers.2.norm2.weight', 'electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.encoder.layers.6.norm1.weight', 'electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.encoder.layers.1.linear1.bias', 'electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.encoder.layers.6.norm2.bias', 'electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.encoder.layers.6.linear1.weight', 'electra.encoder.layers.11.linear1.bias', 'electra.encoder.layers.11.linear2.bias', 'electra.encoder.layers.4.norm2.weight', 'electra.encoder.layers.2.norm1.bias', 'electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.encoder.layers.0.norm2.weight', 'electra.encoder.layers.11.linear1.weight', 'electra.encoder.layers.5.norm2.bias', 'electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.encoder.layers.8.linear2.weight', 'electra.encoder.layers.9.norm1.weight', 'electra.encoder.layers.10.linear2.bias', 'electra.encoder.layers.5.norm1.weight', 'electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.encoder.layers.8.linear1.weight', 'electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.encoder.layers.1.linear2.bias', 'electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.embeddings.layer_norm.weight', 'electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.encoder.layers.5.linear2.bias', 'electra.encoder.layers.3.norm2.weight', 'electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.encoder.layers.9.linear1.bias', 'electra.encoder.layers.11.norm1.weight', 'electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.encoder.layers.7.linear2.weight', 'electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.encoder.layers.11.norm2.bias', 'electra.encoder.layers.1.linear1.weight', 'electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.encoder.layers.5.linear2.weight', 'electra.encoder.layers.8.linear2.bias', 'electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.encoder.layers.8.linear1.bias', 'electra.encoder.layers.8.norm2.bias', 'electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.encoder.layers.4.linear1.weight', 'electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.encoder.layers.4.norm2.bias', 'electra.encoder.layers.10.norm1.bias', 'electra.encoder.layers.2.norm2.bias', 'electra.encoder.layers.2.linear2.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layers.0.norm1.weight', 'electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.encoder.layers.4.norm1.bias', 'electra.encoder.layers.5.linear1.weight', 'electra.encoder.layers.9.linear2.weight', 'electra.encoder.layers.9.linear1.weight', 'electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.encoder.layers.9.norm2.bias', 'electra.encoder.layers.11.self_attn.v_proj.bias']
- This IS expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).[0m
[33m[2023-01-04 14:44:38,896] [ WARNING][0m - Some weights of ErnieHealthForTotalPretraining were not initialized from the model checkpoint at ernie-health-chinese and are newly initialized: ['electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.0.norm2.bias', 'electra.generator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.encoder.layers.10.linear2.bias', 'electra.generator.electra.encoder.layers.0.linear2.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.7.norm2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.5.linear1.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.11.norm2.weight', 'electra.generator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.1.linear2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.linear1.bias', 'electra.discriminator.electra.encoder.layers.3.linear1.bias', 'electra.generator.electra.encoder.layers.9.norm1.weight', 'electra.discriminator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.4.norm2.weight', 'electra.generator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.weight', 'electra.generator.electra.encoder.layers.8.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm2.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.bias', 'electra.generator.electra.encoder.layers.1.norm2.bias', 'electra.generator.electra.encoder.layers.10.linear2.weight', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.1.linear1.weight', 'electra.generator.electra.encoder.layers.3.norm2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.linear1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear2.weight', 'electra.discriminator.discriminator_mts.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.linear2.weight', 'electra.generator.generator_lm_head_bias', 'electra.generator.electra.encoder.layers.10.linear2.bias', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.7.linear2.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.discriminator.discriminator_csp.dense.bias', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.8.linear2.bias', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.10.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.discriminator_csp.dense.weight', 'electra.discriminator.electra.encoder.layers.10.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.linear1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.norm1.bias', 'electra.generator.electra.encoder.layers.6.linear1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.11.norm2.bias', 'electra.generator.electra.encoder.layers.7.norm2.weight', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.weight', 'electra.discriminator.discriminator_rtd.dense.bias', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.8.norm1.bias', 'electra.generator.electra.encoder.layers.9.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.weight', 'electra.generator.electra.encoder.layers.1.norm1.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.weight', 'electra.generator.electra.encoder.layers.5.linear2.weight', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.11.linear1.bias', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.bias', 'electra.discriminator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.4.norm1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.weight', 'electra.discriminator.electra.encoder.layers.7.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.linear1.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.2.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.0.norm1.bias', 'electra.generator.electra.encoder.layers.7.linear1.weight', 'electra.generator.electra.encoder.layers.5.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.norm2.bias', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.norm2.bias', 'electra.discriminator.electra.encoder.layers.0.linear2.weight', 'electra.generator.electra.encoder.layers.7.norm1.bias', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.discriminator.discriminator_rtd.dense_prediction.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.generator.electra.embeddings.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.1.norm2.weight', 'electra.generator.electra.encoder.layers.7.norm1.weight', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.8.linear1.weight', 'electra.generator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.6.linear2.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.8.norm1.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.norm2.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.3.norm1.bias', 'electra.generator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.encoder.layers.11.norm2.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.bias_mts.weight', 'electra.discriminator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.linear1.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.0.linear1.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.10.norm2.weight', 'electra.generator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.discriminator_mts.weight', 'electra.generator.electra.embeddings.layer_norm.bias', 'electra.generator.electra.encoder.layers.4.norm2.bias', 'electra.discriminator.electra.encoder.layers.5.norm1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.linear2.bias', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.norm1.bias', 'electra.generator.electra.encoder.layers.9.norm2.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.generator.generator_predictions.dense.weight', 'electra.generator.electra.encoder.layers.2.norm2.weight', 'electra.discriminator.electra.encoder.layers.4.norm1.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.generator.generator_predictions.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.norm2.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.linear2.weight', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.embeddings.layer_norm.bias', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.11.linear2.weight', 'electra.generator.electra.encoder.layers.5.norm1.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.norm1.weight', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.6.norm2.bias', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.discriminator_rtd.dense_prediction.weight', 'electra.generator.electra.encoder.layers.7.linear2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.discriminator.electra.embeddings.layer_norm.weight', 'electra.generator.electra.encoder.layers.10.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.6.norm2.weight', 'electra.discriminator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.7.norm1.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.8.linear2.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.linear1.weight', 'electra.generator.electra.encoder.layers.3.linear1.weight', 'electra.generator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.4.norm1.bias', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.linear1.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.bias', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.9.linear1.weight', 'electra.generator.electra.encoder.layers.3.norm1.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.norm1.weight', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.6.linear2.weight', 'electra.discriminator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.7.norm1.weight', 'electra.discriminator.electra.encoder.layers.11.norm1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.weight', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.discriminator.discriminator_csp.out_proj.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.11.linear1.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.7.norm2.bias', 'electra.discriminator.electra.encoder.layers.0.norm1.weight', 'electra.generator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.electra.encoder.layers.11.norm2.weight', 'electra.discriminator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.linear2.weight', 'electra.generator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.electra.encoder.layers.5.linear2.bias', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.2.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.5.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.2.linear2.weight', 'electra.generator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.6.linear1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.norm1.bias', 'electra.discriminator.electra.encoder.layers.7.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.norm2.weight', 'electra.discriminator.electra.encoder.layers.0.norm2.bias', 'electra.generator.electra.encoder.layers.1.norm1.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.linear1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.discriminator.discriminator_rtd.dense.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.weight', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.generator.generator_predictions.dense.bias', 'electra.discriminator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.electra.encoder.layers.1.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.9.linear2.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.bias', 'electra.discriminator.electra.encoder.layers.8.linear1.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.discriminator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.4.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.9.norm1.bias', 'electra.generator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.3.linear2.bias', 'electra.generator.generator_predictions.layer_norm.bias', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.8.norm2.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.discriminator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear1.bias', 'electra.discriminator.discriminator_csp.out_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.3.linear2.weight', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[0m
[32m[2023-01-04 14:44:38,897] [    INFO][0m - start load data : 2023-01-04 14:44:38[0m
[32m[2023-01-04 14:44:39,162] [    INFO][0m - load data done, total : 0.26552248001098633 s[0m
[32m[2023-01-04 14:44:39,261] [    INFO][0m - max_steps is given, it will override any value given in num_train_epochs[0m
[32m[2023-01-04 14:44:39,261] [    INFO][0m - Using half precision[0m
[32m[2023-01-04 14:44:39,264] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:44:39,264] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2023-01-04 14:44:39,264] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - bf16                          :False[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - bf16_full_eval                :False[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - current_device                :gpu:5[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2023-01-04 14:44:39,265] [    INFO][0m - dataloader_num_workers        :2[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - device                        :gpu[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - disable_tqdm                  :False[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - do_eval                       :False[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - do_export                     :False[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - do_predict                    :False[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - do_train                      :True[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - eval_batch_size               :8[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - eval_iters                    :10[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - eval_steps                    :None[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - evaluation_strategy           :IntervalStrategy.NO[0m
[32m[2023-01-04 14:44:39,266] [    INFO][0m - fp16                          :True[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - fp16_full_eval                :False[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - greater_is_better             :None[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - label_names                   :None[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - learning_rate                 :0.001[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - load_best_model_at_end        :False[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - local_process_index           :0[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - local_rank                    :0[0m
[32m[2023-01-04 14:44:39,267] [    INFO][0m - log_level                     :-1[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - log_level_replica             :-1[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - log_on_each_node              :True[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - logging_dir                   :output/eheath-pretraining/runs/Jan04_14-44-21_yq01-qianmo-com-255-129-12.yq01[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - logging_first_step            :False[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - logging_steps                 :20[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - max_steps                     :100[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - metric_for_best_model         :None[0m
[32m[2023-01-04 14:44:39,268] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - no_cuda                       :False[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - num_train_epochs              :3.0[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - output_dir                    :output/eheath-pretraining[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - past_index                    :-1[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - process_index                 :0[0m
[32m[2023-01-04 14:44:39,269] [    INFO][0m - recompute                     :True[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - run_name                      :output/eheath-pretraining[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - save_on_each_node             :False[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - save_steps                    :5[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - save_total_limit              :10[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - scale_loss                    :32768[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - seed                          :42[0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - sharding                      :[][0m
[32m[2023-01-04 14:44:39,270] [    INFO][0m - sharding_degree               :-1[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - should_log                    :True[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - should_save                   :True[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - skip_memory_metrics           :True[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - test_iters                    :100[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - train_batch_size              :8[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - warmup_ratio                  :0.01[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - warmup_steps                  :0[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - weight_decay                  :0.01[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - world_size                    :3[0m
[32m[2023-01-04 14:44:39,271] [    INFO][0m - [0m
[32m[2023-01-04 14:44:39,323] [    INFO][0m - ***** Running training *****[0m
[32m[2023-01-04 14:44:39,324] [    INFO][0m -   Num examples = 200061[0m
[32m[2023-01-04 14:44:39,324] [    INFO][0m -   Num Epochs = 1[0m
[32m[2023-01-04 14:44:39,324] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2023-01-04 14:44:39,324] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 24[0m
[32m[2023-01-04 14:44:39,324] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2023-01-04 14:44:39,324] [    INFO][0m -   Total optimization steps = 100[0m
[32m[2023-01-04 14:44:39,324] [    INFO][0m -   Total num train samples = 2400[0m
/ssd1/zhangbin41/miniconda3/envs/paddle_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[32m[2023-01-04 14:53:37,898] [    INFO][0m - loading configuration file<./configs/test.yaml>[0m
<function init_argv at 0x7f28b036d550>
[32m[2023-01-04 14:53:37,906] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-01-04 14:53:37,906] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - model_name_or_path            :ernie-health-chinese[0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - model_type                    :ernie-health[0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - [0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - input_dir                     :./data[0m
[32m[2023-01-04 14:53:37,907] [    INFO][0m - masked_lm_prob                :0.15[0m
[32m[2023-01-04 14:53:37,908] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-01-04 14:53:37,908] [    INFO][0m - [0m
I0104 14:53:37.908685  6585 tcp_utils.cc:181] The server starts to listen on IP_ANY:38908
I0104 14:53:37.908880  6585 tcp_utils.cc:130] Successfully connected to 10.255.129.12:38908
W0104 14:53:43.233444  6585 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2
W0104 14:53:43.237321  6585 gpu_resources.cc:91] device: 5, cuDNN Version: 7.6.
[33m[2023-01-04 14:53:43,602] [ WARNING][0m - Process rank: 0, device: gpu, world_size: 3, distributed training: True, 16-bits training: True[0m
[32m[2023-01-04 14:53:43,604] [    INFO][0m - Already cached /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/vocab.txt[0m
[32m[2023-01-04 14:53:43,637] [    INFO][0m - tokenizer config file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/tokenizer_config.json[0m
[32m[2023-01-04 14:53:43,638] [    INFO][0m - Special tokens file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/special_tokens_map.json[0m
[32m[2023-01-04 14:53:43,640] [    INFO][0m - Model config ElectraConfig {
  "attention_probs_dropout_prob": 0.1,
  "embedding_size": 768,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 512,
  "model_type": "electra",
  "num_attention_heads": 12,
  "num_choices": 2,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "type_vocab_size": 2,
  "vocab_size": 22608
}
[0m
[33m[2023-01-04 14:53:44,171] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:53:44,253] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:53:44,785] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:53:44,863] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:53:45,143] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:53:46,081] [ WARNING][0m - Some weights of the model checkpoint at ernie-health-chinese were not used when initializing ErnieHealthForTotalPretraining: ['electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.encoder.layers.4.norm2.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layers.1.linear2.bias', 'electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.encoder.layers.10.linear2.weight', 'electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.encoder.layers.0.linear1.bias', 'electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.encoder.layers.9.norm2.bias', 'electra.encoder.layers.5.linear2.bias', 'electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.encoder.layers.11.norm2.bias', 'electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.encoder.layers.9.linear2.bias', 'electra.embeddings.layer_norm.weight', 'electra.encoder.layers.1.norm1.weight', 'electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.encoder.layers.2.linear1.bias', 'electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.encoder.layers.9.linear1.weight', 'electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.encoder.layers.2.linear1.weight', 'electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.encoder.layers.6.linear1.weight', 'electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.encoder.layers.11.norm1.weight', 'electra.encoder.layers.4.linear2.bias', 'electra.encoder.layers.2.linear2.weight', 'electra.encoder.layers.6.linear2.weight', 'electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.encoder.layers.9.linear2.weight', 'electra.encoder.layers.7.norm1.bias', 'electra.encoder.layers.7.norm2.weight', 'electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.encoder.layers.0.linear2.weight', 'electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.encoder.layers.5.norm1.weight', 'electra.encoder.layers.5.linear2.weight', 'electra.encoder.layers.6.norm1.bias', 'electra.encoder.layers.5.linear1.bias', 'electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.encoder.layers.8.norm2.bias', 'electra.encoder.layers.8.norm2.weight', 'electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.encoder.layers.11.linear2.bias', 'electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.encoder.layers.3.norm2.weight', 'electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.encoder.layers.4.norm1.bias', 'electra.encoder.layers.3.linear2.bias', 'electra.encoder.layers.10.linear2.bias', 'electra.embeddings.layer_norm.bias', 'electra.encoder.layers.11.norm1.bias', 'electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.encoder.layers.3.linear1.weight', 'electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.encoder.layers.7.linear2.weight', 'electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.encoder.layers.5.norm2.weight', 'electra.encoder.layers.1.norm1.bias', 'electra.encoder.layers.10.norm2.bias', 'electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.encoder.layers.3.norm2.bias', 'electra.encoder.layers.8.linear1.weight', 'electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.encoder.layers.3.linear1.bias', 'electra.encoder.layers.8.linear2.bias', 'electra.encoder.layers.6.norm2.weight', 'electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.encoder.layers.6.norm1.weight', 'electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.encoder.layers.11.linear1.weight', 'electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.encoder.layers.9.norm1.bias', 'electra.encoder.layers.7.linear1.weight', 'electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.encoder.layers.1.linear2.weight', 'electra.encoder.layers.3.norm1.weight', 'electra.encoder.layers.5.norm1.bias', 'electra.encoder.layers.1.norm2.weight', 'electra.encoder.layers.2.norm1.bias', 'electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.encoder.layers.8.norm1.bias', 'electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.encoder.layers.0.norm1.weight', 'electra.encoder.layers.11.norm2.weight', 'electra.encoder.layers.3.linear2.weight', 'electra.encoder.layers.1.linear1.bias', 'electra.encoder.layers.0.linear1.weight', 'electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.encoder.layers.1.linear1.weight', 'electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.encoder.layers.9.norm2.weight', 'electra.encoder.layers.4.norm2.bias', 'electra.encoder.layers.10.norm1.bias', 'electra.encoder.layers.8.norm1.weight', 'electra.encoder.layers.11.linear1.bias', 'electra.encoder.layers.4.linear1.bias', 'electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layers.2.linear2.bias', 'electra.encoder.layers.6.linear1.bias', 'electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.encoder.layers.5.norm2.bias', 'electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.encoder.layers.10.linear1.weight', 'electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.encoder.layers.11.linear2.weight', 'electra.encoder.layers.0.norm2.bias', 'electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.encoder.layers.2.norm2.weight', 'electra.encoder.layers.0.linear2.bias', 'electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.encoder.layers.0.norm1.bias', 'electra.encoder.layers.4.norm1.weight', 'electra.encoder.layers.8.linear2.weight', 'electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.encoder.layers.10.norm2.weight', 'electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.encoder.layers.10.linear1.bias', 'electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.encoder.layers.4.linear2.weight', 'electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.encoder.layers.7.norm1.weight', 'electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.encoder.layers.0.norm2.weight', 'electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.encoder.layers.3.norm1.bias', 'electra.encoder.layers.9.linear1.bias', 'electra.encoder.layers.9.norm1.weight', 'electra.encoder.layers.2.norm2.bias', 'electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.encoder.layers.8.linear1.bias', 'electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.encoder.layers.6.norm2.bias', 'electra.encoder.layers.1.norm2.bias', 'electra.encoder.layers.5.linear1.weight', 'electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.encoder.layers.7.linear1.bias', 'electra.encoder.layers.7.linear2.bias', 'electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.encoder.layers.7.norm2.bias', 'electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.encoder.layers.6.linear2.bias', 'electra.encoder.layers.2.norm1.weight', 'electra.encoder.layers.10.norm1.weight', 'electra.encoder.layers.4.linear1.weight']
- This IS expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).[0m
[33m[2023-01-04 14:53:46,081] [ WARNING][0m - Some weights of ErnieHealthForTotalPretraining were not initialized from the model checkpoint at ernie-health-chinese and are newly initialized: ['electra.generator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.norm2.weight', 'electra.generator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.bias', 'electra.generator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.discriminator_mts.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.norm2.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.1.norm2.bias', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.weight', 'electra.generator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.norm1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.9.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.weight', 'electra.generator.electra.encoder.layers.9.linear1.bias', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear2.bias', 'electra.generator.electra.encoder.layers.11.norm2.weight', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.10.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.weight', 'electra.discriminator.electra.embeddings.layer_norm.weight', 'electra.generator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.linear2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.discriminator.discriminator_rtd.dense.bias', 'electra.generator.electra.encoder.layers.4.linear1.bias', 'electra.discriminator.discriminator_rtd.dense.weight', 'electra.discriminator.electra.encoder.layers.11.linear2.bias', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.norm1.bias', 'electra.generator.electra.encoder.layers.9.linear1.weight', 'electra.discriminator.electra.encoder.layers.10.linear2.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.8.norm1.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.3.linear2.bias', 'electra.discriminator.electra.embeddings.layer_norm.bias', 'electra.generator.electra.encoder.layers.4.norm1.weight', 'electra.discriminator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.7.norm2.weight', 'electra.discriminator.electra.encoder.layers.10.norm2.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.weight', 'electra.discriminator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.discriminator.electra.embeddings.position_embeddings.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.linear2.bias', 'electra.generator.electra.encoder.layers.6.linear1.bias', 'electra.generator.electra.encoder.layers.5.norm1.bias', 'electra.discriminator.electra.encoder.layers.1.linear1.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.norm1.bias', 'electra.generator.electra.encoder.layers.5.linear1.weight', 'electra.discriminator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.4.norm1.bias', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.generator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.norm2.bias', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.norm1.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.4.norm2.bias', 'electra.discriminator.electra.encoder.layers.6.linear2.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.10.norm2.weight', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.weight', 'electra.discriminator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.2.norm1.weight', 'electra.generator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.2.norm2.weight', 'electra.generator.generator_predictions.dense.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.encoder.layers.7.norm1.weight', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.1.norm2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.generator.generator_predictions.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.11.norm1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.9.norm2.bias', 'electra.generator.electra.encoder.layers.5.linear1.bias', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.norm1.bias', 'electra.discriminator.discriminator_csp.dense.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.11.norm1.bias', 'electra.generator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.6.norm2.weight', 'electra.generator.electra.encoder.layers.5.linear2.weight', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.encoder.layers.0.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.norm2.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.0.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm1.bias', 'electra.discriminator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.6.linear2.weight', 'electra.discriminator.electra.encoder.layers.1.norm2.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.generator.electra.embeddings.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.7.linear2.bias', 'electra.generator.electra.encoder.layers.8.norm2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.5.norm2.weight', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.8.norm2.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.linear1.bias', 'electra.discriminator.electra.encoder.layers.5.norm1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.2.norm1.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.9.norm2.weight', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.generator.generator_lm_head_bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.7.norm2.bias', 'electra.generator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.4.linear1.bias', 'electra.discriminator.electra.encoder.layers.8.linear1.bias', 'electra.generator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.11.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.electra.encoder.layers.7.linear1.weight', 'electra.generator.electra.encoder.layers.10.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.linear1.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.7.norm2.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.6.linear1.weight', 'electra.discriminator.discriminator_csp.dense.bias', 'electra.discriminator.electra.encoder.layers.8.linear2.bias', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.linear1.bias', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.norm2.weight', 'electra.discriminator.electra.encoder.layers.1.norm1.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.linear1.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.generator_predictions.dense.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.bias', 'electra.generator.electra.encoder.layers.1.norm2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.3.norm2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.5.norm2.bias', 'electra.generator.electra.encoder.layers.0.linear2.bias', 'electra.generator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.linear1.weight', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.7.norm2.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.discriminator.discriminator_csp.out_proj.weight', 'electra.generator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.discriminator_csp.out_proj.bias', 'electra.generator.electra.encoder.layers.7.linear2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.8.norm1.weight', 'electra.discriminator.electra.encoder.layers.11.norm1.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.bias', 'electra.generator.electra.encoder.layers.0.norm2.bias', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear2.weight', 'electra.generator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.7.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.3.linear2.weight', 'electra.discriminator.bias_mts.weight', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.norm1.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.11.norm2.bias', 'electra.generator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.discriminator_rtd.dense_prediction.weight', 'electra.discriminator.discriminator_mts.weight', 'electra.discriminator.electra.encoder.layers.3.linear1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.8.norm1.bias', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.3.norm1.weight', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.linear2.bias', 'electra.generator.electra.encoder.layers.4.norm1.bias', 'electra.generator.electra.encoder.layers.11.norm2.bias', 'electra.discriminator.discriminator_rtd.dense_prediction.bias', 'electra.discriminator.electra.encoder.layers.0.linear1.weight', 'electra.generator.generator_predictions.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.6.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.generator.electra.embeddings.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.5.linear2.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.5.norm1.weight', 'electra.discriminator.electra.encoder.layers.10.norm1.weight', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.3.norm2.weight', 'electra.generator.electra.encoder.layers.11.linear2.bias', 'electra.generator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.linear2.weight', 'electra.generator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.3.linear1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.6.norm1.weight', 'electra.generator.electra.encoder.layers.1.linear1.weight', 'electra.generator.electra.encoder.layers.4.norm2.weight', 'electra.discriminator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.linear1.weight', 'electra.generator.electra.encoder.layers.5.norm2.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.bias', 'electra.generator.electra.encoder.layers.11.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.2.linear1.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.11.norm2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.7.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.7.linear2.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm1.weight', 'electra.generator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[0m
[32m[2023-01-04 14:53:46,082] [    INFO][0m - start load data : 2023-01-04 14:53:46[0m
[32m[2023-01-04 14:53:46,324] [    INFO][0m - load data done, total : 0.2421419620513916 s[0m
[32m[2023-01-04 14:53:46,413] [    INFO][0m - max_steps is given, it will override any value given in num_train_epochs[0m
[32m[2023-01-04 14:53:46,413] [    INFO][0m - Using half precision[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - bf16                          :False[0m
[32m[2023-01-04 14:53:46,416] [    INFO][0m - bf16_full_eval                :False[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - current_device                :gpu:5[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - dataloader_num_workers        :2[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - device                        :gpu[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - disable_tqdm                  :False[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - do_eval                       :False[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - do_export                     :False[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - do_predict                    :False[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - do_train                      :True[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - eval_batch_size               :8[0m
[32m[2023-01-04 14:53:46,417] [    INFO][0m - eval_iters                    :10[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - eval_steps                    :None[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - evaluation_strategy           :IntervalStrategy.NO[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - fp16                          :True[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - fp16_full_eval                :False[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - greater_is_better             :None[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - label_names                   :None[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - learning_rate                 :0.001[0m
[32m[2023-01-04 14:53:46,418] [    INFO][0m - load_best_model_at_end        :False[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - local_process_index           :0[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - local_rank                    :0[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - log_level                     :-1[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - log_level_replica             :-1[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - log_on_each_node              :True[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - logging_dir                   :output/eheath-pretraining/runs/Jan04_14-53-37_yq01-qianmo-com-255-129-12.yq01[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - logging_first_step            :False[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - logging_steps                 :20[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2023-01-04 14:53:46,419] [    INFO][0m - max_steps                     :100[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - metric_for_best_model         :None[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - no_cuda                       :False[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - num_train_epochs              :3.0[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - output_dir                    :output/eheath-pretraining[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - past_index                    :-1[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2023-01-04 14:53:46,420] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - process_index                 :0[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - recompute                     :True[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - run_name                      :output/eheath-pretraining[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - save_on_each_node             :False[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - save_steps                    :25[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - save_total_limit              :10[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - scale_loss                    :32768[0m
[32m[2023-01-04 14:53:46,421] [    INFO][0m - seed                          :42[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - sharding                      :[][0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - sharding_degree               :-1[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - should_log                    :True[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - should_save                   :True[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - skip_memory_metrics           :True[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - test_iters                    :100[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - train_batch_size              :8[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - warmup_ratio                  :0.01[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - warmup_steps                  :0[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - weight_decay                  :0.01[0m
[32m[2023-01-04 14:53:46,422] [    INFO][0m - world_size                    :3[0m
[32m[2023-01-04 14:53:46,423] [    INFO][0m - [0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m - ***** Running training *****[0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m -   Num examples = 200061[0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m -   Num Epochs = 1[0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 24[0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m -   Total optimization steps = 100[0m
[32m[2023-01-04 14:53:46,474] [    INFO][0m -   Total num train samples = 2400[0m
[32m[2023-01-04 14:53:46,491] [    INFO][0m -   Number of trainable parameters = 190772769[0m
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:03<05:42,  3.45s/it]Found inf or nan, current scale is: 32768.0, decrease to: 32768.0*0.5
  2%|â–         | 2/100 [00:04<03:02,  1.86s/it]  3%|â–Ž         | 3/100 [00:04<02:11,  1.35s/it]Found inf or nan, current scale is: 16384.0, decrease to: 16384.0*0.5
  4%|â–         | 4/100 [00:05<01:46,  1.11s/it]  5%|â–Œ         | 5/100 [00:06<01:33,  1.01it/s]Found inf or nan, current scale is: 8192.0, decrease to: 8192.0*0.5
  6%|â–Œ         | 6/100 [00:07<01:25,  1.10it/s]  7%|â–‹         | 7/100 [00:07<01:19,  1.17it/s]Found inf or nan, current scale is: 4096.0, decrease to: 4096.0*0.5
  8%|â–Š         | 8/100 [00:08<01:15,  1.22it/s]  9%|â–‰         | 9/100 [00:09<01:16,  1.20it/s] 10%|â–ˆ         | 10/100 [00:10<01:14,  1.21it/s] 11%|â–ˆ         | 11/100 [00:11<01:11,  1.25it/s]Found inf or nan, current scale is: 2048.0, decrease to: 2048.0*0.5
 12%|â–ˆâ–        | 12/100 [00:11<01:09,  1.27it/s] 13%|â–ˆâ–Ž        | 13/100 [00:12<01:08,  1.27it/s] 14%|â–ˆâ–        | 14/100 [00:13<01:08,  1.26it/s] 15%|â–ˆâ–Œ        | 15/100 [00:14<01:07,  1.26it/s] 16%|â–ˆâ–Œ        | 16/100 [00:15<01:06,  1.25it/s] 17%|â–ˆâ–‹        | 17/100 [00:15<01:06,  1.25it/s] 18%|â–ˆâ–Š        | 18/100 [00:16<01:05,  1.25it/s] 19%|â–ˆâ–‰        | 19/100 [00:17<01:04,  1.25it/s] 20%|â–ˆâ–ˆ        | 20/100 [00:18<01:03,  1.25it/s]                                                loss: 86.18217773, learning_rate: 0.0008586, global_step: 20, interval_runtime: 18.2653, interval_samples_per_second: 26.279, interval_steps_per_second: 1.095, epoch: 0.0024
 20%|â–ˆâ–ˆ        | 20/100 [00:18<01:03,  1.25it/s] 21%|â–ˆâ–ˆ        | 21/100 [00:19<01:03,  1.25it/s] 22%|â–ˆâ–ˆâ–       | 22/100 [00:19<01:02,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:20<01:01,  1.25it/s] 24%|â–ˆâ–ˆâ–       | 24/100 [00:21<01:01,  1.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:22<01:00,  1.24it/s][32m[2023-01-04 14:54:08,789] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-25[0m
[32m[2023-01-04 14:54:08,791] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-25/config.json[0m
[32m[2023-01-04 14:54:10,836] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-25/tokenizer_config.json[0m
[32m[2023-01-04 14:54:10,837] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-25/special_tokens_map.json[0m
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:28<03:01,  2.45s/it] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:29<02:22,  1.95s/it] 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:30<01:55,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:30<01:36,  1.36s/it] 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:31<01:23,  1.19s/it] 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:32<01:14,  1.07s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:33<01:07,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:34<01:02,  1.07it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:34<00:58,  1.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:35<00:56,  1.15it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:36<00:54,  1.18it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:37<00:52,  1.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:38<00:50,  1.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:38<00:49,  1.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:39<00:48,  1.24it/s]                                                loss: 63.4869812, learning_rate: 0.0006566, global_step: 40, interval_runtime: 21.4669, interval_samples_per_second: 22.36, interval_steps_per_second: 0.932, epoch: 0.0048
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:39<00:48,  1.24it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:40<00:47,  1.24it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:41<00:46,  1.25it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:42<00:45,  1.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:42<00:44,  1.25it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:43<00:43,  1.25it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:44<00:43,  1.25it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:45<00:42,  1.26it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:46<00:41,  1.26it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:46<00:40,  1.26it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:47<00:39,  1.26it/s][32m[2023-01-04 14:54:34,182] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-50[0m
[32m[2023-01-04 14:54:34,184] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-50/config.json[0m
[32m[2023-01-04 14:54:36,153] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-50/tokenizer_config.json[0m
[32m[2023-01-04 14:54:36,153] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-50/special_tokens_map.json[0m
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:53<01:58,  2.42s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:54<01:32,  1.93s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:55<01:15,  1.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:56<01:02,  1.36s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:57<00:53,  1.19s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:57<00:47,  1.07s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:58<00:42,  1.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:59<00:39,  1.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [01:00<00:36,  1.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [01:01<00:34,  1.15it/s]                                                loss: 63.50203857, learning_rate: 0.0004545, global_step: 60, interval_runtime: 21.377, interval_samples_per_second: 22.454, interval_steps_per_second: 0.936, epoch: 0.0072
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [01:01<00:34,  1.15it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [01:01<00:32,  1.18it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [01:02<00:31,  1.20it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [01:03<00:30,  1.22it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [01:04<00:29,  1.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [01:05<00:28,  1.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [01:05<00:27,  1.25it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [01:06<00:26,  1.25it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [01:07<00:25,  1.25it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [01:08<00:24,  1.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [01:09<00:23,  1.26it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [01:09<00:23,  1.26it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [01:10<00:22,  1.26it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [01:11<00:21,  1.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [01:12<00:20,  1.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [01:13<00:19,  1.26it/s][32m[2023-01-04 14:54:59,510] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-75[0m
[32m[2023-01-04 14:54:59,513] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-75/config.json[0m
[32m[2023-01-04 14:55:01,443] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-75/tokenizer_config.json[0m
[32m[2023-01-04 14:55:01,443] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-75/special_tokens_map.json[0m
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [01:19<01:03,  2.65s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [01:20<00:48,  2.10s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [01:21<00:37,  1.72s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [01:22<00:30,  1.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:23<00:25,  1.26s/it]                                                loss: 63.40671387, learning_rate: 0.0002525, global_step: 80, interval_runtime: 22.2005, interval_samples_per_second: 21.621, interval_steps_per_second: 0.901, epoch: 0.0096
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:23<00:25,  1.26s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [01:24<00:21,  1.13s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [01:24<00:18,  1.03s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [01:25<00:16,  1.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [01:26<00:14,  1.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [01:27<00:13,  1.14it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [01:28<00:11,  1.17it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [01:28<00:10,  1.20it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [01:29<00:09,  1.21it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [01:30<00:08,  1.23it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [01:31<00:08,  1.24it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [01:32<00:07,  1.24it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [01:32<00:06,  1.25it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [01:33<00:05,  1.24it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [01:34<00:04,  1.25it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [01:35<00:03,  1.25it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [01:36<00:03,  1.25it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [01:36<00:02,  1.26it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [01:37<00:01,  1.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [01:38<00:00,  1.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:39<00:00,  1.26it/s]                                                 loss: 63.08713379, learning_rate: 5.051e-05, global_step: 100, interval_runtime: 15.9499, interval_samples_per_second: 30.094, interval_steps_per_second: 1.254, epoch: 0.012
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:39<00:00,  1.26it/s][32m[2023-01-04 14:55:25,752] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-100[0m
[32m[2023-01-04 14:55:25,755] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-100/config.json[0m
[32m[2023-01-04 14:55:27,689] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-100/tokenizer_config.json[0m
[32m[2023-01-04 14:55:27,689] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-100/special_tokens_map.json[0m
[32m[2023-01-04 14:55:31,141] [    INFO][0m - 
Training completed. 
[0m
                                                 train_runtime: 104.6502, train_samples_per_second: 22.934, train_steps_per_second: 0.956, train_loss: 67.93300903320312, epoch: 0.012
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:44<00:00,  1.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:44<00:00,  1.05s/it]
[32m[2023-01-04 14:55:31,143] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining[0m
[32m[2023-01-04 14:55:31,145] [    INFO][0m - Configuration saved in output/eheath-pretraining/config.json[0m
[32m[2023-01-04 14:55:33,024] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/tokenizer_config.json[0m
[32m[2023-01-04 14:55:33,025] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/special_tokens_map.json[0m
[32m[2023-01-04 14:55:33,025] [    INFO][0m - ***** train metrics *****[0m
[32m[2023-01-04 14:55:33,025] [    INFO][0m -   epoch                    =      0.012[0m
[32m[2023-01-04 14:55:33,026] [    INFO][0m -   train_loss               =     67.933[0m
[32m[2023-01-04 14:55:33,026] [    INFO][0m -   train_runtime            = 0:01:44.65[0m
[32m[2023-01-04 14:55:33,026] [    INFO][0m -   train_samples_per_second =     22.934[0m
[32m[2023-01-04 14:55:33,026] [    INFO][0m -   train_steps_per_second   =      0.956[0m
I0104 14:55:34.124428  7369 tcp_store.cc:237] receive shutdown event and so quit from MasterDaemon run loop
/ssd1/zhangbin41/miniconda3/envs/paddle_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[32m[2023-01-04 14:59:19,429] [    INFO][0m - loading configuration file<./configs/test.yaml>[0m
[32m[2023-01-04 14:59:19,438] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-01-04 14:59:19,438] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:59:19,438] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-01-04 14:59:19,438] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:59:19,438] [    INFO][0m - model_name_or_path            :ernie-health-chinese[0m
[32m[2023-01-04 14:59:19,438] [    INFO][0m - model_type                    :ernie-health[0m
[32m[2023-01-04 14:59:19,438] [    INFO][0m - [0m
[32m[2023-01-04 14:59:19,439] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:59:19,439] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-01-04 14:59:19,439] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:59:19,439] [    INFO][0m - input_dir                     :./data[0m
[32m[2023-01-04 14:59:19,439] [    INFO][0m - masked_lm_prob                :0.15[0m
[32m[2023-01-04 14:59:19,439] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-01-04 14:59:19,439] [    INFO][0m - [0m
I0104 14:59:19.439929 32031 tcp_utils.cc:181] The server starts to listen on IP_ANY:43418
I0104 14:59:19.440105 32031 tcp_utils.cc:130] Successfully connected to 10.255.129.12:43418
W0104 14:59:22.027225 32031 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2
W0104 14:59:22.031091 32031 gpu_resources.cc:91] device: 5, cuDNN Version: 7.6.
[33m[2023-01-04 14:59:22,840] [ WARNING][0m - Process rank: 0, device: gpu, world_size: 3, distributed training: True, 16-bits training: True[0m
[32m[2023-01-04 14:59:22,841] [    INFO][0m - Checkpoint detected, resuming training at output/eheath-pretraining/checkpoint-100. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.[0m
[32m[2023-01-04 14:59:22,842] [    INFO][0m - Already cached /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/vocab.txt[0m
[32m[2023-01-04 14:59:22,877] [    INFO][0m - tokenizer config file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/tokenizer_config.json[0m
[32m[2023-01-04 14:59:22,877] [    INFO][0m - Special tokens file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/special_tokens_map.json[0m
[32m[2023-01-04 14:59:22,880] [    INFO][0m - Model config ElectraConfig {
  "attention_probs_dropout_prob": 0.1,
  "embedding_size": 768,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 512,
  "model_type": "electra",
  "num_attention_heads": 12,
  "num_choices": 2,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "type_vocab_size": 2,
  "vocab_size": 22608
}
[0m
[33m[2023-01-04 14:59:23,310] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:59:23,377] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:59:23,933] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 14:59:24,000] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:59:24,277] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 14:59:25,225] [ WARNING][0m - Some weights of the model checkpoint at ernie-health-chinese were not used when initializing ErnieHealthForTotalPretraining: ['electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.encoder.layers.1.norm2.bias', 'electra.encoder.layers.11.norm2.bias', 'electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.encoder.layers.9.norm2.weight', 'electra.encoder.layers.11.norm1.weight', 'electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.encoder.layers.10.linear2.bias', 'electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.encoder.layers.0.norm1.bias', 'electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.encoder.layers.9.linear1.bias', 'electra.encoder.layers.10.norm1.bias', 'electra.encoder.layers.1.linear2.weight', 'electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.encoder.layers.1.norm2.weight', 'electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.encoder.layers.8.linear2.bias', 'electra.encoder.layers.2.norm1.weight', 'electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.encoder.layers.5.linear1.bias', 'electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.encoder.layers.8.norm1.weight', 'electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.encoder.layers.5.linear2.weight', 'electra.encoder.layers.2.linear1.weight', 'electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.encoder.layers.0.norm1.weight', 'electra.encoder.layers.11.norm1.bias', 'electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.encoder.layers.7.norm2.weight', 'electra.encoder.layers.0.linear2.weight', 'electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.encoder.layers.9.linear2.bias', 'electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.encoder.layers.5.norm2.weight', 'electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.encoder.layers.1.linear1.bias', 'electra.encoder.layers.8.linear2.weight', 'electra.encoder.layers.11.linear2.bias', 'electra.encoder.layers.3.linear2.bias', 'electra.encoder.layers.3.norm1.bias', 'electra.encoder.layers.6.norm2.weight', 'electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.encoder.layers.0.norm2.bias', 'electra.encoder.layers.5.linear2.bias', 'electra.encoder.layers.2.norm2.weight', 'electra.encoder.layers.4.norm1.bias', 'electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.encoder.layers.9.norm2.bias', 'electra.encoder.layers.3.linear1.weight', 'electra.encoder.layers.3.norm2.weight', 'electra.encoder.layers.6.norm1.weight', 'electra.encoder.layers.4.linear1.weight', 'electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.encoder.layers.9.linear1.weight', 'electra.encoder.layers.1.norm1.weight', 'electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.encoder.layers.2.norm2.bias', 'electra.encoder.layers.11.norm2.weight', 'electra.encoder.layers.8.norm2.bias', 'electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.encoder.layers.4.norm1.weight', 'electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.embeddings.layer_norm.bias', 'electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.encoder.layers.0.linear1.bias', 'electra.encoder.layers.9.linear2.weight', 'electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.encoder.layers.7.linear1.bias', 'electra.encoder.layers.4.linear2.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.encoder.layers.1.linear1.weight', 'electra.encoder.layers.6.linear1.bias', 'electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.encoder.layers.0.norm2.weight', 'electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.encoder.layers.5.linear1.weight', 'electra.encoder.layers.4.norm2.bias', 'electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.embeddings.layer_norm.weight', 'electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.encoder.layers.8.linear1.bias', 'electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.encoder.layers.7.norm2.bias', 'electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.encoder.layers.11.linear1.bias', 'electra.encoder.layers.7.norm1.weight', 'electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.encoder.layers.11.linear2.weight', 'electra.encoder.layers.6.linear2.bias', 'electra.encoder.layers.6.linear1.weight', 'electra.encoder.layers.7.norm1.bias', 'electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.encoder.layers.7.linear1.weight', 'electra.encoder.layers.1.linear2.bias', 'electra.encoder.layers.2.linear1.bias', 'electra.encoder.layers.4.norm2.weight', 'electra.encoder.layers.5.norm2.bias', 'electra.encoder.layers.7.linear2.weight', 'electra.encoder.layers.3.linear2.weight', 'electra.encoder.layers.10.linear1.weight', 'electra.encoder.layers.3.norm1.weight', 'electra.encoder.layers.10.linear2.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layers.4.linear2.weight', 'electra.encoder.layers.6.norm1.bias', 'electra.encoder.layers.9.norm1.weight', 'electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.encoder.layers.6.norm2.bias', 'electra.encoder.layers.9.norm1.bias', 'electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.encoder.layers.10.norm1.weight', 'electra.encoder.layers.11.linear1.weight', 'electra.encoder.layers.7.linear2.bias', 'electra.encoder.layers.10.linear1.bias', 'electra.encoder.layers.2.linear2.weight', 'electra.encoder.layers.5.norm1.weight', 'electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.encoder.layers.5.norm1.bias', 'electra.encoder.layers.6.linear2.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.encoder.layers.2.norm1.bias', 'electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.encoder.layers.1.norm1.bias', 'electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.encoder.layers.8.linear1.weight', 'electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.encoder.layers.8.norm1.bias', 'electra.encoder.layers.4.linear1.bias', 'electra.encoder.layers.10.norm2.bias', 'electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.encoder.layers.10.norm2.weight', 'electra.encoder.layers.3.linear1.bias', 'electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.encoder.layers.3.norm2.bias', 'electra.encoder.layers.0.linear2.bias', 'electra.encoder.layers.0.linear1.weight', 'electra.encoder.layers.8.norm2.weight', 'electra.encoder.layers.2.linear2.bias', 'electra.encoder.layers.1.self_attn.k_proj.weight']
- This IS expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).[0m
[33m[2023-01-04 14:59:25,225] [ WARNING][0m - Some weights of ErnieHealthForTotalPretraining were not initialized from the model checkpoint at ernie-health-chinese and are newly initialized: ['electra.discriminator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.11.norm1.bias', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.9.norm2.weight', 'electra.generator.electra.encoder.layers.5.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.6.linear1.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.7.norm2.weight', 'electra.discriminator.electra.encoder.layers.2.linear1.weight', 'electra.discriminator.discriminator_csp.out_proj.weight', 'electra.generator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.6.norm2.weight', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.9.linear1.weight', 'electra.discriminator.electra.encoder.layers.5.linear2.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.bias', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.discriminator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.5.norm2.bias', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.1.linear1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.generator.generator_predictions.dense.bias', 'electra.generator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.3.norm1.weight', 'electra.discriminator.electra.encoder.layers.8.norm2.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.5.norm1.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.discriminator.discriminator_rtd.dense_prediction.weight', 'electra.generator.electra.encoder.layers.2.linear1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.9.linear1.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.10.norm1.bias', 'electra.generator.electra.encoder.layers.4.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.7.norm2.bias', 'electra.generator.generator_lm_head_bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.linear1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.discriminator_csp.dense.weight', 'electra.generator.electra.encoder.layers.0.linear2.bias', 'electra.generator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.5.norm2.bias', 'electra.generator.electra.encoder.layers.0.linear1.bias', 'electra.discriminator.electra.embeddings.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.2.linear2.bias', 'electra.generator.electra.encoder.layers.2.norm1.bias', 'electra.generator.electra.encoder.layers.10.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.bias', 'electra.discriminator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.2.linear1.bias', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.linear1.bias', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.discriminator_mts.bias', 'electra.generator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.6.norm2.weight', 'electra.generator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.2.norm1.weight', 'electra.generator.electra.encoder.layers.10.linear1.bias', 'electra.generator.electra.encoder.layers.10.linear2.weight', 'electra.generator.electra.encoder.layers.6.norm2.bias', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.bias', 'electra.discriminator.electra.encoder.layers.11.norm2.bias', 'electra.discriminator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.norm2.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.bias', 'electra.generator.electra.encoder.layers.7.norm1.weight', 'electra.generator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.3.linear1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.7.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.1.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.generator.electra.embeddings.layer_norm.weight', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.6.linear2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.9.norm1.bias', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.8.norm2.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.encoder.layers.8.norm1.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.linear1.bias', 'electra.generator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm1.bias', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.2.linear2.bias', 'electra.generator.electra.encoder.layers.4.linear1.bias', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.bias_mts.weight', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.discriminator.discriminator_csp.out_proj.bias', 'electra.generator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear2.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.9.linear2.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.weight', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm1.bias', 'electra.generator.electra.encoder.layers.5.linear2.weight', 'electra.discriminator.electra.encoder.layers.7.norm2.bias', 'electra.discriminator.electra.encoder.layers.7.linear2.weight', 'electra.generator.electra.encoder.layers.6.linear1.bias', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.11.norm1.weight', 'electra.discriminator.electra.encoder.layers.8.norm1.bias', 'electra.generator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.bias', 'electra.discriminator.discriminator_csp.dense.bias', 'electra.generator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.10.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.0.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.linear2.weight', 'electra.generator.electra.encoder.layers.0.norm2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.1.norm2.weight', 'electra.generator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.2.norm2.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.1.linear2.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.norm2.bias', 'electra.discriminator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.electra.encoder.layers.2.norm2.weight', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.discriminator.electra.embeddings.word_embeddings.weight', 'electra.generator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.11.linear2.weight', 'electra.generator.electra.encoder.layers.9.linear2.weight', 'electra.discriminator.electra.encoder.layers.10.linear2.bias', 'electra.generator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.3.linear2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.1.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.linear2.weight', 'electra.generator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.norm2.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.10.norm2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.4.norm2.weight', 'electra.discriminator.discriminator_rtd.dense_prediction.bias', 'electra.discriminator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.generator.generator_predictions.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.2.norm1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.0.linear1.weight', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.1.linear1.weight', 'electra.generator.electra.encoder.layers.4.norm2.bias', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.linear2.bias', 'electra.discriminator.electra.encoder.layers.4.norm1.weight', 'electra.generator.electra.embeddings.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.weight', 'electra.discriminator.discriminator_mts.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.9.norm1.weight', 'electra.discriminator.electra.encoder.layers.9.norm2.bias', 'electra.generator.electra.encoder.layers.8.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.generator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.generator.generator_predictions.dense.weight', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.7.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.5.linear2.bias', 'electra.generator.electra.encoder.layers.8.linear1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.5.norm1.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.linear2.bias', 'electra.discriminator.discriminator_rtd.dense.weight', 'electra.generator.electra.encoder.layers.11.norm2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.4.linear1.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.3.linear2.weight', 'electra.generator.generator_predictions.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.encoder.layers.4.linear1.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.0.norm2.bias', 'electra.discriminator.electra.encoder.layers.1.norm1.bias', 'electra.discriminator.discriminator_rtd.dense.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.11.norm1.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.10.linear1.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.generator.electra.embeddings.token_type_embeddings.weight', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.3.norm2.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.norm1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.4.norm1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.9.norm2.weight', 'electra.discriminator.electra.encoder.layers.2.norm1.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.weight', 'electra.generator.electra.encoder.layers.3.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.11.norm2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.3.linear2.weight', 'electra.discriminator.electra.encoder.layers.3.norm2.weight', 'electra.discriminator.electra.encoder.layers.1.linear1.weight', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.11.linear2.weight', 'electra.generator.electra.encoder.layers.11.norm2.bias', 'electra.generator.electra.encoder.layers.8.norm2.weight', 'electra.discriminator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.norm2.weight', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.5.norm2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.1.norm2.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.bias', 'electra.discriminator.electra.embeddings.token_type_embeddings.weight', 'electra.generator.electra.encoder.layers.11.linear1.bias', 'electra.generator.electra.encoder.layers.7.linear2.bias', 'electra.discriminator.electra.embeddings.layer_norm.weight', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.linear1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.weight', 'electra.discriminator.electra.encoder.layers.7.norm1.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[0m
[32m[2023-01-04 14:59:25,226] [    INFO][0m - start load data : 2023-01-04 14:59:25[0m
[32m[2023-01-04 14:59:25,477] [    INFO][0m - load data done, total : 0.25095558166503906 s[0m
[32m[2023-01-04 14:59:25,600] [    INFO][0m - max_steps is given, it will override any value given in num_train_epochs[0m
[32m[2023-01-04 14:59:25,601] [    INFO][0m - Using half precision[0m
[32m[2023-01-04 14:59:25,606] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 14:59:25,606] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2023-01-04 14:59:25,606] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 14:59:25,607] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2023-01-04 14:59:25,607] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2023-01-04 14:59:25,607] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2023-01-04 14:59:25,607] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2023-01-04 14:59:25,607] [    INFO][0m - bf16                          :False[0m
[32m[2023-01-04 14:59:25,608] [    INFO][0m - bf16_full_eval                :False[0m
[32m[2023-01-04 14:59:25,608] [    INFO][0m - current_device                :gpu:5[0m
[32m[2023-01-04 14:59:25,608] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2023-01-04 14:59:25,608] [    INFO][0m - dataloader_num_workers        :2[0m
[32m[2023-01-04 14:59:25,608] [    INFO][0m - device                        :gpu[0m
[32m[2023-01-04 14:59:25,608] [    INFO][0m - disable_tqdm                  :False[0m
[32m[2023-01-04 14:59:25,609] [    INFO][0m - do_eval                       :False[0m
[32m[2023-01-04 14:59:25,609] [    INFO][0m - do_export                     :False[0m
[32m[2023-01-04 14:59:25,609] [    INFO][0m - do_predict                    :False[0m
[32m[2023-01-04 14:59:25,609] [    INFO][0m - do_train                      :True[0m
[32m[2023-01-04 14:59:25,609] [    INFO][0m - eval_batch_size               :8[0m
[32m[2023-01-04 14:59:25,610] [    INFO][0m - eval_iters                    :10[0m
[32m[2023-01-04 14:59:25,610] [    INFO][0m - eval_steps                    :None[0m
[32m[2023-01-04 14:59:25,610] [    INFO][0m - evaluation_strategy           :IntervalStrategy.NO[0m
[32m[2023-01-04 14:59:25,610] [    INFO][0m - fp16                          :True[0m
[32m[2023-01-04 14:59:25,610] [    INFO][0m - fp16_full_eval                :False[0m
[32m[2023-01-04 14:59:25,610] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2023-01-04 14:59:25,611] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2023-01-04 14:59:25,611] [    INFO][0m - greater_is_better             :None[0m
[32m[2023-01-04 14:59:25,611] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2023-01-04 14:59:25,611] [    INFO][0m - label_names                   :None[0m
[32m[2023-01-04 14:59:25,611] [    INFO][0m - learning_rate                 :0.001[0m
[32m[2023-01-04 14:59:25,611] [    INFO][0m - load_best_model_at_end        :False[0m
[32m[2023-01-04 14:59:25,612] [    INFO][0m - local_process_index           :0[0m
[32m[2023-01-04 14:59:25,612] [    INFO][0m - local_rank                    :0[0m
[32m[2023-01-04 14:59:25,612] [    INFO][0m - log_level                     :-1[0m
[32m[2023-01-04 14:59:25,612] [    INFO][0m - log_level_replica             :-1[0m
[32m[2023-01-04 14:59:25,612] [    INFO][0m - log_on_each_node              :True[0m
[32m[2023-01-04 14:59:25,613] [    INFO][0m - logging_dir                   :output/eheath-pretraining/runs/Jan04_14-59-19_yq01-qianmo-com-255-129-12.yq01[0m
[32m[2023-01-04 14:59:25,613] [    INFO][0m - logging_first_step            :False[0m
[32m[2023-01-04 14:59:25,613] [    INFO][0m - logging_steps                 :20[0m
[32m[2023-01-04 14:59:25,613] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:59:25,613] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2023-01-04 14:59:25,613] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2023-01-04 14:59:25,614] [    INFO][0m - max_steps                     :100[0m
[32m[2023-01-04 14:59:25,614] [    INFO][0m - metric_for_best_model         :None[0m
[32m[2023-01-04 14:59:25,614] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2023-01-04 14:59:25,614] [    INFO][0m - no_cuda                       :False[0m
[32m[2023-01-04 14:59:25,614] [    INFO][0m - num_train_epochs              :3.0[0m
[32m[2023-01-04 14:59:25,614] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2023-01-04 14:59:25,615] [    INFO][0m - output_dir                    :output/eheath-pretraining[0m
[32m[2023-01-04 14:59:25,615] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2023-01-04 14:59:25,615] [    INFO][0m - past_index                    :-1[0m
[32m[2023-01-04 14:59:25,615] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2023-01-04 14:59:25,615] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2023-01-04 14:59:25,616] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2023-01-04 14:59:25,616] [    INFO][0m - process_index                 :0[0m
[32m[2023-01-04 14:59:25,616] [    INFO][0m - recompute                     :True[0m
[32m[2023-01-04 14:59:25,616] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2023-01-04 14:59:25,616] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2023-01-04 14:59:25,616] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2023-01-04 14:59:25,617] [    INFO][0m - run_name                      :output/eheath-pretraining[0m
[32m[2023-01-04 14:59:25,617] [    INFO][0m - save_on_each_node             :False[0m
[32m[2023-01-04 14:59:25,617] [    INFO][0m - save_steps                    :25[0m
[32m[2023-01-04 14:59:25,617] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2023-01-04 14:59:25,617] [    INFO][0m - save_total_limit              :10[0m
[32m[2023-01-04 14:59:25,617] [    INFO][0m - scale_loss                    :32768[0m
[32m[2023-01-04 14:59:25,618] [    INFO][0m - seed                          :42[0m
[32m[2023-01-04 14:59:25,618] [    INFO][0m - sharding                      :[][0m
[32m[2023-01-04 14:59:25,618] [    INFO][0m - sharding_degree               :-1[0m
[32m[2023-01-04 14:59:25,618] [    INFO][0m - should_log                    :True[0m
[32m[2023-01-04 14:59:25,618] [    INFO][0m - should_save                   :True[0m
[32m[2023-01-04 14:59:25,618] [    INFO][0m - skip_memory_metrics           :True[0m
[32m[2023-01-04 14:59:25,618] [    INFO][0m - test_iters                    :100[0m
[32m[2023-01-04 14:59:25,619] [    INFO][0m - train_batch_size              :8[0m
[32m[2023-01-04 14:59:25,619] [    INFO][0m - warmup_ratio                  :0.01[0m
[32m[2023-01-04 14:59:25,619] [    INFO][0m - warmup_steps                  :0[0m
[32m[2023-01-04 14:59:25,619] [    INFO][0m - weight_decay                  :0.01[0m
[32m[2023-01-04 14:59:25,619] [    INFO][0m - world_size                    :3[0m
[32m[2023-01-04 14:59:25,619] [    INFO][0m - [0m
[32m[2023-01-04 14:59:25,620] [    INFO][0m - Loading model from output/eheath-pretraining/checkpoint-100 .[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m - ***** Running training *****[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m -   Num examples = 200061[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m -   Num Epochs = 1[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 24[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m -   Total optimization steps = 100[0m
[32m[2023-01-04 14:59:28,279] [    INFO][0m -   Total num train samples = 2400[0m
[32m[2023-01-04 14:59:28,294] [    INFO][0m -   Number of trainable parameters = 190772769[0m
[32m[2023-01-04 14:59:28,294] [    INFO][0m -   Continuing training from checkpoint, will skip to saved global_step[0m
[32m[2023-01-04 14:59:28,294] [    INFO][0m -   Continuing training from epoch 0[0m
[32m[2023-01-04 14:59:28,294] [    INFO][0m -   Continuing training from global step 100[0m
[32m[2023-01-04 14:59:28,295] [    INFO][0m -   Will skip the first 0 epochs then the first 100 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.[0m
  0%|          | 0/100 [00:00<?, ?it/s]Skipping the first batches:   0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/100 [00:00<?, ?it/s][ASkipping the first batches:   1%|          | 1/100 [00:00<01:07,  1.46it/s]Skipping the first batches:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:00<00:01, 56.17it/s]Skipping the first batches:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:00<00:00, 135.19it/s][32m[2023-01-04 14:59:29,226] [    INFO][0m - Didn't find an RNG file for process 0, if you are resuming a training that wasn't launched in a distributed fashion, reproducibility is not guaranteed.[0m
Skipping the first batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 107.36it/s]

101it [00:05, 20.14it/s]               [A
                        [Aloss: 64.40409088, learning_rate: 4.04e-05, global_step: 101, interval_runtime: 5.3934, interval_samples_per_second: 4.45, interval_steps_per_second: 0.185, epoch: 0.0121

101it [00:05, 20.14it/s][A[32m[2023-01-04 14:59:33,689] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-101[0m
[32m[2023-01-04 14:59:33,692] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-101/config.json[0m
[32m[2023-01-04 14:59:35,640] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-101/tokenizer_config.json[0m
[32m[2023-01-04 14:59:35,640] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-101/special_tokens_map.json[0m
[32m[2023-01-04 14:59:39,434] [    INFO][0m - 
Training completed. 
[0m

                        [Atrain_runtime: 11.1399, train_samples_per_second: 215.441, train_steps_per_second: 8.977, train_loss: 0.637664266151957, epoch: 0.0121

101it [00:11, 20.14it/s][A101it [00:11,  9.07it/s]
[32m[2023-01-04 14:59:39,435] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining[0m
[32m[2023-01-04 14:59:39,438] [    INFO][0m - Configuration saved in output/eheath-pretraining/config.json[0m
[32m[2023-01-04 14:59:42,049] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/tokenizer_config.json[0m
[32m[2023-01-04 14:59:42,049] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/special_tokens_map.json[0m
[32m[2023-01-04 14:59:42,050] [    INFO][0m - ***** train metrics *****[0m
[32m[2023-01-04 14:59:42,050] [    INFO][0m -   epoch                    =     0.0121[0m
[32m[2023-01-04 14:59:42,050] [    INFO][0m -   train_loss               =     0.6377[0m
[32m[2023-01-04 14:59:42,051] [    INFO][0m -   train_runtime            = 0:00:11.13[0m
[32m[2023-01-04 14:59:42,051] [    INFO][0m -   train_samples_per_second =    215.441[0m
[32m[2023-01-04 14:59:42,051] [    INFO][0m -   train_steps_per_second   =      8.977[0m
I0104 14:59:43.231410 32543 tcp_store.cc:237] receive shutdown event and so quit from MasterDaemon run loop
/ssd1/zhangbin41/miniconda3/envs/paddle_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[32m[2023-01-04 15:00:13,534] [    INFO][0m - loading configuration file<./configs/test.yaml>[0m
[32m[2023-01-04 15:00:13,542] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m - model_name_or_path            :ernie-health-chinese[0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m - model_type                    :ernie-health[0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m - [0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-01-04 15:00:13,543] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 15:00:13,544] [    INFO][0m - input_dir                     :./data[0m
[32m[2023-01-04 15:00:13,544] [    INFO][0m - masked_lm_prob                :0.15[0m
[32m[2023-01-04 15:00:13,544] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-01-04 15:00:13,544] [    INFO][0m - [0m
I0104 15:00:13.544854   330 tcp_utils.cc:181] The server starts to listen on IP_ANY:37981
I0104 15:00:13.545053   330 tcp_utils.cc:130] Successfully connected to 10.255.129.12:37981
W0104 15:00:16.500839   330 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2
W0104 15:00:16.504741   330 gpu_resources.cc:91] device: 5, cuDNN Version: 7.6.
[33m[2023-01-04 15:00:17,281] [ WARNING][0m - Process rank: 0, device: gpu, world_size: 3, distributed training: True, 16-bits training: True[0m
[32m[2023-01-04 15:00:17,282] [    INFO][0m - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie-health-chinese/vocab.txt and saved to /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese[0m
[32m[2023-01-04 15:00:17,517] [    INFO][0m - Found /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/vocab.txt[0m
[32m[2023-01-04 15:00:17,554] [    INFO][0m - tokenizer config file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/tokenizer_config.json[0m
[32m[2023-01-04 15:00:17,555] [    INFO][0m - Special tokens file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/special_tokens_map.json[0m
[32m[2023-01-04 15:00:17,557] [    INFO][0m - Model config ElectraConfig {
  "attention_probs_dropout_prob": 0.1,
  "embedding_size": 768,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 512,
  "model_type": "electra",
  "num_attention_heads": 12,
  "num_choices": 2,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "type_vocab_size": 2,
  "vocab_size": 22608
}
[0m
[33m[2023-01-04 15:00:17,979] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 15:00:18,053] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 15:00:18,564] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 15:00:18,641] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 15:00:18,888] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[32m[2023-01-04 15:00:24,971] [    INFO][0m - Downloading ernie-health-chinese.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie-health-chinese/ernie-health-chinese.pdparams[0m
  0%|          | 0.00/392M [00:00<?, ?B/s]  1%|          | 3.28M/392M [00:00<00:11, 34.4MB/s]  2%|â–         | 8.72M/392M [00:00<00:08, 47.7MB/s]  4%|â–         | 15.9M/392M [00:00<00:06, 60.5MB/s]  6%|â–Œ         | 23.4M/392M [00:00<00:05, 67.6MB/s]  8%|â–Š         | 31.0M/392M [00:00<00:05, 71.8MB/s] 10%|â–‰         | 38.7M/392M [00:00<00:04, 75.0MB/s] 12%|â–ˆâ–        | 46.4M/392M [00:00<00:04, 76.9MB/s] 14%|â–ˆâ–        | 54.2M/392M [00:00<00:04, 78.2MB/s] 16%|â–ˆâ–Œ        | 61.9M/392M [00:00<00:04, 79.2MB/s] 18%|â–ˆâ–Š        | 69.7M/392M [00:01<00:04, 79.8MB/s] 20%|â–ˆâ–‰        | 77.4M/392M [00:01<00:04, 80.3MB/s] 22%|â–ˆâ–ˆâ–       | 85.2M/392M [00:01<00:03, 80.7MB/s] 24%|â–ˆâ–ˆâ–Ž       | 92.9M/392M [00:01<00:03, 80.8MB/s] 26%|â–ˆâ–ˆâ–Œ       | 101M/392M [00:01<00:03, 80.9MB/s]  28%|â–ˆâ–ˆâ–Š       | 108M/392M [00:01<00:03, 80.8MB/s] 30%|â–ˆâ–ˆâ–‰       | 116M/392M [00:01<00:03, 80.8MB/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 124M/392M [00:01<00:03, 81.0MB/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 132M/392M [00:01<00:03, 80.9MB/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 139M/392M [00:01<00:03, 80.9MB/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 147M/392M [00:02<00:03, 80.7MB/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 155M/392M [00:02<00:03, 80.8MB/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 163M/392M [00:02<00:02, 81.1MB/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 170M/392M [00:02<00:02, 81.0MB/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 178M/392M [00:02<00:03, 69.1MB/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 185M/392M [00:02<00:03, 69.4MB/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 193M/392M [00:02<00:02, 72.4MB/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 200M/392M [00:02<00:03, 59.1MB/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 206M/392M [00:02<00:03, 57.2MB/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 212M/392M [00:03<00:03, 54.7MB/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 218M/392M [00:03<00:03, 58.9MB/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 226M/392M [00:03<00:02, 65.4MB/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 233M/392M [00:03<00:03, 55.5MB/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 238M/392M [00:03<00:02, 55.3MB/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 244M/392M [00:03<00:02, 56.0MB/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 250M/392M [00:03<00:02, 54.9MB/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 257M/392M [00:03<00:02, 60.0MB/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 262M/392M [00:03<00:02, 57.8MB/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 268M/392M [00:04<00:02, 57.7MB/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 275M/392M [00:04<00:01, 63.3MB/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 283M/392M [00:04<00:01, 69.3MB/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 291M/392M [00:04<00:01, 72.3MB/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 298M/392M [00:04<00:01, 63.9MB/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 305M/392M [00:04<00:01, 67.0MB/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 313M/392M [00:04<00:01, 71.8MB/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 320M/392M [00:04<00:01, 63.3MB/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 327M/392M [00:05<00:01, 60.8MB/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 334M/392M [00:05<00:00, 65.1MB/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 342M/392M [00:05<00:00, 70.6MB/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 350M/392M [00:05<00:00, 74.7MB/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 358M/392M [00:05<00:00, 77.9MB/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 367M/392M [00:05<00:00, 80.3MB/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 375M/392M [00:05<00:00, 82.0MB/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 383M/392M [00:05<00:00, 83.1MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 391M/392M [00:05<00:00, 83.7MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392M/392M [00:05<00:00, 70.4MB/s]
[33m[2023-01-04 15:00:31,678] [ WARNING][0m - Some weights of the model checkpoint at ernie-health-chinese were not used when initializing ErnieHealthForTotalPretraining: ['electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.encoder.layers.1.linear2.bias', 'electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.encoder.layers.3.linear1.bias', 'electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.encoder.layers.0.norm2.weight', 'electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.encoder.layers.4.norm2.weight', 'electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.encoder.layers.11.linear1.weight', 'electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.encoder.layers.6.norm2.bias', 'electra.encoder.layers.11.norm1.bias', 'electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.encoder.layers.10.linear2.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.embeddings.layer_norm.bias', 'electra.encoder.layers.8.norm1.weight', 'electra.encoder.layers.9.linear1.weight', 'electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.encoder.layers.6.norm1.bias', 'electra.encoder.layers.5.linear2.weight', 'electra.encoder.layers.11.norm2.bias', 'electra.encoder.layers.1.norm1.bias', 'electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.embeddings.layer_norm.weight', 'electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.encoder.layers.10.linear1.bias', 'electra.encoder.layers.3.linear1.weight', 'electra.encoder.layers.2.norm1.bias', 'electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.encoder.layers.2.linear1.bias', 'electra.encoder.layers.0.norm1.bias', 'electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.encoder.layers.7.norm1.bias', 'electra.encoder.layers.10.norm2.bias', 'electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.encoder.layers.5.linear2.bias', 'electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.encoder.layers.7.norm1.weight', 'electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.encoder.layers.1.norm2.bias', 'electra.encoder.layers.2.norm2.weight', 'electra.encoder.layers.7.linear1.weight', 'electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.encoder.layers.10.linear2.bias', 'electra.encoder.layers.2.norm2.bias', 'electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.encoder.layers.5.linear1.bias', 'electra.encoder.layers.3.norm1.bias', 'electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.encoder.layers.9.norm2.weight', 'electra.encoder.layers.10.linear1.weight', 'electra.encoder.layers.3.norm2.bias', 'electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.encoder.layers.2.norm1.weight', 'electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.encoder.layers.3.linear2.weight', 'electra.encoder.layers.5.norm1.bias', 'electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.encoder.layers.5.linear1.weight', 'electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.encoder.layers.6.norm1.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.encoder.layers.5.norm1.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layers.7.linear2.weight', 'electra.encoder.layers.0.linear1.bias', 'electra.encoder.layers.6.linear1.bias', 'electra.encoder.layers.3.norm2.weight', 'electra.encoder.layers.7.linear2.bias', 'electra.encoder.layers.9.linear1.bias', 'electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.encoder.layers.0.linear2.bias', 'electra.encoder.layers.7.norm2.weight', 'electra.encoder.layers.11.linear1.bias', 'electra.encoder.layers.4.linear2.weight', 'electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.encoder.layers.1.linear2.weight', 'electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.encoder.layers.8.norm2.weight', 'electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.encoder.layers.6.linear2.weight', 'electra.encoder.layers.11.norm2.weight', 'electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.encoder.layers.4.linear2.bias', 'electra.encoder.layers.10.norm2.weight', 'electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.encoder.layers.0.linear1.weight', 'electra.encoder.layers.4.linear1.weight', 'electra.encoder.layers.4.linear1.bias', 'electra.encoder.layers.6.norm2.weight', 'electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.encoder.layers.1.linear1.weight', 'electra.encoder.layers.5.norm2.bias', 'electra.encoder.layers.3.norm1.weight', 'electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.encoder.layers.9.norm1.bias', 'electra.encoder.layers.9.linear2.bias', 'electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.encoder.layers.6.linear1.weight', 'electra.encoder.layers.11.norm1.weight', 'electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.encoder.layers.1.norm2.weight', 'electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.encoder.layers.11.linear2.bias', 'electra.encoder.layers.1.norm1.weight', 'electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.encoder.layers.1.linear1.bias', 'electra.encoder.layers.10.norm1.bias', 'electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.encoder.layers.0.linear2.weight', 'electra.encoder.layers.8.linear2.weight', 'electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.encoder.layers.8.linear1.weight', 'electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.encoder.layers.2.linear2.bias', 'electra.encoder.layers.4.norm1.bias', 'electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.encoder.layers.4.norm2.bias', 'electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.encoder.layers.9.linear2.weight', 'electra.encoder.layers.0.norm2.bias', 'electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.encoder.layers.8.linear2.bias', 'electra.encoder.layers.4.norm1.weight', 'electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.encoder.layers.5.norm2.weight', 'electra.encoder.layers.0.norm1.weight', 'electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.encoder.layers.10.norm1.weight', 'electra.encoder.layers.11.linear2.weight', 'electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.encoder.layers.9.norm1.weight', 'electra.encoder.layers.2.linear1.weight', 'electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.encoder.layers.7.linear1.bias', 'electra.encoder.layers.2.linear2.weight', 'electra.encoder.layers.8.norm1.bias', 'electra.encoder.layers.7.norm2.bias', 'electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.encoder.layers.8.linear1.bias', 'electra.encoder.layers.8.norm2.bias', 'electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.encoder.layers.9.norm2.bias', 'electra.encoder.layers.3.linear2.bias', 'electra.encoder.layers.6.linear2.bias', 'electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.encoder.layers.10.self_attn.k_proj.bias']
- This IS expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).[0m
[33m[2023-01-04 15:00:31,678] [ WARNING][0m - Some weights of ErnieHealthForTotalPretraining were not initialized from the model checkpoint at ernie-health-chinese and are newly initialized: ['electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.10.norm2.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.3.norm1.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.1.norm2.bias', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.8.linear2.bias', 'electra.generator.electra.encoder.layers.2.norm1.bias', 'electra.generator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.2.norm1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.11.linear1.bias', 'electra.generator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.bias', 'electra.discriminator.electra.encoder.layers.3.norm1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.10.norm2.weight', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.discriminator.discriminator_csp.dense.bias', 'electra.generator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.5.linear2.bias', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.7.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.discriminator.discriminator_rtd.dense.weight', 'electra.generator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.6.linear2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.1.norm1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.weight', 'electra.discriminator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.11.linear2.weight', 'electra.generator.electra.encoder.layers.1.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.generator.electra.embeddings.position_embeddings.weight', 'electra.discriminator.electra.encoder.layers.6.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.0.norm1.bias', 'electra.discriminator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.electra.encoder.layers.3.norm2.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.0.linear2.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.10.norm2.bias', 'electra.discriminator.electra.encoder.layers.9.norm1.bias', 'electra.discriminator.electra.encoder.layers.10.linear2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.5.linear1.weight', 'electra.discriminator.discriminator_csp.dense.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.4.norm1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.bias', 'electra.discriminator.electra.encoder.layers.11.norm1.weight', 'electra.discriminator.electra.embeddings.word_embeddings.weight', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.embeddings.token_type_embeddings.weight', 'electra.generator.electra.encoder.layers.0.linear1.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.9.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.7.norm2.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.5.norm1.bias', 'electra.generator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.4.linear1.bias', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.5.linear1.bias', 'electra.generator.electra.encoder.layers.10.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.linear1.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.discriminator.discriminator_rtd.dense.bias', 'electra.generator.electra.encoder.layers.2.norm2.weight', 'electra.discriminator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.7.linear2.bias', 'electra.discriminator.electra.encoder.layers.2.norm1.bias', 'electra.discriminator.electra.encoder.layers.9.norm2.weight', 'electra.discriminator.discriminator_rtd.dense_prediction.bias', 'electra.discriminator.electra.encoder.layers.6.norm1.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.5.norm1.weight', 'electra.discriminator.electra.encoder.layers.2.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.norm1.weight', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.10.linear2.weight', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.norm1.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.9.norm2.weight', 'electra.discriminator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.3.linear2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.3.linear1.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.5.norm1.weight', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.discriminator.electra.embeddings.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.5.linear2.weight', 'electra.generator.electra.encoder.layers.6.linear1.bias', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.norm2.weight', 'electra.discriminator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.7.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.weight', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.generator.electra.embeddings.layer_norm.bias', 'electra.generator.electra.encoder.layers.4.linear1.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.weight', 'electra.generator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.2.linear1.weight', 'electra.generator.electra.encoder.layers.7.norm2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.embeddings.position_embeddings.weight', 'electra.discriminator.electra.encoder.layers.8.linear2.weight', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.norm1.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.weight', 'electra.generator.electra.encoder.layers.9.linear1.weight', 'electra.generator.electra.encoder.layers.8.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.discriminator.bias_mts.weight', 'electra.discriminator.electra.encoder.layers.4.linear1.weight', 'electra.discriminator.electra.encoder.layers.4.norm1.weight', 'electra.discriminator.electra.encoder.layers.7.norm2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.11.norm2.weight', 'electra.discriminator.electra.encoder.layers.3.linear2.bias', 'electra.discriminator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.1.norm1.bias', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.norm1.bias', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.linear2.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.linear2.bias', 'electra.generator.generator_predictions.dense.weight', 'electra.generator.electra.encoder.layers.11.linear1.weight', 'electra.discriminator.electra.encoder.layers.1.linear1.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.bias', 'electra.discriminator.electra.encoder.layers.11.linear1.bias', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.linear1.bias', 'electra.generator.electra.encoder.layers.8.linear2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.embeddings.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.4.norm2.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.8.norm2.bias', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.6.linear2.weight', 'electra.generator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.6.norm2.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.6.linear1.weight', 'electra.discriminator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.linear2.weight', 'electra.discriminator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.1.linear2.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.11.norm2.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.discriminator_csp.out_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.8.linear2.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.norm2.bias', 'electra.discriminator.electra.encoder.layers.9.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.8.linear1.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.linear1.weight', 'electra.generator.electra.encoder.layers.10.linear2.bias', 'electra.generator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.11.linear2.bias', 'electra.generator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.3.norm2.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.11.norm2.bias', 'electra.generator.electra.encoder.layers.6.linear2.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.embeddings.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.norm2.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.8.norm2.bias', 'electra.discriminator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.discriminator_mts.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm2.bias', 'electra.generator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.linear2.bias', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.weight', 'electra.discriminator.electra.encoder.layers.0.norm1.bias', 'electra.generator.electra.encoder.layers.5.norm2.weight', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.4.linear1.weight', 'electra.generator.generator_predictions.layer_norm.weight', 'electra.discriminator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.norm2.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.6.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.8.norm1.bias', 'electra.generator.electra.encoder.layers.3.linear1.weight', 'electra.generator.generator_predictions.dense.bias', 'electra.discriminator.electra.encoder.layers.1.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.3.linear2.weight', 'electra.generator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.4.norm2.weight', 'electra.discriminator.discriminator_rtd.dense_prediction.weight', 'electra.discriminator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.3.linear1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.0.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.norm1.bias', 'electra.generator.electra.encoder.layers.11.norm1.weight', 'electra.generator.electra.encoder.layers.9.norm1.bias', 'electra.generator.generator_lm_head_bias', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.7.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.4.linear2.weight', 'electra.generator.electra.encoder.layers.1.linear1.weight', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.0.norm2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.bias', 'electra.generator.generator_predictions.layer_norm.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.7.norm2.bias', 'electra.generator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.discriminator_mts.bias', 'electra.generator.electra.encoder.layers.1.norm2.weight', 'electra.discriminator.discriminator_csp.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.6.norm2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[0m
[32m[2023-01-04 15:00:31,679] [    INFO][0m - start load data : 2023-01-04 15:00:31[0m
[32m[2023-01-04 15:00:31,941] [    INFO][0m - load data done, total : 0.26242947578430176 s[0m
[32m[2023-01-04 15:00:32,069] [    INFO][0m - max_steps is given, it will override any value given in num_train_epochs[0m
[32m[2023-01-04 15:00:32,070] [    INFO][0m - Using half precision[0m
[32m[2023-01-04 15:00:32,075] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 15:00:32,076] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2023-01-04 15:00:32,076] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 15:00:32,076] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2023-01-04 15:00:32,077] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2023-01-04 15:00:32,077] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2023-01-04 15:00:32,077] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2023-01-04 15:00:32,077] [    INFO][0m - bf16                          :False[0m
[32m[2023-01-04 15:00:32,077] [    INFO][0m - bf16_full_eval                :False[0m
[32m[2023-01-04 15:00:32,078] [    INFO][0m - current_device                :gpu:5[0m
[32m[2023-01-04 15:00:32,078] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2023-01-04 15:00:32,078] [    INFO][0m - dataloader_num_workers        :2[0m
[32m[2023-01-04 15:00:32,078] [    INFO][0m - device                        :gpu[0m
[32m[2023-01-04 15:00:32,078] [    INFO][0m - disable_tqdm                  :False[0m
[32m[2023-01-04 15:00:32,078] [    INFO][0m - do_eval                       :False[0m
[32m[2023-01-04 15:00:32,079] [    INFO][0m - do_export                     :False[0m
[32m[2023-01-04 15:00:32,079] [    INFO][0m - do_predict                    :False[0m
[32m[2023-01-04 15:00:32,079] [    INFO][0m - do_train                      :True[0m
[32m[2023-01-04 15:00:32,079] [    INFO][0m - eval_batch_size               :8[0m
[32m[2023-01-04 15:00:32,079] [    INFO][0m - eval_iters                    :10[0m
[32m[2023-01-04 15:00:32,079] [    INFO][0m - eval_steps                    :None[0m
[32m[2023-01-04 15:00:32,080] [    INFO][0m - evaluation_strategy           :IntervalStrategy.NO[0m
[32m[2023-01-04 15:00:32,080] [    INFO][0m - fp16                          :True[0m
[32m[2023-01-04 15:00:32,080] [    INFO][0m - fp16_full_eval                :False[0m
[32m[2023-01-04 15:00:32,080] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2023-01-04 15:00:32,080] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2023-01-04 15:00:32,080] [    INFO][0m - greater_is_better             :None[0m
[32m[2023-01-04 15:00:32,081] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2023-01-04 15:00:32,081] [    INFO][0m - label_names                   :None[0m
[32m[2023-01-04 15:00:32,081] [    INFO][0m - learning_rate                 :0.001[0m
[32m[2023-01-04 15:00:32,081] [    INFO][0m - load_best_model_at_end        :False[0m
[32m[2023-01-04 15:00:32,081] [    INFO][0m - local_process_index           :0[0m
[32m[2023-01-04 15:00:32,082] [    INFO][0m - local_rank                    :0[0m
[32m[2023-01-04 15:00:32,082] [    INFO][0m - log_level                     :-1[0m
[32m[2023-01-04 15:00:32,082] [    INFO][0m - log_level_replica             :-1[0m
[32m[2023-01-04 15:00:32,082] [    INFO][0m - log_on_each_node              :True[0m
[32m[2023-01-04 15:00:32,082] [    INFO][0m - logging_dir                   :output/eheath-pretraining/runs/Jan04_15-00-13_yq01-qianmo-com-255-129-12.yq01[0m
[32m[2023-01-04 15:00:32,082] [    INFO][0m - logging_first_step            :False[0m
[32m[2023-01-04 15:00:32,083] [    INFO][0m - logging_steps                 :20[0m
[32m[2023-01-04 15:00:32,083] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2023-01-04 15:00:32,083] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2023-01-04 15:00:32,083] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2023-01-04 15:00:32,083] [    INFO][0m - max_steps                     :100[0m
[32m[2023-01-04 15:00:32,083] [    INFO][0m - metric_for_best_model         :None[0m
[32m[2023-01-04 15:00:32,084] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2023-01-04 15:00:32,084] [    INFO][0m - no_cuda                       :False[0m
[32m[2023-01-04 15:00:32,084] [    INFO][0m - num_train_epochs              :3.0[0m
[32m[2023-01-04 15:00:32,084] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2023-01-04 15:00:32,084] [    INFO][0m - output_dir                    :output/eheath-pretraining[0m
[32m[2023-01-04 15:00:32,084] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2023-01-04 15:00:32,085] [    INFO][0m - past_index                    :-1[0m
[32m[2023-01-04 15:00:32,085] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2023-01-04 15:00:32,085] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2023-01-04 15:00:32,085] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2023-01-04 15:00:32,085] [    INFO][0m - process_index                 :0[0m
[32m[2023-01-04 15:00:32,086] [    INFO][0m - recompute                     :True[0m
[32m[2023-01-04 15:00:32,086] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2023-01-04 15:00:32,086] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2023-01-04 15:00:32,086] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2023-01-04 15:00:32,086] [    INFO][0m - run_name                      :output/eheath-pretraining[0m
[32m[2023-01-04 15:00:32,086] [    INFO][0m - save_on_each_node             :False[0m
[32m[2023-01-04 15:00:32,087] [    INFO][0m - save_steps                    :25[0m
[32m[2023-01-04 15:00:32,087] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2023-01-04 15:00:32,087] [    INFO][0m - save_total_limit              :10[0m
[32m[2023-01-04 15:00:32,087] [    INFO][0m - scale_loss                    :32768[0m
[32m[2023-01-04 15:00:32,087] [    INFO][0m - seed                          :42[0m
[32m[2023-01-04 15:00:32,087] [    INFO][0m - sharding                      :[][0m
[32m[2023-01-04 15:00:32,088] [    INFO][0m - sharding_degree               :-1[0m
[32m[2023-01-04 15:00:32,088] [    INFO][0m - should_log                    :True[0m
[32m[2023-01-04 15:00:32,088] [    INFO][0m - should_save                   :True[0m
[32m[2023-01-04 15:00:32,088] [    INFO][0m - skip_memory_metrics           :True[0m
[32m[2023-01-04 15:00:32,088] [    INFO][0m - test_iters                    :100[0m
[32m[2023-01-04 15:00:32,088] [    INFO][0m - train_batch_size              :8[0m
[32m[2023-01-04 15:00:32,089] [    INFO][0m - warmup_ratio                  :0.01[0m
[32m[2023-01-04 15:00:32,089] [    INFO][0m - warmup_steps                  :0[0m
[32m[2023-01-04 15:00:32,089] [    INFO][0m - weight_decay                  :0.01[0m
[32m[2023-01-04 15:00:32,089] [    INFO][0m - world_size                    :3[0m
[32m[2023-01-04 15:00:32,089] [    INFO][0m - [0m
[32m[2023-01-04 15:00:32,172] [    INFO][0m - ***** Running training *****[0m
[32m[2023-01-04 15:00:32,172] [    INFO][0m -   Num examples = 200061[0m
[32m[2023-01-04 15:00:32,172] [    INFO][0m -   Num Epochs = 1[0m
[32m[2023-01-04 15:00:32,172] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2023-01-04 15:00:32,173] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 24[0m
[32m[2023-01-04 15:00:32,173] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2023-01-04 15:00:32,173] [    INFO][0m -   Total optimization steps = 100[0m
[32m[2023-01-04 15:00:32,173] [    INFO][0m -   Total num train samples = 2400[0m
/ssd1/zhangbin41/miniconda3/envs/paddle_env/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[32m[2023-01-04 15:02:03,692] [    INFO][0m - loading configuration file<./configs/test.yaml>[0m
[32m[2023-01-04 15:02:03,700] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-01-04 15:02:03,701] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 15:02:03,701] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-01-04 15:02:03,701] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 15:02:03,701] [    INFO][0m - model_name_or_path            :ernie-health-chinese[0m
[32m[2023-01-04 15:02:03,701] [    INFO][0m - model_type                    :ernie-health[0m
[32m[2023-01-04 15:02:03,701] [    INFO][0m - [0m
[32m[2023-01-04 15:02:03,701] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 15:02:03,702] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-01-04 15:02:03,702] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 15:02:03,702] [    INFO][0m - input_dir                     :./data[0m
[32m[2023-01-04 15:02:03,702] [    INFO][0m - masked_lm_prob                :0.15[0m
[32m[2023-01-04 15:02:03,702] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-01-04 15:02:03,702] [    INFO][0m - [0m
I0104 15:02:03.703068 19200 tcp_utils.cc:181] The server starts to listen on IP_ANY:50016
I0104 15:02:03.703271 19200 tcp_utils.cc:130] Successfully connected to 10.255.129.12:50016
W0104 15:02:09.218474 19200 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 7.0, Driver API Version: 10.2, Runtime API Version: 10.2
W0104 15:02:09.223389 19200 gpu_resources.cc:91] device: 5, cuDNN Version: 7.6.
[33m[2023-01-04 15:02:10,022] [ WARNING][0m - Process rank: 0, device: gpu, world_size: 3, distributed training: True, 16-bits training: True[0m
[32m[2023-01-04 15:02:10,024] [    INFO][0m - Already cached /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/vocab.txt[0m
[32m[2023-01-04 15:02:10,059] [    INFO][0m - tokenizer config file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/tokenizer_config.json[0m
[32m[2023-01-04 15:02:10,059] [    INFO][0m - Special tokens file saved in /ssd1/zhangbin41/.paddlenlp/models/ernie-health-chinese/special_tokens_map.json[0m
[32m[2023-01-04 15:02:10,062] [    INFO][0m - Model config ElectraConfig {
  "attention_probs_dropout_prob": 0.1,
  "embedding_size": 768,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 512,
  "model_type": "electra",
  "num_attention_heads": 12,
  "num_choices": 2,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "type_vocab_size": 2,
  "vocab_size": 22608
}
[0m
[33m[2023-01-04 15:02:10,464] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 15:02:10,535] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 15:02:11,028] [ WARNING][0m - Accessing `initializer_range` through `model.initializer_range` will be deprecated after v2.6.0. Instead, do `model.config.initializer_range`[0m
[33m[2023-01-04 15:02:11,099] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 15:02:11,385] [ WARNING][0m - Accessing `layer_norm_eps` through `model.layer_norm_eps` will be deprecated after v2.6.0. Instead, do `model.config.layer_norm_eps`[0m
[33m[2023-01-04 15:02:12,262] [ WARNING][0m - Some weights of the model checkpoint at ernie-health-chinese were not used when initializing ErnieHealthForTotalPretraining: ['electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.encoder.layers.2.linear2.bias', 'electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.encoder.layers.4.norm2.weight', 'electra.encoder.layers.0.norm2.weight', 'electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.encoder.layers.10.norm2.bias', 'electra.encoder.layers.7.norm1.weight', 'electra.encoder.layers.9.norm2.bias', 'electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.encoder.layers.7.linear1.weight', 'electra.encoder.layers.6.linear1.weight', 'electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.encoder.layers.11.linear2.bias', 'electra.encoder.layers.5.norm1.bias', 'electra.encoder.layers.11.norm1.bias', 'electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.encoder.layers.5.linear1.weight', 'electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.encoder.layers.3.norm2.bias', 'electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.encoder.layers.9.linear2.bias', 'electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.encoder.layers.8.norm2.bias', 'electra.encoder.layers.2.norm1.weight', 'electra.encoder.layers.11.linear1.weight', 'electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.encoder.layers.5.linear1.bias', 'electra.encoder.layers.1.linear2.bias', 'electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.encoder.layers.4.norm1.bias', 'electra.encoder.layers.8.linear1.weight', 'electra.encoder.layers.1.linear1.weight', 'electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.encoder.layers.3.linear2.bias', 'electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.encoder.layers.7.linear1.bias', 'electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.encoder.layers.6.norm1.bias', 'electra.encoder.layers.0.norm2.bias', 'electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.encoder.layers.0.linear1.weight', 'electra.encoder.layers.9.linear1.bias', 'electra.encoder.layers.0.norm1.weight', 'electra.encoder.layers.8.linear1.bias', 'electra.encoder.layers.1.norm1.weight', 'electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.encoder.layers.3.norm1.weight', 'electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.encoder.layers.1.linear2.weight', 'electra.encoder.layers.10.linear1.bias', 'electra.encoder.layers.4.linear1.weight', 'electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.encoder.layers.10.norm2.weight', 'electra.encoder.layers.4.linear2.bias', 'electra.encoder.layers.11.norm1.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.encoder.layers.9.norm1.weight', 'electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.encoder.layers.7.norm2.weight', 'electra.encoder.layers.0.linear1.bias', 'electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.embeddings.layer_norm.weight', 'electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.encoder.layers.4.norm2.bias', 'electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.encoder.layers.6.linear1.bias', 'electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.encoder.layers.10.linear2.weight', 'electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.encoder.layers.0.linear2.bias', 'electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.encoder.layers.1.norm1.bias', 'electra.encoder.layers.8.norm1.bias', 'electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.encoder.layers.8.norm2.weight', 'electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.encoder.layers.10.linear2.bias', 'electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.encoder.layers.9.norm2.weight', 'electra.encoder.layers.7.norm1.bias', 'electra.encoder.layers.10.norm1.weight', 'electra.encoder.layers.6.linear2.bias', 'electra.encoder.layers.5.linear2.weight', 'electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.encoder.layers.3.linear2.weight', 'electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.encoder.layers.4.norm1.weight', 'electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.encoder.layers.4.linear2.weight', 'electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.encoder.layers.2.norm2.weight', 'electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.encoder.layers.0.norm1.bias', 'electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.encoder.layers.2.linear2.weight', 'electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.encoder.layers.2.linear1.weight', 'electra.encoder.layers.5.linear2.bias', 'electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.encoder.layers.8.linear2.bias', 'electra.encoder.layers.0.linear2.weight', 'electra.encoder.layers.1.linear1.bias', 'electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.encoder.layers.10.linear1.weight', 'electra.encoder.layers.6.norm2.weight', 'electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layers.9.norm1.bias', 'electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.encoder.layers.3.linear1.weight', 'electra.encoder.layers.2.norm2.bias', 'electra.encoder.layers.9.linear1.weight', 'electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.encoder.layers.7.norm2.bias', 'electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.encoder.layers.3.linear1.bias', 'electra.encoder.layers.6.norm1.weight', 'electra.encoder.layers.7.linear2.weight', 'electra.encoder.layers.3.norm2.weight', 'electra.encoder.layers.5.norm2.bias', 'electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.encoder.layers.11.norm2.bias', 'electra.encoder.layers.1.norm2.bias', 'electra.encoder.layers.9.linear2.weight', 'electra.encoder.layers.11.norm2.weight', 'electra.encoder.layers.4.linear1.bias', 'electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.encoder.layers.2.norm1.bias', 'electra.encoder.layers.1.norm2.weight', 'electra.encoder.layers.8.norm1.weight', 'electra.encoder.layers.2.linear1.bias', 'electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.encoder.layers.5.norm1.weight', 'electra.encoder.layers.3.norm1.bias', 'electra.encoder.layers.11.linear2.weight', 'electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.encoder.layers.11.linear1.bias', 'electra.embeddings.layer_norm.bias', 'electra.encoder.layers.7.linear2.bias', 'electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.encoder.layers.6.linear2.weight', 'electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.encoder.layers.8.linear2.weight', 'electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.encoder.layers.6.norm2.bias', 'electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.encoder.layers.10.norm1.bias', 'electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.encoder.layers.5.norm2.weight', 'electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.encoder.layers.1.self_attn.out_proj.bias']
- This IS expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ErnieHealthForTotalPretraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).[0m
[33m[2023-01-04 15:02:12,263] [ WARNING][0m - Some weights of ErnieHealthForTotalPretraining were not initialized from the model checkpoint at ernie-health-chinese and are newly initialized: ['electra.generator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.linear1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.2.norm2.weight', 'electra.generator.electra.encoder.layers.2.norm1.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.10.norm2.weight', 'electra.discriminator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.linear1.weight', 'electra.discriminator.electra.encoder.layers.0.norm1.bias', 'electra.generator.electra.encoder.layers.6.linear2.weight', 'electra.discriminator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.electra.encoder.layers.0.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.discriminator_rtd.dense_prediction.weight', 'electra.generator.electra.encoder.layers.4.norm1.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm2.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.discriminator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.2.linear2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.linear2.bias', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.6.norm1.bias', 'electra.discriminator.discriminator_rtd.dense.bias', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.6.norm2.weight', 'electra.discriminator.electra.encoder.layers.10.linear2.bias', 'electra.generator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.1.linear1.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.norm1.weight', 'electra.discriminator.electra.encoder.layers.8.linear1.bias', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.7.linear2.bias', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.3.linear2.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.3.linear2.bias', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.5.norm1.weight', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.discriminator.discriminator_mts.weight', 'electra.generator.electra.encoder.layers.4.linear1.weight', 'electra.discriminator.discriminator_rtd.dense_prediction.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear1.weight', 'electra.discriminator.electra.encoder.layers.3.linear2.bias', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.6.linear2.weight', 'electra.generator.electra.encoder.layers.5.linear1.weight', 'electra.generator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.6.linear1.weight', 'electra.generator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.6.norm1.bias', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.electra.encoder.layers.10.norm2.weight', 'electra.generator.electra.encoder.layers.4.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.5.norm2.weight', 'electra.discriminator.electra.encoder.layers.5.norm1.bias', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.5.linear2.weight', 'electra.discriminator.electra.encoder.layers.8.norm1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.norm2.weight', 'electra.generator.generator_predictions.dense.weight', 'electra.discriminator.electra.encoder.layers.6.norm1.weight', 'electra.discriminator.electra.encoder.layers.5.linear2.bias', 'electra.discriminator.electra.encoder.layers.11.norm2.bias', 'electra.generator.electra.encoder.layers.0.linear2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.8.linear1.weight', 'electra.generator.electra.encoder.layers.0.norm2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.norm2.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.1.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.norm1.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.7.linear1.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.norm1.bias', 'electra.discriminator.electra.encoder.layers.7.norm2.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.weight', 'electra.generator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.7.linear2.weight', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.weight', 'electra.generator.generator_predictions.layer_norm.weight', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.11.linear1.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.3.norm1.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.2.linear1.weight', 'electra.generator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.norm1.weight', 'electra.generator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.1.linear1.weight', 'electra.discriminator.electra.encoder.layers.10.linear1.bias', 'electra.generator.electra.encoder.layers.11.norm2.weight', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.3.linear2.weight', 'electra.discriminator.electra.encoder.layers.0.linear1.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.1.linear1.bias', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.linear1.bias', 'electra.generator.electra.encoder.layers.7.norm2.bias', 'electra.generator.electra.encoder.layers.0.norm1.weight', 'electra.discriminator.electra.encoder.layers.3.linear1.bias', 'electra.generator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.encoder.layers.3.norm2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.3.norm2.bias', 'electra.generator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.2.norm1.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.generator.generator_predictions.layer_norm.bias', 'electra.generator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.5.linear2.weight', 'electra.generator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.4.linear1.bias', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.linear2.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.8.norm1.bias', 'electra.generator.electra.encoder.layers.0.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.generator.generator_predictions.dense.bias', 'electra.discriminator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.10.norm2.bias', 'electra.generator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.linear2.bias', 'electra.generator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.7.norm2.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.9.linear2.weight', 'electra.generator.electra.encoder.layers.10.norm1.bias', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.bias', 'electra.discriminator.electra.embeddings.layer_norm.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.10.linear1.weight', 'electra.generator.electra.embeddings.layer_norm.weight', 'electra.generator.electra.encoder.layers.9.norm1.weight', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.1.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.2.linear1.bias', 'electra.discriminator.electra.encoder.layers.4.linear1.weight', 'electra.generator.electra.encoder.layers.7.norm1.weight', 'electra.discriminator.electra.encoder.layers.11.linear1.weight', 'electra.generator.electra.encoder.layers.6.norm2.bias', 'electra.discriminator.electra.encoder.layers.9.norm2.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.q_proj.weight', 'electra.discriminator.electra.embeddings.token_type_embeddings.weight', 'electra.discriminator.electra.encoder.layers.7.norm1.weight', 'electra.generator.electra.embeddings.layer_norm.bias', 'electra.generator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.encoder.layers.8.norm1.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.5.linear2.bias', 'electra.generator.electra.encoder.layers.4.linear2.weight', 'electra.discriminator.bias_mts.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.7.linear2.bias', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.generator.generator_lm_head_bias', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.11.linear2.weight', 'electra.discriminator.discriminator_mts.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.1.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.0.norm1.bias', 'electra.generator.electra.encoder.layers.3.norm1.bias', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.linear1.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.10.norm1.weight', 'electra.generator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.11.linear1.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.7.norm2.weight', 'electra.generator.electra.encoder.layers.1.linear2.weight', 'electra.generator.electra.encoder.layers.6.linear1.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.linear1.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.bias', 'electra.discriminator.discriminator_rtd.dense.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.3.norm1.bias', 'electra.generator.electra.encoder.layers.11.norm1.bias', 'electra.discriminator.electra.encoder.layers.11.linear2.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.11.norm2.weight', 'electra.generator.electra.encoder.layers.4.norm2.weight', 'electra.generator.electra.encoder.layers.9.norm1.bias', 'electra.generator.electra.encoder.layers.6.linear2.bias', 'electra.discriminator.electra.encoder.layers.10.linear1.weight', 'electra.discriminator.electra.encoder.layers.6.linear1.bias', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.out_proj.weight', 'electra.discriminator.discriminator_csp.out_proj.weight', 'electra.discriminator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.10.norm2.bias', 'electra.discriminator.electra.encoder.layers.1.norm1.weight', 'electra.generator.electra.encoder.layers.8.linear1.bias', 'electra.discriminator.electra.encoder.layers.11.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.10.linear1.bias', 'electra.discriminator.electra.encoder.layers.9.linear1.weight', 'electra.generator.electra.encoder.layers.10.norm1.weight', 'electra.discriminator.electra.encoder.layers.1.linear2.bias', 'electra.discriminator.electra.encoder.layers.8.linear2.bias', 'electra.generator.electra.encoder.layers.8.linear2.weight', 'electra.discriminator.electra.encoder.layers.2.linear2.bias', 'electra.generator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.1.norm2.weight', 'electra.discriminator.electra.encoder.layers.9.norm1.bias', 'electra.discriminator.electra.embeddings.position_embeddings.weight', 'electra.generator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.encoder.layers.6.norm1.weight', 'electra.generator.electra.encoder.layers.8.norm1.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.bias', 'electra.discriminator.electra.embeddings.layer_norm.bias', 'electra.generator.electra.encoder.layers.7.norm1.bias', 'electra.discriminator.electra.encoder.layers.4.norm2.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.8.norm2.bias', 'electra.discriminator.electra.encoder.layers.4.norm1.weight', 'electra.discriminator.electra.encoder.layers.0.norm2.weight', 'electra.discriminator.electra.encoder.layers.7.linear1.bias', 'electra.generator.electra.embeddings.word_embeddings.weight', 'electra.discriminator.discriminator_csp.dense.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.7.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.9.linear1.bias', 'electra.discriminator.electra.encoder.layers.9.linear2.bias', 'electra.generator.electra.encoder.layers.5.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.9.norm2.weight', 'electra.generator.electra.encoder.layers.10.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.4.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.1.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.3.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.8.norm2.bias', 'electra.discriminator.electra.encoder.layers.10.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.linear1.bias', 'electra.discriminator.electra.encoder.layers.7.linear1.weight', 'electra.discriminator.electra.encoder.layers.5.norm2.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.2.norm1.bias', 'electra.discriminator.electra.encoder.layers.7.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.11.norm1.weight', 'electra.generator.electra.encoder.layers.2.norm2.weight', 'electra.generator.electra.encoder.layers.8.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.4.linear2.bias', 'electra.discriminator.electra.encoder.layers.9.self_attn.q_proj.bias', 'electra.discriminator.discriminator_csp.out_proj.bias', 'electra.discriminator.electra.encoder.layers.3.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.0.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.discriminator.electra.encoder.layers.0.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.11.linear2.bias', 'electra.generator.electra.encoder.layers.5.norm1.bias', 'electra.generator.electra.encoder.layers.8.self_attn.k_proj.weight', 'electra.discriminator.discriminator_csp.dense.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.q_proj.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.5.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.2.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.2.norm2.bias', 'electra.generator.electra.encoder.layers.9.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.norm2.bias', 'electra.generator.electra.encoder.layers.9.linear1.weight', 'electra.discriminator.electra.encoder.layers.0.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.8.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.linear2.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.0.self_attn.out_proj.bias', 'electra.discriminator.electra.encoder.layers.8.norm2.weight', 'electra.generator.electra.encoder.layers.3.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.4.norm1.bias', 'electra.discriminator.electra.encoder.layers.7.linear2.weight', 'electra.discriminator.electra.encoder.layers.8.self_attn.out_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.9.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.q_proj.weight', 'electra.generator.electra.encoder.layers.3.norm1.weight', 'electra.generator.electra.encoder.layers.4.norm1.weight', 'electra.generator.electra.encoder.layers.7.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.3.linear1.bias', 'electra.generator.electra.encoder.layers.10.linear2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.0.linear1.bias', 'electra.generator.electra.encoder.layers.11.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.6.self_attn.q_proj.bias', 'electra.generator.electra.encoder.layers.1.norm1.bias', 'electra.generator.electra.encoder.layers.4.norm2.bias', 'electra.generator.electra.encoder.layers.2.self_attn.v_proj.bias', 'electra.discriminator.electra.encoder.layers.0.norm2.bias', 'electra.discriminator.electra.encoder.layers.2.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.discriminator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.1.self_attn.v_proj.weight', 'electra.discriminator.electra.encoder.layers.3.linear1.weight', 'electra.discriminator.electra.encoder.layers.3.self_attn.out_proj.weight', 'electra.generator.electra.encoder.layers.5.norm2.bias', 'electra.generator.electra.encoder.layers.11.self_attn.v_proj.weight', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.weight', 'electra.generator.electra.encoder.layers.11.self_attn.k_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.bias', 'electra.generator.electra.encoder.layers.2.linear2.weight', 'electra.discriminator.electra.encoder.layers.11.linear1.bias', 'electra.generator.electra.encoder.layers.0.norm2.bias', 'electra.discriminator.electra.encoder.layers.6.norm2.weight', 'electra.discriminator.electra.encoder.layers.4.self_attn.k_proj.weight', 'electra.discriminator.electra.encoder.layers.1.self_attn.k_proj.bias', 'electra.discriminator.electra.encoder.layers.1.norm2.weight', 'electra.discriminator.electra.encoder.layers.6.self_attn.v_proj.bias', 'electra.generator.electra.encoder.layers.10.self_attn.v_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[0m
[32m[2023-01-04 15:02:12,263] [    INFO][0m - start load data : 2023-01-04 15:02:12[0m
[32m[2023-01-04 15:02:12,512] [    INFO][0m - load data done, total : 0.2486414909362793 s[0m
[32m[2023-01-04 15:02:12,606] [    INFO][0m - max_steps is given, it will override any value given in num_train_epochs[0m
[32m[2023-01-04 15:02:12,607] [    INFO][0m - Using half precision[0m
[32m[2023-01-04 15:02:12,609] [    INFO][0m - ============================================================[0m
[32m[2023-01-04 15:02:12,609] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - paddle commit id              :941811b2f0824beba49bbca0f0c55232abe4785a[0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - bf16                          :False[0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - bf16_full_eval                :False[0m
[32m[2023-01-04 15:02:12,610] [    INFO][0m - current_device                :gpu:5[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - dataloader_num_workers        :2[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - device                        :gpu[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - disable_tqdm                  :False[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - do_eval                       :False[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - do_export                     :False[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - do_predict                    :False[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - do_train                      :True[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - eval_batch_size               :8[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - eval_iters                    :10[0m
[32m[2023-01-04 15:02:12,611] [    INFO][0m - eval_steps                    :None[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - evaluation_strategy           :IntervalStrategy.NO[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - fp16                          :True[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - fp16_full_eval                :False[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - greater_is_better             :None[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - label_names                   :None[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - learning_rate                 :0.001[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - load_best_model_at_end        :False[0m
[32m[2023-01-04 15:02:12,612] [    INFO][0m - local_process_index           :0[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - local_rank                    :0[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - log_level                     :-1[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - log_level_replica             :-1[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - log_on_each_node              :True[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - logging_dir                   :output/eheath-pretraining/runs/Jan04_15-02-03_yq01-qianmo-com-255-129-12.yq01[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - logging_first_step            :False[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - logging_steps                 :20[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2023-01-04 15:02:12,613] [    INFO][0m - max_steps                     :100[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - metric_for_best_model         :None[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - no_cuda                       :False[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - num_train_epochs              :3.0[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - output_dir                    :output/eheath-pretraining[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - overwrite_output_dir          :False[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - past_index                    :-1[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - per_device_eval_batch_size    :8[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - per_device_train_batch_size   :8[0m
[32m[2023-01-04 15:02:12,614] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - process_index                 :0[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - recompute                     :True[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - run_name                      :output/eheath-pretraining[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - save_on_each_node             :False[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - save_steps                    :25[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2023-01-04 15:02:12,615] [    INFO][0m - save_total_limit              :10[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - scale_loss                    :32768[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - seed                          :42[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - sharding                      :[][0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - sharding_degree               :-1[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - should_log                    :True[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - should_save                   :True[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - skip_memory_metrics           :True[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - test_iters                    :100[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - train_batch_size              :8[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - warmup_ratio                  :0.01[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - warmup_steps                  :0[0m
[32m[2023-01-04 15:02:12,616] [    INFO][0m - weight_decay                  :0.01[0m
[32m[2023-01-04 15:02:12,617] [    INFO][0m - world_size                    :3[0m
[32m[2023-01-04 15:02:12,617] [    INFO][0m - [0m
[32m[2023-01-04 15:02:12,669] [    INFO][0m - ***** Running training *****[0m
[32m[2023-01-04 15:02:12,669] [    INFO][0m -   Num examples = 200061[0m
[32m[2023-01-04 15:02:12,669] [    INFO][0m -   Num Epochs = 1[0m
[32m[2023-01-04 15:02:12,670] [    INFO][0m -   Instantaneous batch size per device = 8[0m
[32m[2023-01-04 15:02:12,670] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 24[0m
[32m[2023-01-04 15:02:12,670] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2023-01-04 15:02:12,670] [    INFO][0m -   Total optimization steps = 100[0m
[32m[2023-01-04 15:02:12,670] [    INFO][0m -   Total num train samples = 2400[0m
[32m[2023-01-04 15:02:12,725] [    INFO][0m -   Number of trainable parameters = 190772769[0m
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:03<05:45,  3.49s/it]Found inf or nan, current scale is: 32768.0, decrease to: 32768.0*0.5
  2%|â–         | 2/100 [00:04<03:03,  1.88s/it]  3%|â–Ž         | 3/100 [00:04<02:11,  1.36s/it]Found inf or nan, current scale is: 16384.0, decrease to: 16384.0*0.5
  4%|â–         | 4/100 [00:05<01:47,  1.12s/it]  5%|â–Œ         | 5/100 [00:06<01:34,  1.00it/s]Found inf or nan, current scale is: 8192.0, decrease to: 8192.0*0.5
  6%|â–Œ         | 6/100 [00:07<01:25,  1.10it/s]  7%|â–‹         | 7/100 [00:08<01:19,  1.17it/s]Found inf or nan, current scale is: 4096.0, decrease to: 4096.0*0.5
  8%|â–Š         | 8/100 [00:08<01:15,  1.21it/s]  9%|â–‰         | 9/100 [00:09<01:16,  1.19it/s] 10%|â–ˆ         | 10/100 [00:10<01:14,  1.21it/s] 11%|â–ˆ         | 11/100 [00:11<01:12,  1.23it/s] 12%|â–ˆâ–        | 12/100 [00:11<01:09,  1.26it/s]Found inf or nan, current scale is: 2048.0, decrease to: 2048.0*0.5
 13%|â–ˆâ–Ž        | 13/100 [00:12<01:07,  1.28it/s] 14%|â–ˆâ–        | 14/100 [00:13<01:06,  1.30it/s]Found inf or nan, current scale is: 1024.0, decrease to: 1024.0*0.5
 15%|â–ˆâ–Œ        | 15/100 [00:14<01:04,  1.31it/s] 16%|â–ˆâ–Œ        | 16/100 [00:14<01:04,  1.30it/s] 17%|â–ˆâ–‹        | 17/100 [00:15<01:04,  1.28it/s] 18%|â–ˆâ–Š        | 18/100 [00:16<01:04,  1.27it/s] 19%|â–ˆâ–‰        | 19/100 [00:17<01:03,  1.27it/s] 20%|â–ˆâ–ˆ        | 20/100 [00:18<01:03,  1.26it/s]                                                loss: 97.89970703, learning_rate: 0.0008687, global_step: 20, interval_runtime: 18.2006, interval_samples_per_second: 26.373, interval_steps_per_second: 1.099, epoch: 0.0024
 20%|â–ˆâ–ˆ        | 20/100 [00:18<01:03,  1.26it/s] 21%|â–ˆâ–ˆ        | 21/100 [00:18<01:02,  1.26it/s] 22%|â–ˆâ–ˆâ–       | 22/100 [00:19<01:02,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:20<01:01,  1.26it/s] 24%|â–ˆâ–ˆâ–       | 24/100 [00:21<01:00,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:22<00:59,  1.26it/s][32m[2023-01-04 15:02:34,901] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-25[0m
[32m[2023-01-04 15:02:34,904] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-25/config.json[0m
[32m[2023-01-04 15:02:36,871] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-25/tokenizer_config.json[0m
[32m[2023-01-04 15:02:36,871] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-25/special_tokens_map.json[0m
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:28<03:01,  2.45s/it] 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:29<02:22,  1.95s/it] 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:30<01:55,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:30<01:36,  1.36s/it] 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:31<01:23,  1.19s/it] 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:32<01:13,  1.07s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:33<01:07,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:34<01:02,  1.08it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:34<00:58,  1.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:35<00:55,  1.16it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:36<00:53,  1.19it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:37<00:52,  1.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:38<00:50,  1.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:38<00:49,  1.24it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:39<00:48,  1.24it/s]                                                loss: 64.17167969, learning_rate: 0.0006667, global_step: 40, interval_runtime: 21.3952, interval_samples_per_second: 22.435, interval_steps_per_second: 0.935, epoch: 0.0048
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:39<00:48,  1.24it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:40<00:47,  1.25it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:41<00:46,  1.25it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:41<00:45,  1.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:42<00:44,  1.26it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [00:43<00:43,  1.26it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:44<00:42,  1.26it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [00:45<00:42,  1.26it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [00:45<00:41,  1.26it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:46<00:40,  1.26it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:47<00:40,  1.24it/s][32m[2023-01-04 15:03:00,291] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-50[0m
[32m[2023-01-04 15:03:00,294] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-50/config.json[0m
[32m[2023-01-04 15:03:02,128] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-50/tokenizer_config.json[0m
[32m[2023-01-04 15:03:02,128] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-50/special_tokens_map.json[0m
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [00:53<01:54,  2.34s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:54<01:30,  1.88s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:55<01:13,  1.56s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [00:55<01:01,  1.34s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:56<00:53,  1.18s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:57<00:46,  1.06s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:58<00:42,  1.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:59<00:38,  1.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:59<00:36,  1.13it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [01:00<00:34,  1.16it/s]                                                loss: 63.44315186, learning_rate: 0.0004646, global_step: 60, interval_runtime: 21.1135, interval_samples_per_second: 22.734, interval_steps_per_second: 0.947, epoch: 0.0072
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [01:00<00:34,  1.16it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [01:01<00:32,  1.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [01:02<00:31,  1.21it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [01:03<00:30,  1.22it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [01:03<00:29,  1.23it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [01:04<00:28,  1.24it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [01:05<00:27,  1.25it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [01:06<00:26,  1.25it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [01:07<00:25,  1.25it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [01:07<00:24,  1.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [01:08<00:23,  1.26it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [01:09<00:23,  1.26it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [01:10<00:22,  1.26it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [01:11<00:21,  1.26it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [01:11<00:20,  1.26it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [01:12<00:19,  1.26it/s][32m[2023-01-04 15:03:25,344] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-75[0m
[32m[2023-01-04 15:03:25,346] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-75/config.json[0m
[32m[2023-01-04 15:03:27,188] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-75/tokenizer_config.json[0m
[32m[2023-01-04 15:03:27,188] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-75/special_tokens_map.json[0m
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [01:18<00:56,  2.34s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [01:19<00:43,  1.88s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [01:20<00:34,  1.55s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [01:20<00:27,  1.32s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:21<00:23,  1.16s/it]                                                loss: 63.15256348, learning_rate: 0.0002626, global_step: 80, interval_runtime: 21.0262, interval_samples_per_second: 22.829, interval_steps_per_second: 0.951, epoch: 0.0096
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:21<00:23,  1.16s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [01:22<00:20,  1.05s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [01:23<00:17,  1.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [01:24<00:15,  1.09it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [01:24<00:14,  1.13it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [01:25<00:12,  1.17it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [01:26<00:11,  1.20it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [01:27<00:10,  1.21it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [01:28<00:09,  1.23it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [01:28<00:08,  1.24it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [01:29<00:08,  1.24it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [01:30<00:07,  1.25it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [01:31<00:06,  1.25it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [01:32<00:05,  1.25it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [01:32<00:04,  1.26it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [01:33<00:03,  1.26it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [01:34<00:03,  1.26it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [01:35<00:02,  1.26it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [01:36<00:01,  1.26it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [01:36<00:00,  1.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:37<00:00,  1.26it/s]                                                 loss: 62.29503784, learning_rate: 6.061e-05, global_step: 100, interval_runtime: 15.8633, interval_samples_per_second: 30.259, interval_steps_per_second: 1.261, epoch: 0.012
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:37<00:00,  1.26it/s][32m[2023-01-04 15:03:50,326] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining/checkpoint-100[0m
[32m[2023-01-04 15:03:50,328] [    INFO][0m - Configuration saved in output/eheath-pretraining/checkpoint-100/config.json[0m
[32m[2023-01-04 15:03:52,217] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/checkpoint-100/tokenizer_config.json[0m
[32m[2023-01-04 15:03:52,217] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/checkpoint-100/special_tokens_map.json[0m
[32m[2023-01-04 15:03:55,620] [    INFO][0m - 
Training completed. 
[0m
                                                 train_runtime: 102.8945, train_samples_per_second: 23.325, train_steps_per_second: 0.972, train_loss: 70.19242797851562, epoch: 0.012
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:42<00:00,  1.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:42<00:00,  1.03s/it]
[32m[2023-01-04 15:03:55,621] [    INFO][0m - Saving model checkpoint to output/eheath-pretraining[0m
[32m[2023-01-04 15:03:55,624] [    INFO][0m - Configuration saved in output/eheath-pretraining/config.json[0m
[32m[2023-01-04 15:03:57,494] [    INFO][0m - tokenizer config file saved in output/eheath-pretraining/tokenizer_config.json[0m
[32m[2023-01-04 15:03:57,495] [    INFO][0m - Special tokens file saved in output/eheath-pretraining/special_tokens_map.json[0m
[32m[2023-01-04 15:03:57,495] [    INFO][0m - ***** train metrics *****[0m
[32m[2023-01-04 15:03:57,496] [    INFO][0m -   epoch                    =      0.012[0m
[32m[2023-01-04 15:03:57,496] [    INFO][0m -   train_loss               =    70.1924[0m
[32m[2023-01-04 15:03:57,496] [    INFO][0m -   train_runtime            = 0:01:42.89[0m
[32m[2023-01-04 15:03:57,496] [    INFO][0m -   train_samples_per_second =     23.325[0m
[32m[2023-01-04 15:03:57,496] [    INFO][0m -   train_steps_per_second   =      0.972[0m
I0104 15:03:58.611378 19393 tcp_store.cc:237] receive shutdown event and so quit from MasterDaemon run loop
